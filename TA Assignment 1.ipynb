{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6543a2dd-779a-4643-a6bd-ffa5c1ac4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dimits/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to /home/dimits/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6abedf4-87d7-4d30-b058-2a4a4f542aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spell_correction import BigramSpellCorrector, TrigramSpellCorrector\n",
    "from src.autocomplete import BigramModel, START_TOKEN, END_TOKEN, UNKNOWN_TOKEN, TrigramModel, BaseNgramModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b74da53-b6ee-490f-8ebc-6256aea039b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg_corpus = nltk.corpus.gutenberg.fileids()                                 #Get all the files\n",
    "gutenberg_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b16673-a350-459d-8fd3-0c3c990d9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died t\n"
     ]
    }
   ],
   "source": [
    "combined_text = \"\"             \n",
    "for file_id in gutenberg_corpus:                                        # Combine the text from all files\n",
    "    combined_text += nltk.corpus.gutenberg.raw(file_id)\n",
    "\n",
    "print(combined_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9cd0930-d3ab-4bbc-82e8-71de27c63468",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = combined_text.lower()                              #Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c6b392-464d-4c08-b16b-acaabbea6e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[emma by jane austen 1816]\\n\\nvolume i\\n\\nchapter i\\n\\n\\nemma woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.\\n\\nshe was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.  her mother\\nhad died t\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e4f3c82-7a8e-42d5-b04b-4160fe689891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_chars(text):\n",
    "   text = text.replace('[', '')\n",
    "   text = text.replace(']', '')\n",
    "   text = text.replace('\\n', ' ')\n",
    "   text = re.sub(r'[^a-zA-z.?!\\']', ' ', text)                     #Remove these characters   \n",
    "\n",
    "   return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb081710-1d7d-4c53-b85d-acd0a9528c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"emma by jane austen       volume i  chapter i   emma woodhouse  handsome  clever  and rich  with a comfortable home and happy disposition  seemed to unite some of the best blessings of existence  and had lived nearly twenty one years in the world with very little to distress or vex her.  she was the youngest of the two daughters of a most affectionate  indulgent father  and had  in consequence of her sister's marriage  been mistress of his house from a very early period.  her mother had died too\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text = remove_special_chars(combined_text)\n",
    "combined_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f25b00-f68a-4ad1-893d-f4e27e93698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2119883"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_text.split())                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7fcb110-bdda-41dc-8850-fae413272efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11793056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_text)                             # How many characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4da70b8-ff85-4fb0-b23f-df115f397805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"n the sea  the universe  the stars there in the     heavens   urging slowly  surely forward  forming endless  and waiting ever more  forever more behind.       good bye my fancy!  good bye my fancy! farewell dear mate  dear love! i'm going away  i know not where  or to what fortune  or whether i may ever see you again  so good bye my fancy.  now for my last  let me look back a moment  the slower fainter ticking of the clock is in me  exit  nightfall  and soon the heart thud stopping.  long have we lived  joy'd  caress'd together  delightful!  now separation  good bye my fancy.  yet let me not be too hasty  long indeed have we lived  slept  filter'd  become really blended     into one  then if we die we die together   yes  we'll remain one   if we go anywhere we'll go together to meet what happens  may be we'll be better off and blither  and learn something  may be it is yourself now really ushering me to the true songs   who     knows?  may be it is you the mortal knob really undoing  turning  so now finally  good bye  and hail! my fancy.  \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text[11792000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d6b0a3-9064-49b3-a16d-d527cddefe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "    sentences = nltk.sent_tokenize(''.join(text))                  #Get the sentences\n",
    "    return sentences     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f90469b6-7286-4434-a88c-2668f0ccd4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96282\n",
      "her mother had died too long ago for her to have more than an indistinct remembrance of her caresses  and her place had been supplied by an excellent woman as governess  who had fallen little short of a mother in affection.\n",
      "i hardly understand you   replied the scientist  with a cold intensity of manner.\n"
     ]
    }
   ],
   "source": [
    "sentences = tokenize_sentences(combined_text) \n",
    "print(len(sentences))    \n",
    "print(sentences[2])  \n",
    "print(sentences[57649])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaf01dde-77eb-44b7-a099-fffcab33cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3036efe1-6ba2-4a96-9b1d-fae699e453d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2235498\n",
      "austen\n",
      "fancy\n"
     ]
    }
   ],
   "source": [
    "words = tokenize_words(combined_text)\n",
    "print(len(words))\n",
    "print(words[3])\n",
    "print(words[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f56cfa79-f981-43fb-b6c1-1cef34040840",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = []                                    #list of all the words of sentences\n",
    "for f in sentences:\n",
    "    words_list.append(tokenize_words(f))                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01930b98-39d1-4eec-9275-5b154687c41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96282"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ba378be-6fa5-440d-be37-b8ef51dfbab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she\n",
      "was\n",
      "the\n",
      "youngest\n",
      "of\n",
      "the\n",
      "two\n",
      "daughters\n",
      "of\n",
      "a\n",
      "most\n",
      "affectionate\n",
      "indulgent\n",
      "father\n",
      "and\n",
      "had\n",
      "in\n",
      "consequence\n",
      "of\n",
      "her\n",
      "sister\n",
      "'s\n",
      "marriage\n",
      "been\n",
      "mistress\n",
      "of\n",
      "his\n",
      "house\n",
      "from\n",
      "a\n",
      "very\n",
      "early\n",
      "period\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in words_list[1]:                     # all the words of the second sentence\n",
    "    print(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "013c921e-362d-40b9-aabb-474c4b489be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "random.shuffle(words_list)\n",
    "train_len = math.floor(0.6 * len(words_list))                      #Training set length(60%)\n",
    "dev_len = math.floor(0.2 * len(words_list))                        #Development set length (20%)\n",
    "test_len = math.floor(0.2 * len(words_list))                       #Test set length (20%)\n",
    "\n",
    "training_set = []\n",
    "development_set = []\n",
    "test_set = []\n",
    "\n",
    "for content in words_list[0:train_len]:\n",
    "    training_set.append(content)\n",
    "    \n",
    "for content in words_list[train_len: train_len + dev_len]:\n",
    "    development_set.append(content)\n",
    "\n",
    "for content in words_list[train_len + dev_len:]:\n",
    "    test_set.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "941fd203-6132-40db-a596-5b8ae9dd43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "def _calc_ngrams(all_corpus: list[str], ngram: int) -> Counter:\n",
    "    \"\"\"\n",
    "    Process a tokenized sentence into a list of ngrams.\n",
    "    :param all_corpus: a list of all the corpus words\n",
    "    :param ngram: whether the ngrams will be unigrams, bigrams etc\n",
    "    :return: the counter of either unigram, bigram or trigram\n",
    "    \"\"\"\n",
    "    unigram_counter = Counter()\n",
    "    bigram_counter = Counter()\n",
    "    trigram_counter = Counter()\n",
    "     \n",
    "    \n",
    "\n",
    "    if ngram == 1 :\n",
    "        for sentence in all_corpus:\n",
    "             grams = [gram for gram in ngrams(sentence, ngram, pad_left=True, pad_right=True,\n",
    "                                    left_pad_symbol=START_TOKEN, right_pad_symbol=END_TOKEN)]\n",
    "             unigram_counter.update(grams)\n",
    "        return unigram_counter\n",
    "        \n",
    "    elif ngram == 2:\n",
    "        for sentence in all_corpus:\n",
    "             grams = [gram for gram in ngrams(sentence, ngram, pad_left=True, pad_right=True,\n",
    "                                    left_pad_symbol=START_TOKEN, right_pad_symbol=END_TOKEN)]\n",
    "             bigram_counter.update(grams)\n",
    "        return bigram_counter\n",
    "        \n",
    "    elif ngram == 3:\n",
    "        for sentence in all_corpus:\n",
    "             grams = [gram for gram in ngrams(sentence, ngram, pad_left=True, pad_right=True,\n",
    "                                    left_pad_symbol=START_TOKEN, right_pad_symbol=END_TOKEN)]\n",
    "             trigram_counter.update(grams)\n",
    "        return trigram_counter\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dd7c6b6-b1d5-44c1-9308-867c7eb13fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_OOV_words_train(all_corpus):\n",
    "    unigram_counter = _calc_ngrams(all_corpus,1)\n",
    "    OOV_words = {}\n",
    "\n",
    "    for k, v in unigram_counter.items():\n",
    "        if v < 10:\n",
    "            key = k[0]\n",
    "            # README: Use the symbol UNKOWN_TOKEN else the model will think it's a word\n",
    "            OOV_words[key] = UNKNOWN_TOKEN                 #set the word to \"UNK\"\n",
    "\n",
    "    replaced_corpus = []                          #the original corpus having the OOV words replaced by 'UNK'\n",
    "    for sentence in all_corpus:\n",
    "        clean_sentence = []\n",
    "    \n",
    "        for word in sentence:\n",
    "            clean_sentence.append(OOV_words.get(word, word))\n",
    "    \n",
    "        replaced_corpus.append(clean_sentence)\n",
    "\n",
    "\n",
    "    vocabulary = []\n",
    "\n",
    "    for key in unigram_counter.keys():        #Iterate the unigram counter\n",
    "        word = key[0]                         #get the word\n",
    "        if word not in OOV_words:\n",
    "            vocabulary.append(word)\n",
    "\n",
    "    vocabulary = set(vocabulary)              #Keep unique words\n",
    "    return vocabulary, replaced_corpus, OOV_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92f61c51-81f4-4a80-81b1-769dbb9bd058",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, train_corpus, OOV_words = replace_OOV_words_train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "323891dd-f0bc-4454-9d24-bac8427d276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_OOV_words_test(all_corpus, vocabulary, oov_words):\n",
    "    \n",
    "    replaced_corpus = []\n",
    "    for sentence in all_corpus:\n",
    "        updated_sent = []\n",
    "\n",
    "        for word in sentence:\n",
    "            if (word not in vocabulary) or (word in oov_words):\n",
    "                updated_sent.append(UNKNOWN_TOKEN)\n",
    "            else:\n",
    "                updated_sent.append(word)\n",
    "                \n",
    "    replaced_corpus.append(updated_sent)\n",
    "    return replaced_corpus   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0eab7ab-2171-43a8-90ef-ef49e5335b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "development_set = replace_OOV_words_test(development_set, vocabulary, OOV_words)\n",
    "test_set = replace_OOV_words_test(test_set, vocabulary, OOV_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5de1392-390e-47ed-8202-93ad4f1248e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length:  7335\n",
      "Unigram's 20 most common words:\n",
      "(('the',), 80032)\n",
      "(('<UNK>',), 68029)\n",
      "(('and',), 57420)\n",
      "(('.',), 46430)\n",
      "(('of',), 42737)\n",
      "(('to',), 28920)\n",
      "(('a',), 20356)\n",
      "(('in',), 20141)\n",
      "(('i',), 18122)\n",
      "(('that',), 17321)\n",
      "(('he',), 15550)\n",
      "(('it',), 13361)\n",
      "(('his',), 12938)\n",
      "(('for',), 11599)\n",
      "(('was',), 11403)\n",
      "(('not',), 10921)\n",
      "(('with',), 10483)\n",
      "(('is',), 10049)\n",
      "(('you',), 9854)\n",
      "(('be',), 9732)\n",
      "\n",
      "\n",
      "Bigram's 20 most common words:\n",
      "(('.', '<end>'), 46196)\n",
      "(('of', 'the'), 11465)\n",
      "(('the', '<UNK>'), 8108)\n",
      "(('<start>', 'and'), 8013)\n",
      "(('<UNK>', 'and'), 6300)\n",
      "(('in', 'the'), 6231)\n",
      "(('?', '<end>'), 6088)\n",
      "(('and', 'the'), 5310)\n",
      "(('<UNK>', '<UNK>'), 5278)\n",
      "(('!', '<end>'), 4921)\n",
      "(('<UNK>', '.'), 4904)\n",
      "(('and', '<UNK>'), 4749)\n",
      "(('the', 'lord'), 4249)\n",
      "(('<UNK>', 'of'), 4113)\n",
      "(('<start>', 'i'), 3456)\n",
      "(('of', '<UNK>'), 3408)\n",
      "(('to', 'the'), 3290)\n",
      "(('<UNK>', 'the'), 3200)\n",
      "(('<start>', 'the'), 3013)\n",
      "(('a', '<UNK>'), 2587)\n",
      "\n",
      "\n",
      "Trigram's 20 most common words:\n",
      "(('.', '<end>', '<end>'), 46196)\n",
      "(('<start>', '<start>', 'and'), 8013)\n",
      "(('?', '<end>', '<end>'), 6088)\n",
      "(('!', '<end>', '<end>'), 4921)\n",
      "(('<UNK>', '.', '<end>'), 4882)\n",
      "(('<start>', '<start>', 'i'), 3456)\n",
      "(('<start>', '<start>', 'the'), 3013)\n",
      "(('<start>', '<start>', 'but'), 2449)\n",
      "(('<start>', '<start>', 'he'), 2098)\n",
      "(('<UNK>', 'and', '<UNK>'), 1718)\n",
      "(('the', '<UNK>', 'of'), 1512)\n",
      "(('<start>', '<start>', '<UNK>'), 1406)\n",
      "(('<start>', '<start>', 'for'), 1326)\n",
      "(('<start>', '<start>', 'it'), 1313)\n",
      "(('<start>', 'and', 'the'), 1229)\n",
      "(('<start>', '<start>', 'then'), 1145)\n",
      "(('of', 'the', 'lord'), 1056)\n",
      "(('<UNK>', 'of', 'the'), 1018)\n",
      "(('of', 'the', '<UNK>'), 974)\n",
      "(('<start>', '<start>', 'she'), 968)\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(vocabulary)\n",
    "print (\"Vocabulary length: \", vocab_len)\n",
    "\n",
    "print(\"Unigram's 20 most common words:\")\n",
    "unigram_top_20 = _calc_ngrams(train_corpus, 1).most_common(20)\n",
    "for gram in unigram_top_20:\n",
    "    print(gram)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Bigram's 20 most common words:\")\n",
    "bigram_top_20 = _calc_ngrams(train_corpus,2).most_common(20)\n",
    "for gram in bigram_top_20:\n",
    "    print(gram)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Trigram's 20 most common words:\")\n",
    "trigram_top_20 = _calc_ngrams(train_corpus,3).most_common(20)\n",
    "for gram in trigram_top_20:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361a4ed-2f57-4f4b-a61f-6227992bacf8",
   "metadata": {},
   "source": [
    "(ii). First step: Tune α (alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8740d-4f21-49fc-abca-319b07e97926",
   "metadata": {},
   "source": [
    "##  Calculate bi-gram probability\n",
    "\n",
    "### $ P(w_2|w_1) = \\frac{C(w_1,w_2) + \\alpha}{C(w_1) + \\alpha \\cdot|V|} $\n",
    "\n",
    "* $ C(w_1,w_2) $ : bigram count\n",
    "* $ C(w_1) $ : unigram count\n",
    "* $ 0 \\leq\\alpha \\leq1 $ :  smoothing hyper-parameter\n",
    "* |V|: vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2fbe4-0a4b-4a7d-bb1b-5daad8b369c6",
   "metadata": {},
   "source": [
    "## Bi-gram LM Cross entropy & perplexity\n",
    "\n",
    "* $ CrossEntropy = -\\frac{1}{N}\\sum^{bigrams}{log_2(P(w_2|w_1))} $\n",
    " * N: Number of bigrams\n",
    "* $ Perplexity = 2^{H(p)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea916643-39d0-4b00-830d-e294299450fe",
   "metadata": {},
   "source": [
    "## Tri-gram LM Cross entropy & perplexity\n",
    "\n",
    "### $ P(w_3|w_1,w_2) = \\frac{C(w_1,w_2,w_3) + \\alpha}{C(w_1,w_2) + \\alpha \\cdot |V|} $\n",
    "\n",
    "* $ C(w_1,w_2,w_3) $ : trigram count\n",
    "* $ C(w_1,w_2) $ : bigram count\n",
    "* $ 0 \\leq\\alpha \\leq1 $ :  smoothing hyper-parameter\n",
    "* |V|: vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97dd4ed9-b159-469c-8686-ce887789cc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_entropy(model: BaseNgramModel, dataset: list[list[str]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy of a language model on a given dataset.\n",
    "    \n",
    "    Cross-entropy measures how well the language model predicts the given dataset.\n",
    "    Lower cross-entropy indicates better model performance.\n",
    "    \n",
    "    :param model: The n-gram language model for which cross-entropy is calculated.\n",
    "    :param dataset: The dataset as a list of tokenized sentences, where each sentence is a list of strings.\n",
    "    :return: The cross-entropy score as a float.\n",
    "             Lower values indicate better performance in predicting the dataset.\n",
    "    \"\"\"\n",
    "    # since la place smoothing is only involved during inference\n",
    "    # we don't need to refit the model\n",
    "    sum_prob = 0\n",
    "    word_count = 0\n",
    "    \n",
    "    for sentence in dataset:       \n",
    "        # since this is a full sentence we manually append the end token\n",
    "        sentence += [END_TOKEN]\n",
    "        \n",
    "        # take into account only the END_TOKEN since START token probs are not computed\n",
    "        word_count += len(sentence)\n",
    "        \n",
    "        # get sentence probability (already measured in log2)\n",
    "        sum_prob += model.sentence_proba(sentence) \n",
    "    \n",
    "    # do we need to logarithmize this again?\n",
    "    return - sum_prob / word_count\n",
    "\n",
    "\n",
    "def perplexity(cross_entropy: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate perplexity from cross-entropy.\n",
    "    \n",
    "    Perplexity is a measure of how well the language model predicts the given dataset.\n",
    "    A model with a perplexity of k, has approximately a 1/k chance of correctly predicting the next word in a sentence.\n",
    "    \n",
    "    :param cross_entropy: The cross-entropy score calculated for a language model on a dataset.\n",
    "    :return: The perplexity score as a float.\n",
    "             Lower values indicate better performance in predicting the dataset.\n",
    "    \"\"\"\n",
    "    return 2**cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e4809e1-9596-4e76-8094-0b4c241f57ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ngram_model_alpha_search(fitted_model: BaseNgramModel, \n",
    "                             alpha_values: np.ndarray, \n",
    "                             validation_dataset: list[list[str]]) -> float:\n",
    "    \"\"\"\n",
    "    Perform alpha hyperparameter search for an n-gram language model.\n",
    "    \n",
    "    Given a range of alpha values, evaluate the cross-entropy of the language model\n",
    "    for each alpha on a validation dataset and return the alpha value that minimizes\n",
    "    the cross-entropy.\n",
    "    \n",
    "    :param fitted_model: The pre-fitted n-gram language model.\n",
    "    :param alpha_values: Array of alpha values to search through.\n",
    "    :param validation_dataset: The validation dataset as a list of tokenized sentences,\n",
    "                               where each sentence is a list of strings.\n",
    "    :return: The best alpha value that minimizes cross-entropy on the validation dataset.\n",
    "    \"\"\"\n",
    "    entropy_arr = np.full_like(alpha_values, np.inf)\n",
    "    \n",
    "    for i in range(len(alpha_values)):\n",
    "        fitted_model.alpha = alpha_values[i]\n",
    "        entropy_arr[i] = cross_entropy(fitted_model, validation_dataset)\n",
    "        \n",
    "    best_index = np.argmin(entropy_arr)\n",
    "    return alpha_values[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b3cc2dd-e3f0-4f93-80ee-bf3a8205383b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Bi-gram alpha:  0.001\n"
     ]
    }
   ],
   "source": [
    "bi_model = BigramModel(alpha=0.001)\n",
    "bi_model.fit(train_corpus)\n",
    "\n",
    "bi_opt_alpha = ngram_model_alpha_search(bi_model, np.linspace(0.001, 1, 100), development_set)\n",
    "print(\"Optimal Bi-gram alpha: \", bi_opt_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "871e5b71-306b-46f9-b96d-b2d2cb1d71d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Tri-gram alpha:  0.001\n"
     ]
    }
   ],
   "source": [
    "tri_model = TrigramModel(alpha=0.001)\n",
    "tri_model.fit(train_corpus)\n",
    "\n",
    "tri_opt_alpha = ngram_model_alpha_search(tri_model, np.linspace(0.001, 1, 100), development_set)\n",
    "print(\"Optimal Tri-gram alpha: \", tri_opt_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd7c6816-e22b-4be7-bc77-752bd6960c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: validate these alpha values and then use them below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128f63f-7f1d-4d17-8949-67f0f4eef104",
   "metadata": {},
   "source": [
    "Now, let's test the performance in the test set, after having defined the optimal alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17f41bba-770b-40a2-8f26-85695431ab9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-gram model Cross Entropy: 5.93\n",
      "Bi-gram model Perplexity: 60.761378\n"
     ]
    }
   ],
   "source": [
    "# since la place smoothing is only involved during inference\n",
    "# we don't need to refit the model\n",
    "bi_model.alpha = bi_opt_alpha\n",
    "\n",
    "bi_hc = cross_entropy(bi_model, test_set)\n",
    "print(f\"Bi-gram model Cross Entropy: {bi_hc:.2f}\", )\n",
    "print(f\"Bi-gram model Perplexity: {perplexity(bi_hc):2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19423c60-91e1-42d6-98a2-2a902ae7a156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tri-gram model Cross Entropy: 5.45\n",
      "Tri-gram model Perplexity: 43.84\n"
     ]
    }
   ],
   "source": [
    "tri_model.alpha = tri_opt_alpha\n",
    "\n",
    "tri_hc = cross_entropy(tri_model, test_set)\n",
    "print(f\"Tri-gram model Cross Entropy: {tri_hc:.2f}\")\n",
    "print(f\"Tri-gram model Perplexity: {perplexity(tri_hc):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75603bb8-21ee-469b-bf12-85665e9094b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 5\n",
    "beam_width = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a8c72-e1a8-44dc-8338-266bbf419ee2",
   "metadata": {},
   "source": [
    "v. Create a fake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcf7846c-676f-42ed-8edb-5ef8cc6a557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "UNK_sentences = [sent_tokenize(' '.join(sentence)) for sentence in train_corpus]       #get the sentences that include UNK values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5489ff0f-2e72-4587-bdf6-e75e561b83fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: ['these things command and teach .']\n",
      "Corrupted: ['fhese fhings cummend and taasn .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: [\"therefore our sometimes sister now our queene th ' <UNK> <UNK> of this warlike state haue we as <UNK> with a <UNK> <UNK> with one <UNK> and one dropping eye with mirth in <UNK> and with <UNK> in marriage in <UNK> scale <UNK> delight and <UNK> taken to wife nor haue we <UNK> <UNK> 'd your better <UNK> which haue freely gone with this <UNK> along for all our <UNK> .\"]\n",
      "Corrupted: [\"therefore our conetimes cister mow uur queene tn ' <UNK> <UNK> of fhis warllke state naue we es <UNK> wifh a <UNK> <UNK> with ona <UNK> and une drupplmg eye with mirth im <UNK> amd wifn <UNK> in marrlage ln <UNK> ssale <UNK> delignt amb <UNK> taken fo wifa nor neue va <UNK> <UNK> 'd yuur betfer <UNK> wnich heue fteelv gona with this <UNK> alomg tor all our <UNK> .\"]\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['but it was a matter of great consolation to her that what brought evil to herself would bring good to her sister and elinor on the other hand suspecting that it would not be in her power to avoid edward entirely comforted herself by thinking that though their longer stay would therefore <UNK> against her own happiness it would be better for marianne than an immediate return into devonshire .']\n",
      "Corrupted: ['put lt was a mattar of great consuletion fo hat that what broughf evil to harself vouib brlng juod to ner clster anb elimor on the utnet hend suspectlng that it woold nof be in ner powet tu awold edvarb emtirelv comfotfed hatself by tnimkinj tnat tnough their ionget stay would tnarafure <UNK> against her own nappinecs it woold be bettet fot marianne fhan an lnmabiafa taturm into devonshite .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: [\"what in the devil 's name do you want here ?\"]\n",
      "Corrupted: [\"what im the devil 's nama do yuo wanf nere ?\"]\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['for the lord had appointed to defeat the good counsel of ahithophel to the intent that the lord might bring evil upon absalom .']\n",
      "Corrupted: ['for the iord had eppuinfed fo betaaf tne goub coumsai of ahithophel to fhe imtent tnet the lord mighf brinj avil upon apsalon .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['he seemed to want to be acquainted with her .']\n",
      "Corrupted: ['he seemed fo wamt to ba acquainfad with her .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['i am almost ashamed to say it .']\n",
      "Corrupted: ['i am almost ashened to cey lt .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['it was not in her nature .']\n",
      "Corrupted: ['if was nut in her nature .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['and one of the four beasts gave unto the seven angels seven golden <UNK> full of the wrath of god who liveth for ever and ever .']\n",
      "Corrupted: ['and ona of the fuur baacts gave onto tne ceven angels cevan golben <UNK> full uf the wreth uf gob vno liweth for ever and ever .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['for brethren ye have been called unto liberty only use not liberty for an occasion to the flesh but by love serve one another .']\n",
      "Corrupted: ['for brethren ye heve baen called unto liparty oniy use not liberfy fur am occasion tu tha flasn pot bv love serve one another .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['any nonsense will serve .']\n",
      "Corrupted: ['any nunsence wlll serwe .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: [\"and this shall be the priest 's due from the people from them that offer a sacrifice whether it be ox or sheep and they shall give unto the priest the shoulder and the two cheeks and the <UNK> .\"]\n",
      "Corrupted: [\"amb this shali be fhe priesf 'c due from the beopla from them fhat otfer a sactiflse whetner if be ox ot sheap amd they shall give unto fhe brlest fha cnoolder anb tha two sheeks amd the <UNK> .\"]\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['<UNK> an armed head .']\n",
      "Corrupted: ['<UNK> an armeb head .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['behold i give unto you power to tread on serpents and <UNK> and over all the power of the enemy and nothing shall by any means hurt you .']\n",
      "Corrupted: ['bahulb i glwe umto you buwer fo traad on serpents anb <UNK> and uvar ali the power ut tha eneny end nothinj snell by any meams nurt you .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['a worthy <UNK> once more <UNK> good friends hor .']\n",
      "Corrupted: ['a votthy <UNK> onca more <UNK> guod ftlenbs nor .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['therefore i will shake the heavens and the earth shall remove out of her place in the wrath of the lord of hosts and in the day of his fierce anger .']\n",
      "Corrupted: ['theretore i wili chake tna heavenc end the eatfh shall remowe out of her plase in the wtath of tha lotd of hostc amb in the day uf his fietce anget .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: [\"these poor brute beasts do n't know <UNK> what 's going to happen to them and as for dying it 's what we must all do some time or another but to keep <UNK> the hearts of the living that have as much sense as one 's self is what i call cruel and is not this what attorney case has been doing by poor susan and her whole family ever since he took a spite against them ?\"]\n",
      "Corrupted: [\"tnasa poor brute beactc bo m't xnow <UNK> wnat 's going to happen tu them and as for dyimg it 's whaf we most ail du some tima ot another buf to kaep <UNK> the neartc of tne iiving tnat heve as mucn sense as one 's celf is vhat l cail sruel emd is nof this whet atforney casa has paen doing py buor susan and har vhole femilv aver cince he fuok a splte ajainst tnem ?\"]\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['the old professor shook his head with a gravity that gave no hope but syme ran on with a <UNK> <UNK> .']\n",
      "Corrupted: ['the old brotescor shook hlc head wlth a grawify thet gawe mo hopa buf syme tan on wifh a <UNK> <UNK> .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['for i neither received it of man neither was i taught it but by the revelation of jesus christ .']\n",
      "Corrupted: ['fot i nelther receivad lf of man neifhar was i teught if puf by the revelaflon of jesus shrict .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: [\"i 'll make him know it and i 'll make you know it too said archer .\"]\n",
      "Corrupted: [\"i 'll make him kmow if amb i 'li make you kmov lt tou selb atcher .\"]\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['peace !']\n",
      "Corrupted: ['peace !']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['dear sweet louisa !']\n",
      "Corrupted: ['deer sweet louica !']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['the silver is mine and the gold is mine saith the lord of hosts .']\n",
      "Corrupted: ['tne cilver is mine end the gold is nlne caith the lord of nosts .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['her husband had been extravagant and at his death about two years before had left his affairs dreadfully involved .']\n",
      "Corrupted: ['her hosband hab been extravajant and at nic death apout fwo yearc befora heb latt his effalrs dteadfully invoiwed .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['i anchor my ship for a little while only my messengers continually cruise away or bring their returns to me .']\n",
      "Corrupted: ['i anchor mv shib for a little whlie uniy my mescengers continuaiiy cruise awav or bring their returms to me .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['you know what he thinks of <UNK> and <UNK> you are certain of his <UNK> their <UNK> as he ought and you have received every assurance of his admiring pope no more than is proper .']\n",
      "Corrupted: ['you know whaf he thinks of <UNK> and <UNK> you are certain of hlc <UNK> their <UNK> as he ought and you neva received every assurance of his admiring bope no more than is ptuper .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['o <UNK> on the rivers the voyage down the st. lawrence the superb <UNK> the <UNK> the ships sailing the thousand islands the occasional timber <UNK> and the <UNK> with long reaching sweep oars the little <UNK> on the <UNK> and the stream of smoke when they cook supper at evening .']\n",
      "Corrupted: ['o <UNK> om tha rivers the voyage dovn the st. lawtamce tne supetb <UNK> the <UNK> the shibs saillng tna fnoosand lslamdc tna ocsasiunal timbet <UNK> amb tne <UNK> with iong raachinj sweeb uars tne little <UNK> um the <UNK> enb tna streen uf cmoxe when fhev cuox cubper at evening .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['oh !']\n",
      "Corrupted: ['oh !']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['now eli the priest sat upon a seat by a post of the temple of the lord .']\n",
      "Corrupted: ['now eli tha priasf sat upon a seat py e pust of tne tanpie ot fhe iord .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['if you will i will love you always .']\n",
      "Corrupted: ['if you will i vill lova you eiwayc .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['miss woodhouse i hope nothing may happen to prevent the ball .']\n",
      "Corrupted: ['miss woudhooce i nope mothing nay happem tu prevenf fne bell .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['hor .']\n",
      "Corrupted: ['nor .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['i was afraid you would think i was taking a great liberty with you said she in telling you all this .']\n",
      "Corrupted: ['i was afraib vou would think i wes taking a great liperty vith you ceid sha in telling you all fhic .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['again the high priest asked him and said unto him art thou the christ the son of the blessed ?']\n",
      "Corrupted: ['ageim tne hijh priest asxed nim amd saib umto him ert thoo fhe chtist the son uf fha blecsed ?']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['and he sent eliakim who was over the household and <UNK> the scribe and the elders of the priests covered with sackcloth unto isaiah the prophet the son of amoz .']\n",
      "Corrupted: ['anb he semt eliakim who wes uver the household and <UNK> the ccribe and fhe eibars of fhe priests covered wlth sackclotn unto isaiah the btophef the son of amoz .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: [\"on edward 's side more particularly there was a <UNK> of all that a lover ought to look and say on such an occasion .\"]\n",
      "Corrupted: [\"un ebwatd 's cibe mora partisolariy thete wac a <UNK> of ail that a lover ought fu look and cav on such an ocsasion .\"]\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['any punishment of <UNK> he would have felt as natural but the sudden <UNK> between the laughter of his judge and the laughter of the man he had <UNK> made him feel suddenly small or at least <UNK> .']\n",
      "Corrupted: ['any punishmant ot <UNK> he vouib have felt as neturel but tne subben <UNK> pefwaam tha laughtet uf his judga and the laoghtar of tne mem he had <UNK> nebe hlm feel sudbemly small ot et laasf <UNK> .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['when ye go ye shall come unto a people secure and to a large land for god hath given it into your hands a place where there is no want of any thing that is in the earth .']\n",
      "Corrupted: ['when ye gu ye shail sume umto a people cacure and to a lerge land fot gob heth givem if into yout nands a pleca where there ls no wemt uf amv thing fnat is in the earth .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['the <UNK> of course was the choice <UNK> of the champion arms the cigar he had probably brought with him from london .']\n",
      "Corrupted: ['the <UNK> of source was fhe choisa <UNK> of tha chanpiom arms the cigar he ned brubably broojhf wifh hln frum lonbun .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['<UNK> mad to say it .']\n",
      "Corrupted: ['<UNK> mad fo say it .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['grandmama was quite well had a charming evening with mr. woodhouse a vast deal of chat and <UNK> .']\n",
      "Corrupted: ['grandmema vas quite weii had a sharmlng evenimg with mr. voodnooca e vest beal of chat and <UNK> .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['then came syme and next a very old man professor de worms who still kept the chair of <UNK> though every day it was expected that his death would leave it empty .']\n",
      "Corrupted: ['fnen came syme amd naxf a vary old man professot be worms who stlli xept fhe cheir of <UNK> thoogn evaty day lt was expectad tnat nis beeth would leava if empfy .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['one set might recommend their all removing to donwell and leaving hartfield for the john <UNK> and another might <UNK> <UNK> among their servants but yet upon the whole there was no serious objection raised except in one habitation the vicarage .']\n",
      "Corrupted: ['une set might tesomnenb their ali temuvinj to donwell amd leaving hartfield tor fhe jonn <UNK> end anuther mijhf <UNK> <UNK> amomg tneir servents put yef ubom the whoie there was mo sariuos upjectiun ralsed axcabf ln one nabifafion the vicarege .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['there is no king saved by the multitude of an host a mighty man is not delivered by much strength .']\n",
      "Corrupted: ['thare ic no king saveb by the nultitoba of an hucf e nignty nan ls nut delivereb by mucn strangfh .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: [\"lucius who 's that <UNK> luc .\"]\n",
      "Corrupted: [\"iucius who 's that <UNK> iuc .\"]\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['he was at first so much afraid of being late that he did not take notice of the mirth his <UNK> appearance excited in all <UNK> .']\n",
      "Corrupted: ['ha wac at first so mocn atraid uf being late that he dld nut teke notica of fha mitth his <UNK> epbaatenca exsited im ail <UNK> .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['and they fell upon their faces .']\n",
      "Corrupted: ['and they tell opun their feses .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['o my god i cry in the day time but thou <UNK> not and in the night season and am not silent .']\n",
      "Corrupted: ['o nv god i crv in the dav tlme bot thou <UNK> not and im tha nighf ceasom and am not siient .']\n",
      "\n",
      "---\n",
      "\n",
      "Original: ['i almost thought he would sink the ship before the anchor could be got up involuntarily i paused on my <UNK> and told queequeg to do the same thinking of the perils we both ran in starting on the voyage with such a devil for a pilot .']\n",
      "Corrupted: ['i almost thoujhf ne wouid cink the ship befote the ansnor could be jof op inwolumtarily i beused um my <UNK> and told queaqueg to do the same thimkinj of fhe perils we pofn ran ln stattlmg on tna woyaga with such a davil for a pilot .']\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def corrupt_sentence(sentence, probability):\n",
    "    corrupted_sentence = \"\"\n",
    "    for char in sentence:\n",
    "        if char != ' ' and random.random() < probability:\n",
    "            \n",
    "            corrupted_sentence += get_similar_char(char)                 #replace with a similar character\n",
    "        else:\n",
    "            corrupted_sentence += char\n",
    "    return corrupted_sentence\n",
    "\n",
    "def get_similar_char(char):\n",
    "    \n",
    "    # later on maybe use the nlpaug library here \n",
    "    similar_chars = {\n",
    "        'a': 'e',\n",
    "        'b': 'p',\n",
    "        'c': 's',\n",
    "        'd': 'b',\n",
    "        'e': 'a',\n",
    "        'f': 't',\n",
    "        'g': 'j',\n",
    "        'h': 'n',\n",
    "        'i': 'l',\n",
    "        'j': 'g',\n",
    "        'k': 'x',\n",
    "        'l': 'i',\n",
    "        'm': 'n',\n",
    "        'n': 'm',\n",
    "        'o': 'u',\n",
    "        'p': 'b',\n",
    "        'q': 'g',\n",
    "        'r': 't',\n",
    "        's': 'c',\n",
    "        't': 'f',\n",
    "        'u': 'o',\n",
    "        'v': 'w',\n",
    "        'w': 'v',\n",
    "        'x': 'k',\n",
    "        'y': 'v',\n",
    "        'z': 's',\n",
    "    }\n",
    "\n",
    "    \n",
    "    return similar_chars.get(char, char)                            #return a randomly chosen character\n",
    "\n",
    "'''\n",
    "test_corpus = [\"he plays football\",\n",
    "               \"he plais footbal\",\n",
    "               \"she enjoys good football\",\n",
    "               \"she plays good music\",\n",
    "               \"he prays to god\",\n",
    "               \"please buy me the other ball\",\n",
    "               \"he pleases the other players by playing good football\",\n",
    "               \"he plys god ftball\"]\n",
    "\n",
    "'''\n",
    "probability = 0.2                                        #probability of character replacement\n",
    "\n",
    "\n",
    "     \n",
    "corrupted_corpus = [[corrupt_sentence(word, probability) for word in sentence] for sentence in UNK_sentences[1:50]]   #generate the corrupted corpus\n",
    "\n",
    "for original, corrupted in zip(UNK_sentences[1:50], corrupted_corpus):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Corrupted: {corrupted}\")\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bde09d0-4ad6-4a34-a17a-46e1a6e0bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "tweet_wt = TweetTokenizer()\n",
    "tokenized = [tweet_wt.tokenize(' '.join(sentence)) for sentence in UNK_sentences[:50]]  # Get the first 50 sentences\n",
    "\n",
    "model = BigramModel(alpha=0.01)\n",
    "model.fit(tokenized)                                # model is fitted with the correct and tokenized words\n",
    "\n",
    "corrupted_tokenized = [tweet_wt.tokenize(sentence) for sentence_list in corrupted_corpus for sentence in sentence_list] #tokenize the corrupted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6779be16-f60e-4fbf-a336-c0e2dad91458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentences: [['he seemed to want to be acquainted with her .'], ['i am almost ashamed to say it .'], ['it was not in her nature .'], ['and one of the four beasts gave unto the seven angels seven golden <UNK> full of the wrath of god who liveth for ever and ever .'], ['for brethren ye have been called unto liberty only use not liberty for an occasion to the flesh but by love serve one another .']]\n",
      "\n",
      "\n",
      "Corrupted(wrong) sentences: [['ha saamed to wamt to be ecqoeinfed with ner .'], ['i am alnoct acnamed to say it .'], ['it wac not ln her nature .'], ['and ome of tha fout beacfs gave unto the seven angels sewen jolben <UNK> fuii uf fne wrath of gob wnu ilvatn fut ewer and ever .'], ['for brethren va have peen callad ontu llbetty omly ose not llperty fot an uscasion fo tha flech but by lova serve una another .']]\n",
      "\n",
      "\n",
      "Final result (corrected sentences): [['<start>', 'therefore', 'our', 'queene', 'th', \"'\", 's', 'name', 'do', 'some', 'time', 'or', 'sheep', 'and', 'teach', '.', 'lawrence', 'the', 'kisses', 'of', 'his'], ['<start>', 'therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister'], ['<start>', 'therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister'], ['<start>', 'therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", 's', 'name', 'do', \"n't\", 'know', 'what', 'attorney'], ['<start>', 'therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister', 'now', 'our', 'sometimes', 'sister']]\n"
     ]
    }
   ],
   "source": [
    "corrected = []\n",
    "corrector = BigramSpellCorrector(model, lamda1=0.5, lamda2=-0.5)\n",
    "for sent in corrupted_tokenized:\n",
    "  output_seq = corrector.spell_correct(original_tokenized_sentence=sent, max_depth = 20, beam_width = 3)  #give the corrupt sentences to spell correct\n",
    "  corrected.append(output_seq)\n",
    "    \n",
    "print('Original sentences:', UNK_sentences[6:11])\n",
    "print('\\n')\n",
    "print('Corrupted(wrong) sentences:', corrupted_corpus[5:10])\n",
    "print('\\n')\n",
    "print('Final result (corrected sentences):', corrected[5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadeb1d-ed6d-4c29-9dbe-73cd4f88f7cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth', 'for', 'thy', 'love', 'is', 'better', 'than', 'wine', '.']\n",
      "Original sentence:  ['let']\n",
      "Prediction:  him\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him']\n",
      "Prediction:  kiss\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss']\n",
      "Prediction:  me\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me']\n",
      "Prediction:  with\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with']\n",
      "Prediction:  long\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the']\n",
      "Prediction:  lord\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses']\n",
      "Prediction:  of\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of']\n",
      "Prediction:  his\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his']\n",
      "Prediction:  death\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth']\n",
      "Prediction:  for\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth', 'for']\n",
      "Prediction:  thy\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth', 'for', 'thy']\n",
      "Prediction:  love\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth', 'for', 'thy', 'love']\n",
      "Prediction:  serve\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth', 'for', 'thy', 'love', 'is']\n",
      "Prediction:  mine\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth', 'for', 'thy', 'love', 'is', 'better']\n",
      "Prediction:  than\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth', 'for', 'thy', 'love', 'is', 'better', 'than']\n",
      "Prediction:  wine\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth', 'for', 'thy', 'love', 'is', 'better', 'than', 'wine']\n",
      "Prediction:  .\n",
      "\n",
      "\n",
      "Original sentence:  ['let', 'him', 'kiss', 'me', 'with', 'the', 'kisses', 'of', 'his', 'mouth', 'for', 'thy', 'love', 'is', 'better', 'than', 'wine', '.']\n",
      "Prediction:  <end>\n",
      "\n",
      "\n",
      "Original sentence ['these', 'things', 'command', 'and', 'teach', '.']\n",
      "Original sentence:  ['these']\n",
      "Prediction:  things\n",
      "\n",
      "\n",
      "Original sentence:  ['these', 'things']\n",
      "Prediction:  command\n",
      "\n",
      "\n",
      "Original sentence:  ['these', 'things', 'command']\n",
      "Prediction:  and\n",
      "\n",
      "\n",
      "Original sentence:  ['these', 'things', 'command', 'and']\n",
      "Prediction:  they\n",
      "\n",
      "\n",
      "Original sentence:  ['these', 'things', 'command', 'and', 'teach']\n",
      "Prediction:  .\n",
      "\n",
      "\n",
      "Original sentence:  ['these', 'things', 'command', 'and', 'teach', '.']\n",
      "Prediction:  <end>\n",
      "\n",
      "\n",
      "Original sentence ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with', 'this', '<UNK>', 'along', 'for', 'all', 'our', '<UNK>', '.']\n",
      "Original sentence:  ['therefore']\n",
      "Prediction:  our\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our']\n",
      "Prediction:  sometimes\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes']\n",
      "Prediction:  sister\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister']\n",
      "Prediction:  now\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now']\n",
      "Prediction:  eli\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our']\n",
      "Prediction:  sometimes\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene']\n",
      "Prediction:  th\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th']\n",
      "Prediction:  '\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\"]\n",
      "Prediction:  s\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of']\n",
      "Prediction:  his\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this']\n",
      "Prediction:  warlike\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike']\n",
      "Prediction:  state\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state']\n",
      "Prediction:  haue\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue']\n",
      "Prediction:  we\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we']\n",
      "Prediction:  must\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as']\n",
      "Prediction:  natural\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with']\n",
      "Prediction:  long\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a']\n",
      "Prediction:  matter\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with']\n",
      "Prediction:  long\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one']\n",
      "Prediction:  dropping\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and']\n",
      "Prediction:  they\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one']\n",
      "Prediction:  dropping\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping']\n",
      "Prediction:  eye\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye']\n",
      "Prediction:  with\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with']\n",
      "Prediction:  long\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth']\n",
      "Prediction:  his\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in']\n",
      "Prediction:  marriage\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and']\n",
      "Prediction:  they\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with']\n",
      "Prediction:  long\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in']\n",
      "Prediction:  marriage\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage']\n",
      "Prediction:  in\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in']\n",
      "Prediction:  marriage\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale']\n",
      "Prediction:  let\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight']\n",
      "Prediction:  and\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and']\n",
      "Prediction:  they\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken']\n",
      "Prediction:  to\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to']\n",
      "Prediction:  say\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife']\n",
      "Prediction:  nor\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor']\n",
      "Prediction:  haue\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue']\n",
      "Prediction:  we\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we']\n",
      "Prediction:  must\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\"]\n",
      "Prediction:  s\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd']\n",
      "Prediction:  your\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your']\n",
      "Prediction:  hands\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better']\n",
      "Prediction:  than\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which']\n",
      "Prediction:  haue\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue']\n",
      "Prediction:  we\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely']\n",
      "Prediction:  gone\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone']\n",
      "Prediction:  with\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with']\n",
      "Prediction:  long\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with', 'this']\n",
      "Prediction:  warlike\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with', 'this', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with', 'this', '<UNK>', 'along']\n",
      "Prediction:  for\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with', 'this', '<UNK>', 'along', 'for']\n",
      "Prediction:  thy\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with', 'this', '<UNK>', 'along', 'for', 'all']\n",
      "Prediction:  removing\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with', 'this', '<UNK>', 'along', 'for', 'all', 'our']\n",
      "Prediction:  sometimes\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with', 'this', '<UNK>', 'along', 'for', 'all', 'our', '<UNK>']\n",
      "Prediction:  scale\n",
      "\n",
      "\n",
      "Original sentence:  ['therefore', 'our', 'sometimes', 'sister', 'now', 'our', 'queene', 'th', \"'\", '<UNK>', '<UNK>', 'of', 'this', 'warlike', 'state', 'haue', 'we', 'as', '<UNK>', 'with', 'a', '<UNK>', '<UNK>', 'with', 'one', '<UNK>', 'and', 'one', 'dropping', 'eye', 'with', 'mirth', 'in', '<UNK>', 'and', 'with', '<UNK>', 'in', 'marriage', 'in', '<UNK>', 'scale', '<UNK>', 'delight', 'and', '<UNK>', 'taken', 'to', 'wife', 'nor', 'haue', 'we', '<UNK>', '<UNK>', \"'\", 'd', 'your', 'better', '<UNK>', 'which', 'haue', 'freely', 'gone', 'with', 'this', '<UNK>', 'along', 'for', 'all', 'our', '<UNK>', '.']\n",
      "Prediction:  <end>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You need to give incomplete sentence for autocorrect. Right now it just predicts the end of the sentences after the '.'\n",
    "# Try a while loop until END_TOKEN is the output maybe\n",
    "\n",
    "#Check how the auto correction works\n",
    "predicted = []\n",
    "for sent in tokenized[:3]:\n",
    "    print(\"Original sentence\", sent)\n",
    "    for i, token in enumerate(sent):                     #try all possible combinations within the sentence\n",
    "        partial_sent = sent[:i+1]\n",
    "        if END_TOKEN in partial_sent:\n",
    "            break\n",
    "        pred = model.predict(tokenized_sentence = partial_sent)\n",
    "        print(\"Original sentence: \", partial_sent)\n",
    "        print(\"Prediction: \", pred)\n",
    "        predicted.append(pred)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399e286-72a6-4202-9b68-a5ccd53ec5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import cer, wer\n",
    "\n",
    "\n",
    "count = 0\n",
    "sum_cer = 0\n",
    "sum_wer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2059fe-2d2d-4be3-a6f9-8c8c722a7eaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m corrected_sentence \u001b[38;5;129;01min\u001b[39;00m corrected:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(corrected_sentence)):\n\u001b[0;32m----> 3\u001b[0m         token_k \u001b[38;5;241m=\u001b[39m START_TOKEN \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m tokenized[i][i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m         token_j \u001b[38;5;241m=\u001b[39m corrected_sentence[i]\n\u001b[1;32m      5\u001b[0m         sum_cer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cer(token_k, token_j)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for corrected_sentence in corrected:\n",
    "    for i in range(len(corrected_sentence)):\n",
    "        token_k = START_TOKEN if i == 0 else tokenized[i][i - 1]\n",
    "        token_j = corrected_sentence[i]\n",
    "        sum_cer += cer(token_k, token_j)\n",
    "        sum_wer += wer(token_k, token_j)\n",
    "        count += 1\n",
    "        \n",
    "avg_cer = sum_cer/count\n",
    "avg_wer = sum_wer/count\n",
    "\n",
    "print(f'Avg cer = {avg_cer}')\n",
    "print(f'Avg wer = {avg_wer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40890cc-c615-4a65-9f3a-d7ef513fdf66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
