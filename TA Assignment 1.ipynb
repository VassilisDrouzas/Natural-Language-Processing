{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6543a2dd-779a-4643-a6bd-ffa5c1ac4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dimits/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to /home/dimits/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6abedf4-87d7-4d30-b058-2a4a4f542aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spell_correction import BigramSpellCorrector, TrigramSpellCorrector\n",
    "from src.autocomplete import BigramModel, START_TOKEN, END_TOKEN, UNKNOWN_TOKEN, TrigramModel, BaseNgramModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b74da53-b6ee-490f-8ebc-6256aea039b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg_corpus = nltk.corpus.gutenberg.fileids()                                 #Get all the files\n",
    "gutenberg_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b16673-a350-459d-8fd3-0c3c990d9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died t\n"
     ]
    }
   ],
   "source": [
    "combined_text = \"\"             \n",
    "for file_id in gutenberg_corpus:                                        # Combine the text from all files\n",
    "    combined_text += nltk.corpus.gutenberg.raw(file_id)\n",
    "\n",
    "print(combined_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9cd0930-d3ab-4bbc-82e8-71de27c63468",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = combined_text.lower()                              #Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c6b392-464d-4c08-b16b-acaabbea6e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[emma by jane austen 1816]\\n\\nvolume i\\n\\nchapter i\\n\\n\\nemma woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.\\n\\nshe was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.  her mother\\nhad died t\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e4f3c82-7a8e-42d5-b04b-4160fe689891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_chars(text):\n",
    "   text = text.replace('[', '')\n",
    "   text = text.replace(']', '')\n",
    "   text = text.replace('\\n', ' ')\n",
    "   text = re.sub(r'[^a-zA-z.?!\\']', ' ', text)                     #Remove these characters   \n",
    "\n",
    "   return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb081710-1d7d-4c53-b85d-acd0a9528c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"emma by jane austen       volume i  chapter i   emma woodhouse  handsome  clever  and rich  with a comfortable home and happy disposition  seemed to unite some of the best blessings of existence  and had lived nearly twenty one years in the world with very little to distress or vex her.  she was the youngest of the two daughters of a most affectionate  indulgent father  and had  in consequence of her sister's marriage  been mistress of his house from a very early period.  her mother had died too\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text = remove_special_chars(combined_text)\n",
    "combined_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f25b00-f68a-4ad1-893d-f4e27e93698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2119883"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_text.split())                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7fcb110-bdda-41dc-8850-fae413272efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11793056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_text)                             # How many characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4da70b8-ff85-4fb0-b23f-df115f397805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"n the sea  the universe  the stars there in the     heavens   urging slowly  surely forward  forming endless  and waiting ever more  forever more behind.       good bye my fancy!  good bye my fancy! farewell dear mate  dear love! i'm going away  i know not where  or to what fortune  or whether i may ever see you again  so good bye my fancy.  now for my last  let me look back a moment  the slower fainter ticking of the clock is in me  exit  nightfall  and soon the heart thud stopping.  long have we lived  joy'd  caress'd together  delightful!  now separation  good bye my fancy.  yet let me not be too hasty  long indeed have we lived  slept  filter'd  become really blended     into one  then if we die we die together   yes  we'll remain one   if we go anywhere we'll go together to meet what happens  may be we'll be better off and blither  and learn something  may be it is yourself now really ushering me to the true songs   who     knows?  may be it is you the mortal knob really undoing  turning  so now finally  good bye  and hail! my fancy.  \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text[11792000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d6b0a3-9064-49b3-a16d-d527cddefe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "    sentences = nltk.sent_tokenize(''.join(text))                  #Get the sentences\n",
    "    return sentences     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f90469b6-7286-4434-a88c-2668f0ccd4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96282\n",
      "her mother had died too long ago for her to have more than an indistinct remembrance of her caresses  and her place had been supplied by an excellent woman as governess  who had fallen little short of a mother in affection.\n",
      "i hardly understand you   replied the scientist  with a cold intensity of manner.\n"
     ]
    }
   ],
   "source": [
    "sentences = tokenize_sentences(combined_text) \n",
    "print(len(sentences))    \n",
    "print(sentences[2])  \n",
    "print(sentences[57649])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaf01dde-77eb-44b7-a099-fffcab33cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3036efe1-6ba2-4a96-9b1d-fae699e453d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2235498\n",
      "austen\n",
      "fancy\n"
     ]
    }
   ],
   "source": [
    "words = tokenize_words(combined_text)\n",
    "print(len(words))\n",
    "print(words[3])\n",
    "print(words[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f56cfa79-f981-43fb-b6c1-1cef34040840",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = []                                    #list of all the words of sentences\n",
    "for f in sentences:\n",
    "    words_list.append(tokenize_words(f))                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01930b98-39d1-4eec-9275-5b154687c41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96282"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ba378be-6fa5-440d-be37-b8ef51dfbab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she\n",
      "was\n",
      "the\n",
      "youngest\n",
      "of\n",
      "the\n",
      "two\n",
      "daughters\n",
      "of\n",
      "a\n",
      "most\n",
      "affectionate\n",
      "indulgent\n",
      "father\n",
      "and\n",
      "had\n",
      "in\n",
      "consequence\n",
      "of\n",
      "her\n",
      "sister\n",
      "'s\n",
      "marriage\n",
      "been\n",
      "mistress\n",
      "of\n",
      "his\n",
      "house\n",
      "from\n",
      "a\n",
      "very\n",
      "early\n",
      "period\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in words_list[1]:                     # all the words of the second sentence\n",
    "    print(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "013c921e-362d-40b9-aabb-474c4b489be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "random.shuffle(words_list)\n",
    "train_len = math.floor(0.6 * len(words_list))                      #Training set length(60%)\n",
    "dev_len = math.floor(0.2 * len(words_list))                        #Development set length (20%)\n",
    "test_len = math.floor(0.2 * len(words_list))                       #Test set length (20%)\n",
    "\n",
    "training_set = []\n",
    "development_set = []\n",
    "test_set = []\n",
    "\n",
    "for content in words_list[0:train_len]:\n",
    "    training_set.append(content)\n",
    "    \n",
    "for content in words_list[train_len: train_len + dev_len]:\n",
    "    development_set.append(content)\n",
    "\n",
    "for content in words_list[train_len + dev_len:]:\n",
    "    test_set.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "941fd203-6132-40db-a596-5b8ae9dd43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "def _calc_ngrams(all_corpus: list[str], ngram: int) -> Counter:\n",
    "    \"\"\"\n",
    "    Process a tokenized sentence into a list of ngrams.\n",
    "    :param all_corpus: a list of all the corpus words\n",
    "    :param ngram: whether the ngrams will be unigrams, bigrams etc\n",
    "    :return: the counter of either unigram, bigram or trigram\n",
    "    \"\"\"\n",
    "    unigram_counter = Counter()\n",
    "    bigram_counter = Counter()\n",
    "    trigram_counter = Counter()\n",
    "     \n",
    "    \n",
    "\n",
    "    if ngram == 1 :\n",
    "        for sentence in all_corpus:\n",
    "             grams = [gram for gram in ngrams(sentence, ngram, pad_left=True, pad_right=True,\n",
    "                                    left_pad_symbol=START_TOKEN, right_pad_symbol=END_TOKEN)]\n",
    "             unigram_counter.update(grams)\n",
    "        return unigram_counter\n",
    "        \n",
    "    elif ngram == 2:\n",
    "        for sentence in all_corpus:\n",
    "             grams = [gram for gram in ngrams(sentence, ngram, pad_left=True, pad_right=True,\n",
    "                                    left_pad_symbol=START_TOKEN, right_pad_symbol=END_TOKEN)]\n",
    "             bigram_counter.update(grams)\n",
    "        return bigram_counter\n",
    "        \n",
    "    elif ngram == 3:\n",
    "        for sentence in all_corpus:\n",
    "             grams = [gram for gram in ngrams(sentence, ngram, pad_left=True, pad_right=True,\n",
    "                                    left_pad_symbol=START_TOKEN, right_pad_symbol=END_TOKEN)]\n",
    "             trigram_counter.update(grams)\n",
    "        return trigram_counter\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dd7c6b6-b1d5-44c1-9308-867c7eb13fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_OOV_words_train(all_corpus):\n",
    "    unigram_counter = _calc_ngrams(all_corpus,1)\n",
    "    OOV_words = {}\n",
    "\n",
    "    for k, v in unigram_counter.items():\n",
    "        if v < 10:\n",
    "            key = k[0]\n",
    "            # README: Use the symbol UNKOWN_TOKEN else the model will think it's a word\n",
    "            OOV_words[key] = UNKNOWN_TOKEN                 #set the word to \"UNK\"\n",
    "\n",
    "    replaced_corpus = []                          #the original corpus having the OOV words replaced by 'UNK'\n",
    "    for sentence in all_corpus:\n",
    "        clean_sentence = []\n",
    "    \n",
    "        for word in sentence:\n",
    "            clean_sentence.append(OOV_words.get(word, word))\n",
    "    \n",
    "        replaced_corpus.append(clean_sentence)\n",
    "\n",
    "\n",
    "    vocabulary = []\n",
    "\n",
    "    for key in unigram_counter.keys():        #Iterate the unigram counter\n",
    "        word = key[0]                         #get the word\n",
    "        if word not in OOV_words:\n",
    "            vocabulary.append(word)\n",
    "\n",
    "    vocabulary = set(vocabulary)              #Keep unique words\n",
    "    return vocabulary, replaced_corpus, OOV_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92f61c51-81f4-4a80-81b1-769dbb9bd058",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, train_corpus, OOV_words = replace_OOV_words_train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "323891dd-f0bc-4454-9d24-bac8427d276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_OOV_words_test(all_corpus, vocabulary, oov_words):\n",
    "    \n",
    "    replaced_corpus = []\n",
    "    for sentence in all_corpus:\n",
    "        updated_sent = []\n",
    "\n",
    "        for word in sentence:\n",
    "            if (word not in vocabulary) or (word in oov_words):\n",
    "                updated_sent.append(UNKNOWN_TOKEN)\n",
    "            else:\n",
    "                updated_sent.append(word)\n",
    "                \n",
    "    replaced_corpus.append(updated_sent)\n",
    "    return replaced_corpus   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0eab7ab-2171-43a8-90ef-ef49e5335b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "development_set = replace_OOV_words_test(development_set, vocabulary, OOV_words)\n",
    "test_set = replace_OOV_words_test(test_set, vocabulary, OOV_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5de1392-390e-47ed-8202-93ad4f1248e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length:  7376\n",
      "Unigram's 20 most common words:\n",
      "(('the',), 80943)\n",
      "(('and',), 57872)\n",
      "(('.',), 46409)\n",
      "(('of',), 43107)\n",
      "(('to',), 29214)\n",
      "(('a',), 20204)\n",
      "(('in',), 20121)\n",
      "(('i',), 18217)\n",
      "(('that',), 17358)\n",
      "(('he',), 15669)\n",
      "(('it',), 13414)\n",
      "(('his',), 12995)\n",
      "(('for',), 11860)\n",
      "(('was',), 11348)\n",
      "(('not',), 11023)\n",
      "(('with',), 10654)\n",
      "(('is',), 10099)\n",
      "(('be',), 9843)\n",
      "(('you',), 9837)\n",
      "(('as',), 8873)\n",
      "\n",
      "\n",
      "Bigram's 20 most common words:\n",
      "(('.', '<end>'), 46169)\n",
      "(('of', 'the'), 11603)\n",
      "(('<start>', 'and'), 8091)\n",
      "(('in', 'the'), 6116)\n",
      "(('?', '<end>'), 6090)\n",
      "(('and', 'the'), 5421)\n",
      "(('!', '<end>'), 4927)\n",
      "(('the', 'lord'), 4269)\n",
      "(('<start>', 'i'), 3479)\n",
      "(('to', 'the'), 3262)\n",
      "(('<start>', 'the'), 3080)\n",
      "(('<start>', 'but'), 2427)\n",
      "(('all', 'the'), 2224)\n",
      "(('and', 'he'), 2158)\n",
      "(('to', 'be'), 2147)\n",
      "(('<start>', 'he'), 2091)\n",
      "(('for', 'the'), 1825)\n",
      "(('shall', 'be'), 1722)\n",
      "(('it', 'was'), 1713)\n",
      "(('on', 'the'), 1711)\n",
      "\n",
      "\n",
      "Trigram's 20 most common words:\n",
      "(('.', '<end>', '<end>'), 46169)\n",
      "(('<start>', '<start>', 'and'), 8091)\n",
      "(('?', '<end>', '<end>'), 6090)\n",
      "(('!', '<end>', '<end>'), 4927)\n",
      "(('<start>', '<start>', 'i'), 3479)\n",
      "(('<start>', '<start>', 'the'), 3080)\n",
      "(('<start>', '<start>', 'but'), 2427)\n",
      "(('<start>', '<start>', 'he'), 2091)\n",
      "(('<start>', '<start>', 'for'), 1375)\n",
      "(('<start>', '<start>', 'it'), 1324)\n",
      "(('<start>', 'and', 'the'), 1259)\n",
      "(('<start>', '<start>', 'then'), 1149)\n",
      "(('of', 'the', 'lord'), 1034)\n",
      "(('him', '.', '<end>'), 970)\n",
      "(('<start>', '<start>', 'she'), 969)\n",
      "(('<start>', 'and', 'he'), 947)\n",
      "(('it', '.', '<end>'), 937)\n",
      "(('the', 'son', 'of'), 928)\n",
      "(('<start>', '<start>', 'you'), 872)\n",
      "(('the', 'children', 'of'), 829)\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(vocabulary)\n",
    "print (\"Vocabulary length: \", vocab_len)\n",
    "\n",
    "print(\"Unigram's 20 most common words:\")\n",
    "unigram_top_20 = _calc_ngrams(training_set, 1).most_common(20)\n",
    "for gram in unigram_top_20:\n",
    "    print(gram)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Bigram's 20 most common words:\")\n",
    "bigram_top_20 = _calc_ngrams(training_set,2).most_common(20)\n",
    "for gram in bigram_top_20:\n",
    "    print(gram)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Trigram's 20 most common words:\")\n",
    "trigram_top_20 = _calc_ngrams(training_set,3).most_common(20)\n",
    "for gram in trigram_top_20:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361a4ed-2f57-4f4b-a61f-6227992bacf8",
   "metadata": {},
   "source": [
    "(ii). First step: Tune Î± (alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8740d-4f21-49fc-abca-319b07e97926",
   "metadata": {},
   "source": [
    "##  Calculate bi-gram probability\n",
    "\n",
    "### $ P(w_2|w_1) = \\frac{C(w_1,w_2) + \\alpha}{C(w_1) + \\alpha \\cdot|V|} $\n",
    "\n",
    "* $ C(w_1,w_2) $ : bigram count\n",
    "* $ C(w_1) $ : unigram count\n",
    "* $ 0 \\leq\\alpha \\leq1 $ :  smoothing hyper-parameter\n",
    "* |V|: vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2fbe4-0a4b-4a7d-bb1b-5daad8b369c6",
   "metadata": {},
   "source": [
    "## Bi-gram LM Cross entropy & perplexity\n",
    "\n",
    "* $ CrossEntropy = -\\frac{1}{N}\\sum^{bigrams}{log_2(P(w_2|w_1))} $\n",
    " * N: Number of bigrams\n",
    "* $ Perplexity = 2^{H(p)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea916643-39d0-4b00-830d-e294299450fe",
   "metadata": {},
   "source": [
    "## Tri-gram LM Cross entropy & perplexity\n",
    "\n",
    "### $ P(w_3|w_1,w_2) = \\frac{C(w_1,w_2,w_3) + \\alpha}{C(w_1,w_2) + \\alpha \\cdot |V|} $\n",
    "\n",
    "* $ C(w_1,w_2,w_3) $ : trigram count\n",
    "* $ C(w_1,w_2) $ : bigram count\n",
    "* $ 0 \\leq\\alpha \\leq1 $ :  smoothing hyper-parameter\n",
    "* |V|: vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97dd4ed9-b159-469c-8686-ce887789cc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_entropy(model: BaseNgramModel, dataset: list[list[str]]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy of a language model on a given dataset.\n",
    "    \n",
    "    Cross-entropy measures how well the language model predicts the given dataset.\n",
    "    Lower cross-entropy indicates better model performance.\n",
    "    \n",
    "    :param model: The n-gram language model for which cross-entropy is calculated.\n",
    "    :param dataset: The dataset as a list of tokenized sentences, where each sentence is a list of strings.\n",
    "    :return: The cross-entropy score as a float.\n",
    "             Lower values indicate better performance in predicting the dataset.\n",
    "    \"\"\"\n",
    "    # since la place smoothing is only involved during inference\n",
    "    # we don't need to refit the model\n",
    "    sum_prob = 0\n",
    "    word_count = 0\n",
    "    \n",
    "    for sentence in dataset:       \n",
    "        # since this is a full sentence we manually append the end token\n",
    "        sentence += [END_TOKEN]\n",
    "        \n",
    "        # take into account only the END_TOKEN since START token probs are not computed\n",
    "        word_count += len(sentence)\n",
    "        \n",
    "        # get sentence probability\n",
    "        sum_prob += bi_model.sentence_proba(sentence) \n",
    "    \n",
    "    # do we need to logarithmize this again?\n",
    "    return - sum_prob / word_count\n",
    "\n",
    "\n",
    "def perplexity(cross_entropy: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate perplexity from cross-entropy.\n",
    "    \n",
    "    Perplexity is a measure of how well the language model predicts the given dataset.\n",
    "    A model with a perplexity of k, has approximately a 1/k chance of correctly predicting the next word in a sentence.\n",
    "    \n",
    "    :param cross_entropy: The cross-entropy score calculated for a language model on a dataset.\n",
    "    :return: The perplexity score as a float.\n",
    "             Lower values indicate better performance in predicting the dataset.\n",
    "    \"\"\"\n",
    "    return 2**cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17f41bba-770b-40a2-8f26-85695431ab9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-gram model Cross Entropy:  6.217716632120343\n",
      "Bi-gram model Perplexity:  74.42506297645622\n"
     ]
    }
   ],
   "source": [
    "bi_model = BigramModel(alpha=0.001)\n",
    "bi_model.fit(train_corpus)\n",
    "\n",
    "bi_hc = cross_entropy(bi_model, train_corpus)\n",
    "print(\"Bi-gram model Cross Entropy: \", bi_hc)\n",
    "print(\"Bi-gram model Perplexity: \", perplexity(bi_hc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19423c60-91e1-42d6-98a2-2a902ae7a156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tri-gram model Cross Entropy:  6.988207017115861\n",
      "Tri-gram model Perplexity:  126.9579578476758\n"
     ]
    }
   ],
   "source": [
    "tri_model = TrigramModel(alpha=0.001)\n",
    "tri_model.fit(train_corpus)\n",
    "\n",
    "tri_hc = cross_entropy(tri_model, train_corpus)\n",
    "print(\"Tri-gram model Cross Entropy: \", tri_hc)\n",
    "print(\"Tri-gram model Perplexity: \", perplexity(tri_hc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc76f7f8-4f0a-4a74-a78b-cc806cb28b91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha after tuning:  1.0\n",
      "Cross Entropy: 2.827\n",
      "perplexity: 7.097\n"
     ]
    }
   ],
   "source": [
    "HC = []\n",
    "perplexity = []\n",
    "\n",
    "min_entropy = 10000\n",
    "min_index = 0\n",
    "alpha_values = np.linspace(0.001, 1)\n",
    "best_alpha_bigram = 0\n",
    "\n",
    "bi_model = BigramModel(alpha=0.001)\n",
    "bi_model.fit(train_corpus)\n",
    "\n",
    "for i, alpha in enumerate(alpha_values):\n",
    "    # since la place smoothing is only involved during inference\n",
    "    # we don't need to refit the model\n",
    "    bi_model.alpha = alpha\n",
    "    \n",
    "    sum_prob = 0\n",
    "    bi_count = 0\n",
    "    for sentence in development_set:\n",
    "        bi_count += len(sentence)\n",
    "        \n",
    "        # since this is a full sentence we manually append the end token\n",
    "        sentence += [END_TOKEN]\n",
    "        \n",
    "        # get sentence probability\n",
    "        sum_prob = bi_model.sentence_proba(sentence) \n",
    "\n",
    "    HC.append(-sum_prob / bi_count)\n",
    "    perplexity.append(math.pow(2, -sum_prob / bi_count))\n",
    "    if ((-sum_prob / bi_count) < min_entropy ):\n",
    "        min_entropy = -sum_prob / bi_count\n",
    "        min_index = i\n",
    "        best_alpha_bigram = alpha\n",
    "\n",
    "print(\"Best alpha after tuning: \", best_alpha_bigram)\n",
    "print(\"Cross Entropy: {0:.3f}\".format(HC[min_index]))\n",
    "print(\"perplexity: {0:.3f}\".format(perplexity[min_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62e2d9-1ea3-4935-9d0b-735e7c37c21e",
   "metadata": {},
   "source": [
    "Now, let's test the performance in the test set, after having defined the optimal alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75603bb8-21ee-469b-bf12-85665e9094b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 5\n",
    "beam_width = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a8c72-e1a8-44dc-8338-266bbf419ee2",
   "metadata": {},
   "source": [
    "v. Create a fake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c7a057e-c101-4158-a412-39c85dd6ba66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: emma by jane austen       volume i  chapter i   emma woodhouse  handsome  clever  and rich  with a comfortable home and happy disposition  seemed to unite some of the best blessings of existence  and had lived nearly twenty one years in the world with very little to distress or vex her.\n",
      "Corrupted: she was fhe youngest of the two baughters of a most affectionete  indulgent father  and hed  in cunsequence uf her sisfet's marriage  been nistress of his house from a very early period.\n",
      "\n",
      "---\n",
      "\n",
      "Original: she was the youngest of the two daughters of a most affectionate  indulgent father  and had  in consequence of her sister's marriage  been mistress of his house from a very early period.\n",
      "Corrupted: her motner had dieb too long ago for her fo have more fhan an indistincf remembrance uf her caresces  and her blace hed been supplied by an axcellent woman as govetnecs  whu had fallen little shorf of a mutner in affection.\n",
      "\n",
      "---\n",
      "\n",
      "Original: her mother had died too long ago for her to have more than an indistinct remembrance of her caresses  and her place had been supplied by an excellent woman as governess  who had fallen little short of a mother in affection.\n",
      "Corrupted: cixteen years had miss tavlor been in mr. woodhouse's tamiiy  lesc as a guvermess than a friand  very fond uf puth daughtets  but barticularly ut emma.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def corrupt_sentence(sentence, probability):\n",
    "    corrupted_sentence = \"\"\n",
    "    for char in sentence:\n",
    "        if char != ' ' and random.random() < probability:\n",
    "            \n",
    "            corrupted_sentence += get_similar_char(char)                 #replace with a similar character\n",
    "        else:\n",
    "            corrupted_sentence += char\n",
    "    return corrupted_sentence\n",
    "\n",
    "def get_similar_char(char):\n",
    "    \n",
    "    # later on maybe use the nlpaug library here \n",
    "    similar_chars = {\n",
    "        'a': 'e',\n",
    "        'b': 'p',\n",
    "        'c': 's',\n",
    "        'd': 'b',\n",
    "        'e': 'a',\n",
    "        'f': 't',\n",
    "        'g': 'j',\n",
    "        'h': 'n',\n",
    "        'i': 'l',\n",
    "        'j': 'g',\n",
    "        'k': 'x',\n",
    "        'l': 'i',\n",
    "        'm': 'n',\n",
    "        'n': 'm',\n",
    "        'o': 'u',\n",
    "        'p': 'b',\n",
    "        'q': 'g',\n",
    "        'r': 't',\n",
    "        's': 'c',\n",
    "        't': 'f',\n",
    "        'u': 'o',\n",
    "        'v': 'w',\n",
    "        'w': 'v',\n",
    "        'x': 'k',\n",
    "        'y': 'v',\n",
    "        'z': 's',\n",
    "    }\n",
    "\n",
    "    \n",
    "    return similar_chars.get(char, char)                            #return a randomly chosen character\n",
    "\n",
    "'''\n",
    "test_corpus = [\"he plays football\",\n",
    "               \"he plais footbal\",\n",
    "               \"she enjoys good football\",\n",
    "               \"she plays good music\",\n",
    "               \"he prays to god\",\n",
    "               \"please buy me the other ball\",\n",
    "               \"he pleases the other players by playing good football\",\n",
    "               \"he plys god ftball\"]\n",
    "\n",
    "'''\n",
    "probability = 0.1                                         #probability of character replacement\n",
    "\n",
    "\n",
    "corrupted_corpus = [corrupt_sentence(sentence, probability) for sentence in sentences[1:50]]          #generate the corrupted corpus\n",
    "\n",
    "\n",
    "for original, corrupted in zip(sentences[:3], corrupted_corpus[:3]):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Corrupted: {corrupted}\")\n",
    "    print(\"\\n---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74fc0e10-f718-42e4-9f04-86bcf1fcec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "tweet_wt = TweetTokenizer()\n",
    "tokenized = [tweet_wt.tokenize(sentence) for sentence in sentences[1:50]]   #Get the first 50 sentences\n",
    "\n",
    "model = BigramModel(alpha=0.01)\n",
    "model.fit(tokenized)                                # model is fitted with the correct and tokenized words\n",
    "\n",
    "corrupted_tokenized = [tweet_wt.tokenize(sentence) for sentence in corrupted_corpus]             # tokenize the corrupted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6779be16-f60e-4fbf-a336-c0e2dad91458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentences: [\"she was the youngest of the two daughters of a most affectionate  indulgent father  and had  in consequence of her sister's marriage  been mistress of his house from a very early period.\", 'her mother had died too long ago for her to have more than an indistinct remembrance of her caresses  and her place had been supplied by an excellent woman as governess  who had fallen little short of a mother in affection.', \"sixteen years had miss taylor been in mr. woodhouse's family  less as a governess than a friend  very fond of both daughters  but particularly of emma.\"]\n",
      "\n",
      "\n",
      "Corrupted(wrong) sentences: [\"she was fhe youngest of the two baughters of a most affectionete  indulgent father  and hed  in cunsequence uf her sisfet's marriage  been nistress of his house from a very early period.\", 'her motner had dieb too long ago for her fo have more fhan an indistincf remembrance uf her caresces  and her blace hed been supplied by an axcellent woman as govetnecs  whu had fallen little shorf of a mutner in affection.', \"cixteen years had miss tavlor been in mr. woodhouse's tamiiy  lesc as a guvermess than a friand  very fond uf puth daughtets  but barticularly ut emma.\"]\n",
      "\n",
      "\n",
      "Final result (corrected sentences): [['<start>', 'matrimony', 'being', 'settled', 'in', 'conversation', 'rational', 'or', 'body', 'that', 'other', 'people', 'could', 'not', 'have', 'recommended', 'him', 'from', 'them', 'hating', 'change'], ['<start>', 'i', 'cannot', 'agree', 'with', 'compassion', 'though', 'everywhere', 'beloved', 'friend', 'very', 'mutually', 'attached', 'and', 'peculiarly', 'interested', 'in', 'conversation', 'rational', 'or', 'playful'], ['<start>', 'i', 'cannot', 'agree', 'with', 'compassion', 'though', 'everywhere', 'beloved', 'friend', 'very', 'soon', 'followed', \"isabella's\", 'marriage', 'on', 'their', 'little', 'removed', 'by', 'matrimony']]\n"
     ]
    }
   ],
   "source": [
    "corrected = []\n",
    "corrector = BigramSpellCorrector(model, lamda1=0.5, lamda2=-0.5)\n",
    "for sent in corrupted_tokenized:\n",
    "  output_seq = corrector.spell_correct(original_tokenized_sentence=sent, max_depth = 20, beam_width = 3)  #give the corrupt sentences to spell correct\n",
    "  corrected.append(output_seq)\n",
    "    \n",
    "print('Original sentences:', sentences[1:4])\n",
    "print('\\n')\n",
    "print('Corrupted(wrong) sentences:', corrupted_corpus[:3])\n",
    "print('\\n')\n",
    "print('Final result (corrected sentences):', corrected[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9aadeb1d-ed6d-4c29-9dbe-73cd4f88f7cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.']\n",
      "Original sentence:  ['she']\n",
      "Prediction:  had\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was']\n",
      "Prediction:  now\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the']\n",
      "Prediction:  wedding\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest']\n",
      "Prediction:  of\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of']\n",
      "Prediction:  every\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the']\n",
      "Prediction:  wedding\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two']\n",
      "Prediction:  daughters\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters']\n",
      "Prediction:  but\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of']\n",
      "Prediction:  every\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a']\n",
      "Prediction:  mile\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most']\n",
      "Prediction:  affectionate\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate']\n",
      "Prediction:  indulgent\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent']\n",
      "Prediction:  father\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father']\n",
      "Prediction:  composed\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and']\n",
      "Prediction:  you\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had']\n",
      "Prediction:  been\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in']\n",
      "Prediction:  consequence\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence']\n",
      "Prediction:  there\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of']\n",
      "Prediction:  every\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her']\n",
      "Prediction:  father\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\"]\n",
      "Prediction:  marriage\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage']\n",
      "Prediction:  on\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been']\n",
      "Prediction:  mistress\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress']\n",
      "Prediction:  of\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of']\n",
      "Prediction:  every\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of', 'his']\n",
      "Prediction:  constitution\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of', 'his', 'house']\n",
      "Prediction:  from\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from']\n",
      "Prediction:  five\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a']\n",
      "Prediction:  mile\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very']\n",
      "Prediction:  mutually\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early']\n",
      "Prediction:  period\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period']\n",
      "Prediction:  .\n",
      "\n",
      "\n",
      "Original sentence:  ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', \"sister's\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.']\n",
      "Prediction:  <end>\n",
      "\n",
      "\n",
      "Original sentence ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection', '.']\n",
      "Original sentence:  ['her']\n",
      "Prediction:  father\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother']\n",
      "Prediction:  in\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had']\n",
      "Prediction:  been\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died']\n",
      "Prediction:  too\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too']\n",
      "Prediction:  well\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long']\n",
      "Prediction:  ago\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago']\n",
      "Prediction:  for\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for']\n",
      "Prediction:  even\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her']\n",
      "Prediction:  father\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to']\n",
      "Prediction:  part\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have']\n",
      "Prediction:  recommended\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more']\n",
      "Prediction:  than\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than']\n",
      "Prediction:  an\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an']\n",
      "Prediction:  indistinct\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct']\n",
      "Prediction:  remembrance\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance']\n",
      "Prediction:  of\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of']\n",
      "Prediction:  every\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her']\n",
      "Prediction:  father\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses']\n",
      "Prediction:  and\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and']\n",
      "Prediction:  you\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her']\n",
      "Prediction:  father\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place']\n",
      "Prediction:  for\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had']\n",
      "Prediction:  been\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been']\n",
      "Prediction:  mistress\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied']\n",
      "Prediction:  by\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by']\n",
      "Prediction:  matrimony\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an']\n",
      "Prediction:  indistinct\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent']\n",
      "Prediction:  woman\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman']\n",
      "Prediction:  as\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as']\n",
      "Prediction:  misfortunes\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess']\n",
      "Prediction:  than\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who']\n",
      "Prediction:  could\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had']\n",
      "Prediction:  been\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen']\n",
      "Prediction:  little\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little']\n",
      "Prediction:  short\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little', 'short']\n",
      "Prediction:  of\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little', 'short', 'of']\n",
      "Prediction:  every\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a']\n",
      "Prediction:  mile\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother']\n",
      "Prediction:  in\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in']\n",
      "Prediction:  consequence\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection']\n",
      "Prediction:  when\n",
      "\n",
      "\n",
      "Original sentence:  ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection', '.']\n",
      "Prediction:  <end>\n",
      "\n",
      "\n",
      "Original sentence ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond', 'of', 'both', 'daughters', 'but', 'particularly', 'of', 'emma', '.']\n",
      "Original sentence:  ['sixteen']\n",
      "Prediction:  years\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years']\n",
      "Prediction:  old\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had']\n",
      "Prediction:  been\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss']\n",
      "Prediction:  taylor\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor']\n",
      "Prediction:  live\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been']\n",
      "Prediction:  mistress\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in']\n",
      "Prediction:  consequence\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr']\n",
      "Prediction:  .\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.']\n",
      "Prediction:  <end>\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\"]\n",
      "Prediction:  family\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family']\n",
      "Prediction:  less\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less']\n",
      "Prediction:  as\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as']\n",
      "Prediction:  misfortunes\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a']\n",
      "Prediction:  mile\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess']\n",
      "Prediction:  than\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than']\n",
      "Prediction:  an\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a']\n",
      "Prediction:  mile\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend']\n",
      "Prediction:  very\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very']\n",
      "Prediction:  mutually\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond']\n",
      "Prediction:  of\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond', 'of']\n",
      "Prediction:  every\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond', 'of', 'both']\n",
      "Prediction:  daughters\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond', 'of', 'both', 'daughters']\n",
      "Prediction:  but\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond', 'of', 'both', 'daughters', 'but']\n",
      "Prediction:  particularly\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond', 'of', 'both', 'daughters', 'but', 'particularly']\n",
      "Prediction:  of\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond', 'of', 'both', 'daughters', 'but', 'particularly', 'of']\n",
      "Prediction:  every\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond', 'of', 'both', 'daughters', 'but', 'particularly', 'of', 'emma']\n",
      "Prediction:  doing\n",
      "\n",
      "\n",
      "Original sentence:  ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', \"woodhouse's\", 'family', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', 'very', 'fond', 'of', 'both', 'daughters', 'but', 'particularly', 'of', 'emma', '.']\n",
      "Prediction:  <end>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You need to give incomplete sentence for autocorrect. Right now it just predicts the end of the sentences after the '.'\n",
    "# Try a while loop until END_TOKEN is the output maybe\n",
    "\n",
    "#Check how the auto correction works\n",
    "predicted = []\n",
    "for sent in tokenized[:3]:\n",
    "    print(\"Original sentence\", sent)\n",
    "    for i, token in enumerate(sent):                     #try all possible combinations within the sentence\n",
    "        partial_sent = sent[:i+1]\n",
    "        if END_TOKEN in partial_sent:\n",
    "            break\n",
    "        pred = model.predict(tokenized_sentence = partial_sent)\n",
    "        print(\"Original sentence: \", partial_sent)\n",
    "        print(\"Prediction: \", pred)\n",
    "        predicted.append(pred)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e399e286-72a6-4202-9b68-a5ccd53ec5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import cer, wer\n",
    "\n",
    "\n",
    "count = 0\n",
    "sum_cer = 0\n",
    "sum_wer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef2059fe-2d2d-4be3-a6f9-8c8c722a7eaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m corrected_sentence \u001b[38;5;129;01min\u001b[39;00m corrected:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(corrected_sentence)):\n\u001b[0;32m----> 3\u001b[0m         token_k \u001b[38;5;241m=\u001b[39m START_TOKEN \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m tokenized[i][index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m         token_j \u001b[38;5;241m=\u001b[39m corrected_sentence[index]\n\u001b[1;32m      5\u001b[0m         sum_cer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cer(token_k, token_j)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "for corrected_sentence in corrected:\n",
    "    for i in range(len(corrected_sentence)):\n",
    "        token_k = START_TOKEN if index == 0 else tokenized[i][index - 1]\n",
    "        token_j = corrected_sentence[index]\n",
    "        sum_cer += cer(token_k, token_j)\n",
    "        sum_wer += wer(token_k, token_j)\n",
    "        count += 1\n",
    "        \n",
    "avg_cer = sum_cer/count\n",
    "avg_wer = sum_wer/count\n",
    "\n",
    "print(f'Avg cer = {avg_cer}')\n",
    "print(f'Avg wer = {avg_wer}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
