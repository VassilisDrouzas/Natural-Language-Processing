{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5432735fd4845c99e6d985eddc2ffa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6db3e944185945c3b8872daf55ae0c26",
              "IPY_MODEL_89f1f35c651a4b1ab0ffd5d57bdc7d37",
              "IPY_MODEL_ecbe0bb0ea534deebfa3a2e91dac9d95"
            ],
            "layout": "IPY_MODEL_47f52a87a7bc4672819fd35fff1c2b82"
          }
        },
        "6db3e944185945c3b8872daf55ae0c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d504aeeed326459d82b82b6440070dfa",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd50ad36fe649b0b7e6cda00108e538",
            "value": "100%"
          }
        },
        "89f1f35c651a4b1ab0ffd5d57bdc7d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59e8b920b25c410881d1456ff497a035",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e338fc1bb3e4e7db9f9d860be4a7696",
            "value": 2000
          }
        },
        "ecbe0bb0ea534deebfa3a2e91dac9d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_848b857381554645ae313c0b2e0ddcb3",
            "placeholder": "​",
            "style": "IPY_MODEL_002de0d22ad24d7893b910a8f7ab48cd",
            "value": " 2000/2000 [01:25&lt;00:00, 52.26it/s]"
          }
        },
        "47f52a87a7bc4672819fd35fff1c2b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d504aeeed326459d82b82b6440070dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd50ad36fe649b0b7e6cda00108e538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59e8b920b25c410881d1456ff497a035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e338fc1bb3e4e7db9f9d860be4a7696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "848b857381554645ae313c0b2e0ddcb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002de0d22ad24d7893b910a8f7ab48cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a57ddab54a64fae99c5243bf85bb92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f1c0cca24eb4aefaa83d637616c5f53",
              "IPY_MODEL_0c6ea9a5305142ccae72586f21a7e7b9",
              "IPY_MODEL_0ad63a8d76e8415295a7525b9a72315a"
            ],
            "layout": "IPY_MODEL_0c2089e160e84f9eacec53f94159efb3"
          }
        },
        "4f1c0cca24eb4aefaa83d637616c5f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a9132be57e741bc889e8f5cb9387495",
            "placeholder": "​",
            "style": "IPY_MODEL_29d644f3b82a4f6098fdf1fc23f5df7a",
            "value": "100%"
          }
        },
        "0c6ea9a5305142ccae72586f21a7e7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b35ce82763946fda5a125955f1b5fa0",
            "max": 1400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_254d2834a3b24271887f95073a4ca05e",
            "value": 1400
          }
        },
        "0ad63a8d76e8415295a7525b9a72315a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb0c2894fee433b85bdb1c67d9711ad",
            "placeholder": "​",
            "style": "IPY_MODEL_8ed0011660bd406aaba6385c8987a10f",
            "value": " 1400/1400 [00:52&lt;00:00, 28.19it/s]"
          }
        },
        "0c2089e160e84f9eacec53f94159efb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9132be57e741bc889e8f5cb9387495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29d644f3b82a4f6098fdf1fc23f5df7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b35ce82763946fda5a125955f1b5fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "254d2834a3b24271887f95073a4ca05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eb0c2894fee433b85bdb1c67d9711ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed0011660bd406aaba6385c8987a10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42000551a14e44159a3901b834c04f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37e3528f0c964a338f5d3461874da369",
              "IPY_MODEL_3709189d2c674c948a4f4cc0a94e90ed",
              "IPY_MODEL_66c41662db54420ab5cae0590def7472"
            ],
            "layout": "IPY_MODEL_416e592854b843acba4a79507f64c803"
          }
        },
        "37e3528f0c964a338f5d3461874da369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d90eb81f8b437f8cb9a25a194a6c01",
            "placeholder": "​",
            "style": "IPY_MODEL_aadb7d7e5c6e4131bf9233c5260b6723",
            "value": "100%"
          }
        },
        "3709189d2c674c948a4f4cc0a94e90ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85c2bb9e418c4ed3982d2d90e96f832b",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_489cb2bb42d64018a7bdedce0f1739d3",
            "value": 300
          }
        },
        "66c41662db54420ab5cae0590def7472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b329b6660c6e4167adb721c4464bd2a0",
            "placeholder": "​",
            "style": "IPY_MODEL_f875ddb17ad842e8891884df1f6d99f0",
            "value": " 300/300 [00:11&lt;00:00, 28.15it/s]"
          }
        },
        "416e592854b843acba4a79507f64c803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d90eb81f8b437f8cb9a25a194a6c01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aadb7d7e5c6e4131bf9233c5260b6723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85c2bb9e418c4ed3982d2d90e96f832b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489cb2bb42d64018a7bdedce0f1739d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b329b6660c6e4167adb721c4464bd2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f875ddb17ad842e8891884df1f6d99f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "159c00026fc2431dbcaa6ed23d80eb92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0c044f741bc49f9a0020fb52719e1bc",
              "IPY_MODEL_887001ddc153417db18675b352fcc008",
              "IPY_MODEL_525520fc9c15479995a03db5aaf5aea1"
            ],
            "layout": "IPY_MODEL_fae00d433fbf4a0f819102e78fbec69a"
          }
        },
        "d0c044f741bc49f9a0020fb52719e1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ce1dc4c8df847da8c583bfad635136d",
            "placeholder": "​",
            "style": "IPY_MODEL_1c0b3336e06b4f63898f738b94f86e0c",
            "value": "100%"
          }
        },
        "887001ddc153417db18675b352fcc008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4742242cd26c41db81439b3e294cdccc",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44d3044a3fc14bfca80180f6891625ed",
            "value": 300
          }
        },
        "525520fc9c15479995a03db5aaf5aea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e8d677186a4789b9ab69a28fc9ee4b",
            "placeholder": "​",
            "style": "IPY_MODEL_41c9dbe5ca71426daeebddcdd29d75f2",
            "value": " 300/300 [00:10&lt;00:00, 30.95it/s]"
          }
        },
        "fae00d433fbf4a0f819102e78fbec69a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce1dc4c8df847da8c583bfad635136d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0b3336e06b4f63898f738b94f86e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4742242cd26c41db81439b3e294cdccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d3044a3fc14bfca80180f6891625ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53e8d677186a4789b9ab69a28fc9ee4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c9dbe5ca71426daeebddcdd29d75f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX1a7kd3jMGs",
        "outputId": "23ad61d3-c127-4c6c-8838-e25e7e864cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "Successfully installed tensorflow-2.15.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRe15Be4lyAJ",
        "outputId": "0f771b31-ac9b-4760-f20a-014c8d8bfb9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199772 sha256=d685e61ff3f058762dade06190e3935e17157a63e31542f10d1c0234c4420056\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NRKjJ8ymI_p",
        "outputId": "a320a935-d4ef-45fa-e255-119c37bab0a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load the dataset"
      ],
      "metadata": {
        "id": "cSdFYuu_sEtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
        "!tar xzf review_polarity.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sYe0nTQrS1B",
        "outputId": "c4745eb6-cf8c-4537-ad86-bae354aac1cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-18 09:27:39--  https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3127238 (3.0M) [application/x-gzip]\n",
            "Saving to: ‘review_polarity.tar.gz’\n",
            "\n",
            "review_polarity.tar 100%[===================>]   2.98M  5.98MB/s    in 0.5s    \n",
            "\n",
            "2024-02-18 09:27:40 (5.98 MB/s) - ‘review_polarity.tar.gz’ saved [3127238/3127238]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "\n",
        "dataset_path = 'txt_sentoken'\n",
        "movie_reviews = load_files(container_path = dataset_path, encoding = 'utf-8')\n",
        "\n",
        "\n",
        "x = movie_reviews.data            #the data\n",
        "y = movie_reviews.target          #the labels\n",
        "z = movie_reviews.target_names    #the names of labels"
      ],
      "metadata": {
        "id": "ajTyfDWSwgq5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDj-7nUvwj5R",
        "outputId": "a663a37e-1874-48b1-9025-b44a28e450d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1baTcgdfwlUR",
        "outputId": "23017f5e-0eee-4f0e-96b3-f57f8691e03c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB6FzTDpwmzJ",
        "outputId": "204f0d28-0a4c-4e88-d975-fce8bca126e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg', 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average_doc_length(corpus):\n",
        "    ''' Takes as input a whole corpus\n",
        "      Returns the average number of words and chars per document '''\n",
        "\n",
        "    document_word_lengths = [len(doc.split()) for doc in corpus]                            #length of each doc (in words)\n",
        "    average_doc_length_words = sum(document_word_lengths) / len(document_word_lengths)      #average doc length (in words)\n",
        "\n",
        "    document_char_lengths = [len(doc) for doc in corpus]                                    #length of each doc (in characters)\n",
        "    average_doc_length_chars = sum(document_char_lengths) / len(document_char_lengths)      #average doc length (in characters)\n",
        "\n",
        "    return average_doc_length_words, average_doc_length_chars"
      ],
      "metadata": {
        "id": "9DcborDYiXqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---Before preprocessing---\")\n",
        "avg_length_words, avg_length_chars = average_doc_length(x)\n",
        "print(\"Average Document Length (in words):\", avg_length_words)\n",
        "print(\"Average Document Length (in characters):\", avg_length_chars)"
      ],
      "metadata": {
        "id": "dFCB-r9biYyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-processing"
      ],
      "metadata": {
        "id": "LPyKL89hw9SZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN30flXUIy1J"
      },
      "source": [
        "The english stopwords is a package of 179 words that in general, would not help in a sentiment analysis problem. But, since they include terms that are negative, removing them could prove harmful for our case.\n",
        "\n",
        "e.g. imagine the phrase \"I didn't like the film\" to end up \"like film\".\n",
        "\n",
        "So, the plan is to remove all the stop words that include negative meaning before the preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmU8jzwswobg",
        "outputId": "70f28d2c-f36c-40c4-8d36-9fd702da6704"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From these words, we will decide which ones to keep because in fact they have a meaningful impact in our sentiment analysis problem, as we stated earlier."
      ],
      "metadata": {
        "id": "rqZSeeqHxiDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_stop_words = set(stopwords.words('english'))\n",
        "\n",
        "to_keep_words = ['not', \"don't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"hadn't\", \"hasn't\" , \"shouldn't\", \"haven't\", \"wasn't\", \"weren't\",  \"isn't\", \"doesn\"]\n",
        "to_keep_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1mKiosyxaNh",
        "outputId": "772f545f-46db-47c0-a3ba-1467148f7f96"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not',\n",
              " \"don't\",\n",
              " \"aren't\",\n",
              " \"couldn't\",\n",
              " \"didn't\",\n",
              " \"doesn't\",\n",
              " \"hadn't\",\n",
              " \"hasn't\",\n",
              " \"shouldn't\",\n",
              " \"haven't\",\n",
              " \"wasn't\",\n",
              " \"weren't\",\n",
              " \"isn't\",\n",
              " 'doesn']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_updated = set(stopwords.words('english')) - set(to_keep_words)\n",
        "print(len(stopwords.words('english')))\n",
        "print(len(to_keep_words))\n",
        "print(len(stopwords_updated))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2etFA9fWyE05",
        "outputId": "063f6444-b369-406c-b10d-58fd02596c3a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n",
            "14\n",
            "165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "import string\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def pre_process_text(text):\n",
        "    ''' Function to preprocess text.\n",
        "     input: initial text\n",
        "     output: processed text\n",
        "     Performs pre-processing methods:\n",
        "        1. Combination to a single document.\n",
        "        2. Convertion to lowercase.\n",
        "        3. Lemmatization and stop words extraction\n",
        "        4. Punctuation removal\n",
        "        5. Number removal\n",
        "        6. Single characters removal\n",
        "        7. Converting multiple spaces to single ones\n",
        "        '''\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    all_docs = []\n",
        "\n",
        "    single_char = re.compile(r'\\s+[a-z]\\s+')                                          #6. Remove single characters\n",
        "    multiple_space= re.compile(r'\\s+')                                                 #7. Replace multiple space with a single one\n",
        "\n",
        "    stopwords_updated = set(stopwords.words('english')) - set(to_keep_words)\n",
        "    for document in tqdm(x):\n",
        "\n",
        "        combined_text = ' '.join(text)            #1.Combine in one single document\n",
        "\n",
        "        combined_text = combined_text.lower()    #2. Convert to lowercase\n",
        "        combined_text = [lemmatizer.lemmatize(word) for word in document.split() if word not in stopwords_updated]  # 3.Lemmatize and remove stop words\n",
        "\n",
        "\n",
        "        combined_text = ' '.join(combined_text)\n",
        "\n",
        "        combined_text = ''.join([char for char in combined_text if char not in string.punctuation])   #4.remove punctuation\n",
        "        combined_text = ''.join([char for char in combined_text if not char.isdigit()])     #5.remove numbers\n",
        "\n",
        "        res = single_char.sub(combined_text, '')\n",
        "        res2 = multiple_space.sub(combined_text, ' ')\n",
        "        all_docs.append(combined_text)\n",
        "\n",
        "    return all_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKIgoYWCyOPw",
        "outputId": "cc86332f-1e07-4f29-f313-adda8c2e2154"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_text = pre_process_text(x)\n",
        "\n",
        "processed_text[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "d5432735fd4845c99e6d985eddc2ffa6",
            "6db3e944185945c3b8872daf55ae0c26",
            "89f1f35c651a4b1ab0ffd5d57bdc7d37",
            "ecbe0bb0ea534deebfa3a2e91dac9d95",
            "47f52a87a7bc4672819fd35fff1c2b82",
            "d504aeeed326459d82b82b6440070dfa",
            "8bd50ad36fe649b0b7e6cda00108e538",
            "59e8b920b25c410881d1456ff497a035",
            "1e338fc1bb3e4e7db9f9d860be4a7696",
            "848b857381554645ae313c0b2e0ddcb3",
            "002de0d22ad24d7893b910a8f7ab48cd"
          ]
        },
        "id": "r0lgYGgDyfEY",
        "outputId": "2580083b-57f3-400a-c06f-89bd61ab1366"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5432735fd4845c99e6d985eddc2ffa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arnold schwarzenegger icon action enthusiast  since late s  lately film sloppy oneliner getting worse  hard seeing arnold mr  freeze batman robin  especially say ton ice joke  hey got  million  whats matter  arnold signed another expensive blockbuster  cant compare like terminator series  true lie even eraser  called dark thriller  devil  gabriel byrne  come upon earth  impregnate woman  robin tunney  happens every  year  basically destroy world  apparently god chosen one man  one man jericho cane  arnold   help trusty sidekick  kevin pollack   stop nothing let devil take world  part actually absurd  would fit right dogma  yes  film weak  better blockbuster right  sleepy hollow   make world not enough look like  star film  anyway  definitely doesnt seem like arnold movie  wasnt type film see  sure gave u chuckle well known oneliner  seemed confused character film going  understandable  especially ending changed according source  aside form  still walked  much like past film  im sorry say arnold maybe end action day  speaking action  film  hardly explosion fight  devil made place explode  arnold wasnt kicking devil butt  ending changed make spiritual  undoubtedly ruined film  least hoping cool ending nothing else occurred  let  also dont know film took long cost much  really super affect  unless consider invisible devil   minute top  worth overpriced budget  budget gone better script  least audience could somewhat entertained instead facing boredom  pitiful see script like get bought made movie  even read thing anymore  sure doesnt seem like  thankfully gabriels performance gave light poor film  walk street searching robin tunney  cant help feel looked like devil  guy creepy looking anyway   glad end movie  dont bother see  expecting solid action flick  neither solid action  another movie suckered seeing  due strategic marketing campaign  save money see world not enough entertaining experience ']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting into training set (70%), development set (15%) and test set (15%)"
      ],
      "metadata": {
        "id": "vsP4h-94y6RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(processed_text, y, test_size=0.3, random_state=17)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=25)\n",
        "\n",
        "training_text = ' '.join(X_train)                    #Flatten into a single string\n",
        "development_text = ' '.join(X_dev)\n",
        "test_text = ' '.join(X_test)\n",
        "\n",
        "training_words = training_text.split()\n",
        "development_words = development_text.split()\n",
        "test_words = test_text.split()\n",
        "\n",
        "training_vocab = set(training_words)\n",
        "development_vocab = set(development_words)\n",
        "test_vocab = set(test_words)"
      ],
      "metadata": {
        "id": "w2GVixrAy0M5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set size (in documents): \", len(y_train))\n",
        "print(\"Development set size (in documents): \", len(y_dev))\n",
        "print(\"Test set size (in documents): \", len(y_test))\n",
        "print(\"Full size (sanity check): \", len(y_train) + len(y_dev) + len(y_test))\n",
        "print(\"---------------------------------\")\n",
        "print(\"Training vocabulary size (in words): \" , len(training_vocab))\n",
        "print(\"Development vocabulary size (in words): \", len(development_vocab))\n",
        "print(\"Test vocabulary size (in words): \", len(test_vocab))\n",
        "print(\"Full vocabulary size (in words): \", len(training_vocab) + len(development_vocab) + len(test_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMqHNi20zPOf",
        "outputId": "ff74d91b-bf29-498a-e6d2-d5debcdbdf68"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size (in documents):  1400\n",
            "Development set size (in documents):  300\n",
            "Test set size (in documents):  300\n",
            "Full size (sanity check):  2000\n",
            "---------------------------------\n",
            "Training vocabulary size (in words):  36624\n",
            "Development vocabulary size (in words):  16948\n",
            "Test vocabulary size (in words):  16780\n",
            "Full vocabulary size (in words):  70352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "print(STOP_WORDS)\n",
        "print(len(STOP_WORDS))\n",
        "extra_to_keep = [\"n't\", \"not\", \"no\"]\n",
        "for i in range(len(extra_to_keep)):\n",
        "  to_keep_words.append(extra_to_keep[i])\n",
        "\n",
        "to_keep_words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H2cQKI4zbJw",
        "outputId": "626b657e-66db-492e-b02e-7917e51ada8f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'‘ve', 'somewhere', 'out', 'former', 'not', 'since', 'been', 'becomes', 'various', 'take', 'moreover', 'back', '’d', 'everyone', 'this', 'are', 'put', 'them', 'still', \"'s\", 'becoming', 'yourselves', 'eight', 'side', 'behind', 'on', 'otherwise', 'ours', 'themselves', 're', 'should', 'until', 'unless', '’re', 'per', 'any', 'us', 'the', 'its', 'there', 'most', 'move', 'indeed', 'both', 'due', 'nor', 'forty', 'fifteen', 'then', 'amount', 'least', 'does', 'whoever', 'amongst', 'may', 'onto', 'nevertheless', 'six', 'whole', 'please', 'others', 'nowhere', 'top', 'because', 'your', 'though', 'nine', 'he', 'sometimes', 'why', 'meanwhile', '‘m', 'third', 'ten', 'thence', 'him', 'besides', 'i', 'before', 'almost', 'down', 'regarding', 'many', \"'ve\", 'first', 'except', 'next', 'somehow', 'twenty', 'further', '‘d', 'hereby', 'hereupon', 'again', 'quite', 'they', 'be', 'get', 'already', 'whereafter', 'seeming', 'whereupon', 'enough', 'became', 'no', 'much', 'nobody', 'just', 'keep', 'someone', 'it', 'made', 'was', 'everything', 'that', 'you', 'above', 'about', 'say', 'after', 'together', 'over', 'so', 'thereafter', 'part', 'up', 'however', 'between', 'three', 'can', 'such', 'towards', 'did', 'well', 'from', 'around', 'for', 'too', 'below', 'or', 'anyone', 'all', 'serious', 'wherever', 'n’t', 'hence', 'toward', 'without', 'used', 'my', 'throughout', 'we', '’m', 'in', 'four', 'nothing', 'what', 'either', 'an', 'call', \"'d\", 'being', 'anything', 'when', 'perhaps', 'seems', 'none', 'via', 'really', 'five', 'among', \"'ll\", 'how', 'several', 'some', 'must', '‘ll', 'under', 'few', 'whether', 'everywhere', 'anywhere', 'whereas', 'n‘t', 'whose', 'formerly', 'latter', 'himself', 'else', 'a', 'namely', 'who', 'bottom', 'empty', 'his', 'more', 'myself', 'now', 'also', 'mostly', 'along', 'although', 'within', 'eleven', 'fifty', 'herein', 'each', '‘s', 'anyway', 'have', 'anyhow', \"'m\", 'seemed', \"n't\", 'become', 'less', 'name', 'thereupon', '’ll', 'than', 'thru', 'her', 'ever', 'another', 'by', 'might', 'latterly', 'which', 'during', 'itself', 'beyond', 'upon', 'often', 'doing', 'twelve', 'here', 'thereby', 'will', 'therefore', 'noone', 'to', 'go', 'their', 'own', 'do', 'of', 'and', 'hundred', 'ca', 'hers', 'only', 'herself', 'whom', 'give', 'against', 'afterwards', 'with', 'at', 'where', 'elsewhere', 'beside', 'our', \"'re\", 'yours', 'something', 'if', 'whither', 'me', 'thus', 'mine', 'while', 'but', 'rather', 'into', 'every', 'alone', 'last', 'neither', 'she', 'whatever', 'has', 'front', 'am', 'even', 'yet', 'show', 'other', 'once', 'sometime', 'same', 'would', '’ve', 'off', 'one', 'done', 'whereby', '’s', 'sixty', 'yourself', 'through', 'hereafter', 'wherein', 'see', 'two', 'therein', 'make', '‘re', 'across', 'ourselves', 'always', 'whenever', 'never', 'full', 'had', 'seem', 'those', 'whence', 'these', 'were', 'could', 'using', 'cannot', 'as', 'very', 'is', 'beforehand'}\n",
            "326\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not',\n",
              " \"don't\",\n",
              " \"aren't\",\n",
              " \"couldn't\",\n",
              " \"didn't\",\n",
              " \"doesn't\",\n",
              " \"hadn't\",\n",
              " \"hasn't\",\n",
              " \"shouldn't\",\n",
              " \"haven't\",\n",
              " \"wasn't\",\n",
              " \"weren't\",\n",
              " \"isn't\",\n",
              " 'doesn',\n",
              " \"n't\",\n",
              " 'not',\n",
              " 'no']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_updated = STOP_WORDS - set(to_keep_words)\n",
        "print(len(stop_words_updated))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzDTTrtX4A7J",
        "outputId": "e52439a9-90c2-4853-dbf6-c4004e42206d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm',disable=[\"tagger\", \"parser\",\"ner\"])\n",
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "id": "dqiO44uW5Cfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d45f1e8-a0de-4444-c3e9-5d2d63527ed0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7c51b060d700>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Use spaCy for sentence splitting & tokenization"
      ],
      "metadata": {
        "id": "ggXTl3Ff4VWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sent(x):\n",
        "\n",
        "  X_tokenized = []\n",
        "  for idx in tqdm(range(len(x))):\n",
        "    doc = nlp(x[idx])\n",
        "    tokens = []\n",
        "    for sent in doc.sents:\n",
        "      for tok in sent:\n",
        "        if '\\n' in tok.text or \"\\t\" in tok.text or \"--\" in tok.text or \"*\" in tok.text or tok.text.lower() in stop_words_updated or tok.text in string.punctuation or all(x in string.punctuation for x in tok.text):\n",
        "          continue\n",
        "        if tok.text.strip():\n",
        "          tokens.append(tok.text.replace('\"',\"'\").strip().lower())\n",
        "    X_tokenized.append(tokens)\n",
        "  return X_tokenized"
      ],
      "metadata": {
        "id": "imPBqgCy4K4x"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized = tokenize_sent(X_train)\n",
        "X_dev_tokenized = tokenize_sent(X_dev)\n",
        "X_test_tokenized = tokenize_sent(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "4a57ddab54a64fae99c5243bf85bb92a",
            "4f1c0cca24eb4aefaa83d637616c5f53",
            "0c6ea9a5305142ccae72586f21a7e7b9",
            "0ad63a8d76e8415295a7525b9a72315a",
            "0c2089e160e84f9eacec53f94159efb3",
            "6a9132be57e741bc889e8f5cb9387495",
            "29d644f3b82a4f6098fdf1fc23f5df7a",
            "1b35ce82763946fda5a125955f1b5fa0",
            "254d2834a3b24271887f95073a4ca05e",
            "6eb0c2894fee433b85bdb1c67d9711ad",
            "8ed0011660bd406aaba6385c8987a10f",
            "42000551a14e44159a3901b834c04f7d",
            "37e3528f0c964a338f5d3461874da369",
            "3709189d2c674c948a4f4cc0a94e90ed",
            "66c41662db54420ab5cae0590def7472",
            "416e592854b843acba4a79507f64c803",
            "08d90eb81f8b437f8cb9a25a194a6c01",
            "aadb7d7e5c6e4131bf9233c5260b6723",
            "85c2bb9e418c4ed3982d2d90e96f832b",
            "489cb2bb42d64018a7bdedce0f1739d3",
            "b329b6660c6e4167adb721c4464bd2a0",
            "f875ddb17ad842e8891884df1f6d99f0",
            "159c00026fc2431dbcaa6ed23d80eb92",
            "d0c044f741bc49f9a0020fb52719e1bc",
            "887001ddc153417db18675b352fcc008",
            "525520fc9c15479995a03db5aaf5aea1",
            "fae00d433fbf4a0f819102e78fbec69a",
            "4ce1dc4c8df847da8c583bfad635136d",
            "1c0b3336e06b4f63898f738b94f86e0c",
            "4742242cd26c41db81439b3e294cdccc",
            "44d3044a3fc14bfca80180f6891625ed",
            "53e8d677186a4789b9ab69a28fc9ee4b",
            "41c9dbe5ca71426daeebddcdd29d75f2"
          ]
        },
        "id": "JUurnAiE5y55",
        "outputId": "9836f072-3035-4881-b3a5-1727775e3c14"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1400 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a57ddab54a64fae99c5243bf85bb92a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42000551a14e44159a3901b834c04f7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "159c00026fc2431dbcaa6ed23d80eb92"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"Total word length before tokenization:\", [len(x) for x in X_train])\n",
        "print(\"Total word length after tokenization:\", [len(x) for x in X_train_tokenized])\n",
        "\n",
        "print(\"-----------------------------------------------------------\")\n",
        "\n",
        "print(\"Average word length before tokenization:\", np.mean([len(x) for x in X_train]))\n",
        "print(\"Average word length after tokenization:\", np.mean([len(x) for x in X_train_tokenized]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQzno_K4hU0r",
        "outputId": "9b541c2b-ccb2-48b0-d031-bd23265da994"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total word length before tokenization: [1910, 4209, 3093, 1382, 1574, 1239, 4053, 1042, 6206, 2550, 2693, 4096, 3678, 2388, 943, 2316, 2228, 4459, 4586, 2112, 2227, 2743, 1606, 791, 2321, 2903, 2693, 4476, 3583, 2241, 2490, 1719, 2804, 3176, 1336, 800, 5545, 2102, 2411, 4811, 2947, 2195, 1294, 1774, 2754, 1520, 3547, 1888, 2094, 1584, 4735, 1274, 2724, 3922, 1968, 1124, 2736, 3521, 2311, 2329, 2434, 4925, 1544, 2104, 935, 746, 1455, 593, 2325, 3718, 1768, 2206, 2989, 1180, 3287, 1359, 2650, 2204, 2339, 5212, 5447, 2112, 3601, 2824, 1912, 2388, 1482, 2185, 5191, 2883, 2981, 2002, 3331, 1782, 2157, 2141, 2590, 3800, 3393, 1933, 2925, 2294, 3405, 2047, 1251, 2903, 2111, 2902, 2805, 3191, 2118, 2706, 1877, 1000, 1259, 3983, 4724, 2286, 3712, 1555, 2490, 1256, 2542, 2394, 2488, 3550, 3433, 553, 2682, 2831, 941, 3457, 1049, 5903, 3145, 3218, 2378, 2035, 2661, 2495, 1958, 2728, 2125, 2924, 2159, 3182, 5699, 1172, 2943, 866, 667, 3179, 3595, 2169, 1539, 1868, 3993, 2336, 2226, 2436, 1634, 3292, 1746, 2510, 1828, 3609, 2696, 2959, 3035, 2162, 3749, 1306, 1820, 3709, 1937, 1251, 3789, 5213, 2301, 4402, 6045, 4612, 3294, 1965, 5337, 1834, 3045, 2461, 2239, 3473, 3102, 2896, 2171, 1480, 1807, 4032, 2611, 4450, 4420, 1900, 2349, 2308, 984, 2880, 2913, 3608, 4107, 1841, 1837, 4601, 1603, 2753, 4141, 1778, 3537, 2173, 2295, 919, 1847, 4775, 3923, 2313, 2009, 1717, 1940, 2361, 7195, 1708, 1662, 56, 3263, 2443, 1629, 2104, 1406, 3158, 2261, 1511, 2450, 1299, 1749, 1492, 3528, 1297, 2395, 5254, 2184, 1362, 1628, 2211, 1623, 1422, 1508, 4136, 3335, 1533, 1917, 1592, 2708, 1691, 3111, 762, 8513, 3143, 2176, 2555, 1953, 1317, 1940, 1878, 1877, 1451, 2577, 3062, 1766, 1131, 1192, 4542, 3541, 3118, 3037, 1998, 1969, 1973, 2000, 3548, 2761, 2646, 1990, 1256, 3962, 4467, 3851, 3321, 5291, 2552, 1882, 2625, 3686, 2857, 1912, 2245, 2187, 2715, 2090, 1622, 2356, 1513, 3356, 3022, 4334, 2716, 830, 2766, 3692, 1398, 2845, 1787, 2183, 1513, 3760, 5357, 4889, 2284, 1658, 2967, 3855, 2080, 1346, 2052, 2023, 2125, 2457, 2849, 3614, 2035, 2850, 2168, 930, 1817, 2718, 1130, 2592, 2976, 3836, 2517, 1640, 2886, 3256, 2632, 1996, 1739, 2915, 1404, 2528, 3502, 2605, 639, 3393, 1755, 2467, 4687, 2070, 2772, 3038, 2578, 4127, 4263, 4204, 3010, 1790, 2149, 3396, 4222, 834, 2353, 1256, 2998, 2334, 1953, 3232, 2827, 3372, 2412, 2019, 1778, 1720, 3643, 2539, 1167, 4183, 2123, 1690, 2328, 3065, 1129, 2000, 2395, 3278, 1639, 1453, 1044, 4470, 4000, 2291, 2839, 2820, 1647, 2695, 2902, 1920, 1467, 3482, 3061, 907, 2147, 5013, 2068, 2300, 1793, 1640, 1833, 2930, 2252, 2443, 4770, 2727, 3471, 4125, 2184, 3138, 1942, 3050, 3183, 3257, 3193, 2182, 2696, 1620, 4430, 2971, 1364, 2833, 3842, 5301, 1428, 3293, 2590, 2904, 3273, 1618, 4001, 2250, 4396, 1859, 2365, 2376, 1868, 2458, 2719, 2763, 2277, 1873, 2067, 3105, 2734, 2911, 3518, 1461, 1498, 2873, 2765, 2280, 3677, 1564, 1279, 3381, 1714, 2747, 1612, 2165, 1949, 2766, 1322, 3739, 2516, 1727, 4239, 1079, 2140, 2690, 2216, 1696, 3916, 841, 1281, 3491, 3055, 2300, 3554, 2776, 3226, 1945, 3076, 2591, 3526, 1855, 2398, 2667, 2446, 3273, 1880, 1432, 3878, 2937, 3144, 2927, 1571, 2532, 2297, 2884, 3797, 2858, 2199, 1846, 1184, 2536, 2675, 1526, 2621, 2765, 2575, 2610, 2512, 3096, 4456, 1426, 1829, 1865, 1965, 2272, 2080, 3517, 3359, 2189, 3538, 1050, 1597, 3646, 3890, 1739, 1001, 1244, 2706, 1706, 1984, 2768, 648, 2733, 1469, 1566, 3741, 3715, 4252, 1669, 3537, 3335, 509, 2713, 1908, 1143, 3500, 3204, 2497, 3064, 1278, 3257, 2285, 2772, 2273, 2501, 1895, 1464, 4776, 3229, 1505, 1569, 2981, 3695, 2004, 3797, 1151, 3322, 2577, 2105, 2183, 2625, 2248, 3060, 2487, 3109, 1326, 3478, 842, 1428, 2144, 2664, 2496, 798, 3822, 2544, 1831, 2192, 3041, 1673, 826, 2946, 2711, 2312, 1974, 4182, 2424, 5579, 3564, 2095, 2444, 2817, 6027, 4996, 1326, 1334, 5085, 4483, 2394, 2967, 2776, 2632, 3056, 1721, 2094, 1449, 2833, 2323, 3070, 2165, 3300, 2718, 2351, 2964, 2386, 2094, 2638, 2476, 3303, 2816, 2562, 2678, 3086, 2475, 3444, 2206, 974, 2336, 2732, 2545, 1263, 2870, 3026, 2497, 1910, 4035, 1388, 3024, 1703, 3238, 1425, 2997, 2901, 970, 2593, 2528, 1782, 1632, 4127, 2456, 3255, 2298, 2111, 3182, 2361, 3703, 2290, 3846, 3609, 3453, 1208, 2598, 3049, 1422, 1528, 2685, 1668, 2920, 3142, 2342, 3019, 1554, 2220, 2821, 3335, 3130, 2467, 2544, 1690, 2017, 4513, 2596, 2322, 2130, 6853, 2163, 2460, 3380, 1307, 3548, 2299, 2506, 3837, 2456, 4062, 1641, 2813, 4096, 2773, 2340, 2015, 5545, 1896, 3494, 3596, 2747, 2195, 2259, 2239, 840, 2031, 2645, 1861, 1555, 1900, 3175, 2697, 1680, 1415, 1854, 1583, 1095, 2177, 2821, 1559, 5709, 3412, 3581, 5972, 3850, 3064, 1965, 2486, 3766, 1989, 2552, 2557, 3201, 1153, 3214, 3105, 1625, 1798, 2145, 1807, 2006, 2775, 2133, 2910, 2135, 787, 3024, 2439, 3716, 1823, 2063, 3502, 1810, 4137, 3260, 1742, 1050, 1735, 2065, 2051, 1438, 2111, 2220, 2179, 2953, 1727, 3592, 1682, 1894, 3065, 2945, 1810, 2877, 3126, 2063, 1429, 4186, 6136, 2320, 1676, 2413, 1776, 3113, 3342, 953, 1314, 2181, 2914, 1775, 2184, 2303, 10678, 4371, 5296, 3828, 5079, 2802, 2244, 928, 4931, 4658, 1741, 3130, 2252, 4618, 3241, 3418, 1418, 4631, 2528, 1313, 1659, 1811, 2955, 1239, 1299, 1221, 3902, 2167, 4018, 1779, 2687, 2696, 882, 1462, 2582, 2563, 3138, 1503, 768, 2956, 2918, 2206, 1456, 4844, 2189, 1559, 4361, 1544, 1818, 1627, 2310, 5002, 3190, 6845, 2689, 1407, 878, 2202, 1351, 5024, 2985, 2683, 1934, 2101, 894, 3240, 2489, 2559, 2705, 1753, 1487, 2586, 1837, 3140, 1442, 2949, 3792, 2842, 1784, 1774, 1440, 3066, 2307, 1967, 2478, 2208, 5353, 3474, 2296, 3597, 916, 3921, 2932, 2790, 2059, 587, 4628, 1654, 2877, 2052, 2327, 3407, 2156, 2816, 2448, 3317, 2126, 2270, 4166, 2022, 1625, 2459, 2797, 2677, 1520, 2890, 2467, 1036, 2744, 898, 1256, 1936, 2351, 972, 967, 2461, 1624, 3048, 2124, 5797, 2791, 2352, 1418, 1659, 4102, 2228, 2548, 1847, 4141, 2351, 868, 1852, 2430, 3662, 1946, 1680, 4688, 3376, 3254, 3334, 2636, 1860, 1125, 1359, 3115, 1911, 2127, 3812, 2982, 3473, 3809, 2944, 1745, 1372, 3579, 4347, 2857, 1908, 4399, 2418, 1945, 1592, 1124, 2856, 2985, 1687, 3297, 1260, 4915, 5111, 2369, 1840, 2098, 2503, 2012, 1027, 3231, 1600, 1275, 2547, 1123, 2034, 1904, 1243, 5098, 2670, 2304, 3420, 5034, 1920, 2130, 4172, 2696, 2212, 5167, 3214, 1598, 2677, 3684, 1579, 2338, 1034, 3335, 2763, 2870, 3653, 1799, 2144, 2650, 2949, 3311, 3458, 2559, 2293, 2337, 1484, 4405, 1234, 2961, 5940, 2055, 701, 1290, 2046, 3122, 1858, 2005, 2416, 3250, 1278, 3237, 1251, 3025, 3050, 2083, 3567, 1272, 938, 2290, 1196, 3167, 2796, 2114, 2785, 1970, 1925, 1704, 1700, 2520, 1414, 5759, 632, 1426, 1966, 2263, 1507, 1250, 2100, 1737, 2349, 2651, 2839, 2546, 4722, 5547, 1354, 3587, 3386, 2592, 1735, 935, 3312, 1719, 3536, 3712, 2125, 3544, 5471, 2456, 2024, 7426, 2959, 1844, 1561, 2798, 2017, 3094, 1495, 2750, 3283, 2124, 3031, 2850, 1576, 4090, 2024, 2436, 1857, 1411, 2535, 1759, 2475, 2607, 1067, 2815, 3805, 1296, 4550, 2686, 1882, 1938, 2894, 2197, 2835, 1221, 2057, 3440, 3045, 2915, 3405, 2015, 3125, 3446, 2991, 2442, 1992, 1594, 2575, 3756, 3065, 1764, 3266, 1382, 308, 3651, 674, 1234, 2264, 3103, 5162, 4938, 1903, 2000, 1030, 3003, 3185, 1344, 3437, 1856, 2235, 1824, 3583, 3668, 1944, 2946, 1087, 901, 2432, 3891, 1532, 2966, 4989, 1990, 2219, 2614, 2707, 1056, 1502, 1934, 3928, 2534, 2561, 1806, 3979, 2461, 1440, 2133, 1560, 1808, 1320, 1876, 1063, 3600, 976, 2281, 1832, 1150, 1295, 3579, 2172, 2141, 4015, 2613, 2361, 2257, 2152, 3628, 2028, 944, 5781, 3951, 2520, 5461, 3954, 3015, 2551, 1890, 2499, 2697, 1608, 3880, 8411, 3574, 2560, 1924, 1954, 3352, 1964, 2779, 2930, 2327, 1408, 1863, 2642, 2497, 5572, 3532, 1847, 2457, 2133, 1766, 2141, 1664, 2640, 6099, 3385, 2842, 2014, 3890, 1815, 2408, 5103, 1605, 2518, 858, 1841, 2107, 4293, 2495, 1763, 2535, 1075, 1341, 1571, 2637, 2409, 1367, 1761, 1756, 2699, 3079, 2154, 4417, 1170, 785, 2773, 2111, 1310, 1747, 1799, 5750, 2138, 1092, 2333, 2900, 2755, 1773, 3926, 2926, 2308, 2309, 2155, 2370, 1557, 4451, 428, 1024, 7080, 1355, 1466, 3911, 4970, 1537, 1962, 2307, 2683, 2135, 2304, 3449, 1310, 3894, 3401, 3212, 4311, 1275, 3030, 3184, 2539, 3442, 5213, 4217, 1545, 4188, 3277, 2126, 2344, 1520, 2483, 3458, 1620, 3660, 3322, 3005, 3500, 1043, 1692, 2829, 4535, 3053, 2618, 1990, 2111, 3487, 2501, 2048, 780, 2824, 4349, 2172, 3268, 1330, 1763, 1939, 1858, 1457, 3631, 2184, 2917, 1429, 2587, 3066, 3499, 4415, 2460, 5539, 2272, 2455, 2403, 3091]\n",
            "Total word length after tokenization: [230, 506, 373, 177, 180, 148, 480, 130, 704, 317, 332, 475, 425, 276, 111, 297, 273, 530, 506, 277, 273, 335, 194, 99, 264, 349, 306, 483, 423, 269, 297, 192, 333, 390, 150, 102, 667, 252, 297, 556, 353, 258, 156, 219, 340, 176, 422, 235, 246, 208, 555, 170, 337, 488, 246, 144, 317, 413, 274, 272, 284, 636, 177, 248, 114, 91, 186, 73, 273, 455, 207, 289, 351, 145, 406, 163, 314, 256, 305, 675, 661, 245, 447, 349, 239, 289, 175, 266, 661, 323, 358, 247, 419, 205, 252, 259, 320, 440, 423, 238, 346, 288, 413, 250, 142, 373, 247, 354, 356, 371, 269, 316, 234, 130, 165, 451, 575, 278, 469, 188, 325, 156, 299, 296, 298, 464, 416, 68, 297, 356, 122, 437, 128, 731, 383, 358, 276, 251, 357, 322, 243, 323, 277, 357, 251, 385, 668, 141, 337, 100, 76, 381, 430, 264, 191, 227, 474, 275, 274, 295, 189, 396, 210, 303, 236, 447, 329, 352, 352, 281, 444, 163, 206, 472, 221, 161, 445, 603, 292, 548, 733, 555, 407, 240, 621, 223, 358, 293, 260, 422, 388, 368, 255, 178, 225, 506, 327, 538, 530, 241, 286, 282, 123, 352, 349, 420, 493, 213, 217, 565, 180, 360, 493, 207, 434, 257, 278, 110, 228, 567, 457, 275, 243, 208, 231, 296, 829, 205, 205, 8, 365, 296, 203, 251, 175, 366, 262, 189, 280, 154, 213, 185, 414, 157, 302, 608, 259, 166, 192, 251, 198, 166, 191, 512, 404, 197, 244, 198, 320, 200, 358, 94, 1044, 379, 262, 315, 240, 168, 240, 227, 229, 164, 302, 369, 203, 133, 153, 537, 443, 388, 364, 242, 241, 258, 228, 423, 333, 323, 260, 158, 482, 548, 456, 389, 634, 309, 234, 288, 442, 349, 246, 274, 266, 338, 248, 196, 273, 182, 405, 371, 540, 365, 98, 331, 439, 156, 340, 237, 282, 199, 440, 657, 593, 279, 194, 363, 450, 239, 167, 235, 255, 257, 301, 331, 429, 249, 337, 246, 118, 239, 326, 134, 332, 351, 468, 290, 199, 343, 394, 330, 247, 201, 379, 170, 320, 415, 306, 79, 420, 216, 313, 563, 235, 353, 360, 317, 443, 524, 495, 366, 220, 243, 418, 530, 95, 288, 151, 362, 290, 220, 375, 346, 422, 283, 257, 212, 209, 426, 309, 144, 497, 261, 203, 281, 353, 138, 243, 283, 363, 199, 177, 136, 542, 492, 272, 354, 342, 212, 315, 353, 240, 180, 422, 388, 105, 277, 572, 248, 275, 230, 207, 208, 362, 266, 301, 573, 330, 421, 480, 246, 362, 226, 349, 382, 397, 377, 276, 337, 195, 537, 382, 178, 333, 456, 609, 173, 390, 308, 361, 410, 193, 475, 276, 488, 216, 303, 283, 232, 291, 302, 336, 265, 239, 242, 383, 339, 363, 448, 186, 187, 334, 336, 275, 455, 187, 156, 390, 208, 341, 193, 268, 241, 324, 157, 448, 330, 206, 509, 138, 271, 316, 255, 196, 469, 106, 148, 397, 351, 275, 433, 314, 406, 222, 367, 317, 429, 221, 301, 294, 300, 406, 229, 182, 454, 350, 373, 363, 185, 303, 266, 336, 454, 344, 274, 221, 153, 306, 340, 196, 327, 331, 326, 325, 317, 367, 518, 184, 237, 237, 250, 266, 250, 429, 390, 259, 445, 135, 199, 461, 469, 207, 120, 158, 331, 204, 240, 347, 73, 319, 179, 185, 444, 432, 509, 203, 404, 394, 70, 322, 226, 145, 439, 375, 320, 371, 163, 367, 287, 335, 254, 282, 232, 181, 544, 389, 185, 204, 367, 430, 235, 476, 147, 403, 316, 253, 257, 331, 265, 361, 300, 372, 156, 420, 100, 178, 253, 315, 305, 95, 452, 327, 227, 270, 357, 214, 91, 346, 342, 284, 250, 489, 304, 674, 455, 252, 304, 323, 715, 610, 162, 168, 634, 538, 297, 368, 325, 300, 377, 214, 253, 183, 320, 280, 359, 266, 385, 336, 295, 355, 277, 249, 301, 314, 373, 342, 309, 326, 375, 273, 424, 276, 124, 286, 313, 315, 154, 363, 370, 311, 227, 490, 167, 386, 203, 387, 163, 367, 364, 123, 313, 319, 206, 208, 497, 303, 367, 281, 260, 384, 294, 439, 273, 447, 445, 444, 144, 311, 381, 166, 185, 337, 200, 354, 372, 278, 371, 195, 280, 355, 388, 377, 300, 316, 217, 243, 552, 287, 287, 269, 826, 257, 301, 425, 160, 425, 264, 295, 442, 280, 467, 209, 329, 482, 324, 278, 241, 683, 229, 411, 444, 334, 257, 257, 281, 97, 243, 324, 211, 189, 226, 386, 335, 210, 174, 232, 185, 131, 260, 342, 181, 692, 417, 410, 700, 483, 373, 242, 273, 450, 277, 300, 300, 405, 143, 385, 367, 192, 215, 251, 232, 241, 339, 257, 351, 257, 98, 362, 284, 460, 223, 243, 444, 220, 487, 407, 204, 133, 214, 238, 260, 172, 259, 264, 248, 380, 213, 410, 194, 235, 372, 351, 219, 337, 369, 222, 169, 483, 735, 281, 208, 286, 202, 397, 406, 120, 161, 262, 356, 222, 306, 282, 1289, 531, 618, 460, 639, 327, 274, 119, 578, 540, 218, 365, 292, 556, 387, 408, 177, 557, 323, 165, 213, 218, 354, 151, 160, 146, 471, 249, 496, 224, 313, 366, 105, 180, 304, 325, 387, 185, 101, 351, 361, 250, 173, 577, 258, 199, 508, 195, 217, 196, 289, 587, 408, 823, 330, 175, 101, 281, 168, 610, 387, 323, 223, 247, 122, 370, 303, 312, 333, 208, 182, 306, 224, 364, 175, 386, 455, 336, 226, 221, 170, 365, 267, 243, 314, 248, 658, 421, 284, 454, 114, 488, 363, 333, 250, 72, 576, 197, 343, 235, 262, 406, 262, 351, 305, 414, 257, 256, 502, 228, 190, 286, 334, 313, 194, 349, 297, 133, 339, 112, 155, 230, 307, 120, 118, 290, 189, 371, 282, 717, 341, 282, 164, 205, 566, 272, 330, 224, 497, 289, 105, 214, 288, 457, 240, 208, 566, 408, 401, 408, 321, 227, 132, 175, 389, 235, 254, 453, 365, 416, 449, 375, 220, 153, 418, 517, 328, 237, 552, 297, 225, 195, 126, 348, 371, 206, 389, 153, 631, 595, 291, 224, 260, 314, 244, 127, 394, 186, 155, 309, 141, 235, 230, 159, 601, 317, 284, 424, 582, 239, 263, 467, 342, 256, 621, 384, 202, 306, 444, 183, 276, 129, 419, 364, 346, 433, 239, 251, 334, 362, 415, 400, 314, 270, 286, 169, 503, 146, 373, 728, 249, 94, 159, 268, 390, 234, 242, 304, 366, 163, 398, 150, 358, 376, 255, 436, 175, 120, 279, 150, 402, 328, 250, 330, 238, 214, 211, 199, 299, 172, 690, 84, 170, 243, 285, 186, 167, 266, 212, 279, 328, 344, 306, 555, 671, 161, 424, 423, 314, 204, 116, 397, 200, 404, 437, 262, 435, 686, 303, 277, 926, 350, 208, 191, 342, 244, 364, 174, 354, 399, 254, 346, 341, 193, 488, 242, 282, 225, 177, 325, 211, 301, 320, 124, 346, 477, 166, 533, 333, 228, 228, 368, 257, 327, 146, 255, 423, 357, 332, 417, 244, 365, 416, 356, 291, 251, 202, 318, 465, 366, 213, 407, 173, 37, 433, 79, 165, 281, 377, 631, 584, 228, 265, 117, 359, 383, 157, 405, 226, 278, 231, 427, 439, 240, 365, 133, 120, 282, 439, 202, 378, 597, 235, 265, 302, 329, 120, 193, 227, 475, 303, 312, 218, 485, 311, 169, 266, 184, 221, 177, 226, 127, 438, 122, 283, 243, 138, 149, 422, 269, 272, 484, 313, 274, 248, 261, 458, 241, 121, 712, 457, 307, 655, 449, 372, 332, 228, 294, 328, 203, 496, 1045, 419, 296, 237, 251, 400, 253, 345, 352, 287, 179, 229, 343, 308, 653, 407, 232, 299, 265, 225, 281, 198, 307, 738, 415, 346, 244, 463, 206, 308, 609, 196, 322, 107, 227, 256, 525, 285, 212, 301, 127, 162, 191, 306, 298, 181, 230, 195, 324, 384, 257, 578, 153, 98, 318, 257, 158, 216, 228, 704, 271, 125, 269, 352, 326, 223, 475, 357, 292, 273, 268, 297, 187, 551, 48, 141, 830, 172, 185, 477, 596, 176, 248, 271, 331, 241, 270, 439, 154, 444, 406, 393, 504, 153, 355, 371, 314, 394, 630, 518, 200, 515, 393, 255, 295, 183, 297, 410, 205, 442, 413, 353, 420, 118, 200, 330, 521, 390, 322, 244, 259, 438, 297, 236, 92, 342, 513, 260, 389, 160, 209, 242, 234, 185, 467, 259, 373, 184, 329, 363, 429, 558, 312, 662, 268, 298, 290, 353]\n",
            "Average word length before tokenization: 2586.9\n",
            "Average word length after tokenization: 312.97285714285715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get mean and std of sequence length\n",
        "train_mean = np.mean([len(x) for x in X_train_tokenized])\n",
        "train_std = np.std([len(x) for x in X_train_tokenized])\n",
        "print(\"Mean of sequence length on training set:\", train_mean)\n",
        "print(\"Standard deviation of sequence length on training set:\", train_std)\n",
        "\n",
        "print(\"-----------------------------------------------------------\")\n",
        "\n",
        "dev_mean = np.mean([len(x) for x in X_dev_tokenized])\n",
        "dev_std = np.std([len(x) for x in X_dev_tokenized])\n",
        "print(\"Mean of sequence length on development set:\", dev_mean)\n",
        "print(\"Standard deviation of sequence length on development set:\", dev_std)\n",
        "\n",
        "print(\"-----------------------------------------------------------\")\n",
        "\n",
        "test_mean = np.mean([len(x) for x in X_test_tokenized])\n",
        "test_std = np.std([len(x) for x in X_test_tokenized])\n",
        "print(\"Mean of sequence length on test set:\", test_mean)\n",
        "print(\"Standard deviation of sequence length on test set:\", test_std)"
      ],
      "metadata": {
        "id": "fi0bHmHx6ayR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a784ba-a1fb-4356-847d-baf33df6e717"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of sequence length on training set: 312.97285714285715\n",
            "Standard deviation of sequence length on training set: 134.5485652324931\n",
            "Mean of sequence length on development set: 315.10333333333335\n",
            "Standard deviation of sequence length on development set: 139.33664027176133\n",
            "Mean of sequence length on test set: 305.0566666666667\n",
            "Standard deviation of sequence length on test set: 131.16630711513616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "print(X_train_tokenized[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FowDIKShmCz9",
        "outputId": "d8dc27d3-579d-4b43-ca27-d994707e8c28"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not many people know james whale  safe bet good chunk seen movie  believe semi biographical god monster  whale would wanted way  insightful  haunting exploration last day frankenstein bride frankenstein director  notable introducing one first complicated gay character hollywood movie  god monster interest biopic whales life track final day life  probably better movie  focus whales  ian mckellen  untraditional deceptive lust heterosexual gardener clayton boone  brendan fraser   begin whale  fairly talented artist  aside director  asking boone  sit    pose portrait   first  boone doesnt realize whale gay grows fascinated old man  discover whales sexual orientation dedicated protective maid  lynn redgrave   frightened  refusing sit guy  come back  storm  disgusted whales  locker room talk   boone return yet another time  whale promise tone aforementioned  locker room talk   find platonic relationship strengthening  meanwhile  jimmy suffering hallucination mental attack result stroke not long ago  ailment lead desperation depression  build point forced ask boone incredulously big favor  perhaps sensational god monster brendan frasers bravura performance  seeing film intensely disliked young actor tendency ruin movie  blast past  example   surprised expressive actor proved  impressive characters dialogue minimal  mckellan talking  requires fraser act body language  difficult skill master  something prof capable well  not ignore mckellans oscar nominated turn  earned nomination touching performance  although  risk sounding like philistine  would chosen performance nazi apt pupil nomination   understated  compelling gem  whale dreaded remembered solely work hollywood horror genre  thought hollywood equivalent battlefield  rejoiced free  reluctantly going reception fellow movie people  end  perhaps  killed  memory hollywood war blending together form living nightmare    eugene novikov \n",
            "['not', 'people', 'know', 'james', 'whale', 'safe', 'bet', 'good', 'chunk', 'seen', 'movie', 'believe', 'semi', 'biographical', 'god', 'monster', 'whale', 'wanted', 'way', 'insightful', 'haunting', 'exploration', 'day', 'frankenstein', 'bride', 'frankenstein', 'director', 'notable', 'introducing', 'complicated', 'gay', 'character', 'hollywood', 'movie', 'god', 'monster', 'interest', 'biopic', 'whales', 'life', 'track', 'final', 'day', 'life', 'probably', 'better', 'movie', 'focus', 'whales', 'ian', 'mckellen', 'untraditional', 'deceptive', 'lust', 'heterosexual', 'gardener', 'clayton', 'boone', 'brendan', 'fraser', 'begin', 'whale', 'fairly', 'talented', 'artist', 'aside', 'director', 'asking', 'boone', 'sit', 'pose', 'portrait', 'boone', 'nt', 'realize', 'whale', 'gay', 'grows', 'fascinated', 'old', 'man', 'discover', 'whales', 'sexual', 'orientation', 'dedicated', 'protective', 'maid', 'lynn', 'redgrave', 'frightened', 'refusing', 'sit', 'guy', 'come', 'storm', 'disgusted', 'whales', 'locker', 'room', 'talk', 'boone', 'return', 'time', 'whale', 'promise', 'tone', 'aforementioned', 'locker', 'room', 'talk', 'find', 'platonic', 'relationship', 'strengthening', 'jimmy', 'suffering', 'hallucination', 'mental', 'attack', 'result', 'stroke', 'not', 'long', 'ago', 'ailment', 'lead', 'desperation', 'depression', 'build', 'point', 'forced', 'ask', 'boone', 'incredulously', 'big', 'favor', 'sensational', 'god', 'monster', 'brendan', 'frasers', 'bravura', 'performance', 'seeing', 'film', 'intensely', 'disliked', 'young', 'actor', 'tendency', 'ruin', 'movie', 'blast', 'past', 'example', 'surprised', 'expressive', 'actor', 'proved', 'impressive', 'characters', 'dialogue', 'minimal', 'mckellan', 'talking', 'requires', 'fraser', 'act', 'body', 'language', 'difficult', 'skill', 'master', 'prof', 'capable', 'not', 'ignore', 'mckellans', 'oscar', 'nominated', 'turn', 'earned', 'nomination', 'touching', 'performance', 'risk', 'sounding', 'like', 'philistine', 'chosen', 'performance', 'nazi', 'apt', 'pupil', 'nomination', 'understated', 'compelling', 'gem', 'whale', 'dreaded', 'remembered', 'solely', 'work', 'hollywood', 'horror', 'genre', 'thought', 'hollywood', 'equivalent', 'battlefield', 'rejoiced', 'free', 'reluctantly', 'going', 'reception', 'fellow', 'movie', 'people', 'end', 'killed', 'memory', 'hollywood', 'war', 'blending', 'form', 'living', 'nightmare', 'eugene', 'novikov']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenize, convert text (sequence of words) to sequence of indexes and PAD the sequences"
      ],
      "metadata": {
        "id": "4xeBK1x2xDpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import math\n",
        "\n",
        "MAX_WORDS = 100000\n",
        "MAX_SEQUENCE_LENGTH =  math.ceil(train_mean + train_std)\n",
        "EMBEDDING_DIM = 300              #to be changed\n",
        "\n",
        "tokenizer = Tokenizer(num_words = MAX_WORDS, oov_token ='UNK')\n",
        "tokenizer.fit_on_texts([\" \".join(x) for x in X_train_tokenized])\n",
        "\n",
        "word_idx = tokenizer.word_index\n"
      ],
      "metadata": {
        "id": "glx4fvhHxBFV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of unique words in the word index: \", len(word_idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CsFs6b3goPV",
        "outputId": "38173f48-3517-44a3-de8e-4f10cf1635e7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in the word index:  36337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences([\" \".join(x) for x in X_train_tokenized])\n",
        "dev_sequences = tokenizer.texts_to_sequences([\" \".join(x) for x in X_dev_tokenized])\n",
        "test_sequences = tokenizer.texts_to_sequences([\" \".join(x) for x in X_test_tokenized])\n",
        "\n",
        "train_pad = pad_sequences(train_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding ='post')\n",
        "dev_pad = pad_sequences(dev_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding ='post')\n",
        "test_pad = pad_sequences(test_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding ='post')"
      ],
      "metadata": {
        "id": "GlqPE_iZ08Gs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_sequences[0])\n",
        "print(\"------------------------------\")\n",
        "print(train_pad[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXkC9kDZ14l8",
        "outputId": "90dcc9c5-423f-4569-821f-e91cb5eeae88"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 21, 19, 172, 2072, 1378, 1887, 11, 4996, 47, 3, 226, 10828, 12688, 363, 567, 2072, 615, 13, 3289, 1486, 4069, 45, 2294, 2744, 2294, 34, 1888, 4491, 2295, 1015, 7, 110, 3, 363, 567, 343, 9480, 7054, 14, 715, 206, 45, 14, 114, 46, 3, 524, 7054, 1983, 15531, 20585, 12689, 4492, 6522, 7684, 6523, 4493, 4754, 3290, 106, 2072, 736, 670, 975, 859, 34, 1648, 4493, 765, 3906, 2406, 4493, 4, 593, 2072, 1015, 1349, 4755, 71, 26, 950, 7054, 568, 15532, 3050, 7685, 4494, 8470, 7686, 3742, 4495, 765, 48, 17, 1649, 7687, 7054, 6524, 284, 288, 4493, 302, 9, 2072, 976, 705, 1841, 6524, 284, 288, 37, 20586, 151, 20587, 1431, 2034, 6525, 1790, 688, 244, 3424, 5, 72, 442, 15533, 136, 3743, 4070, 1016, 54, 443, 766, 4493, 20588, 42, 1683, 6526, 363, 567, 4754, 15534, 10829, 24, 212, 2, 5663, 6058, 65, 30, 2838, 2073, 3, 4071, 219, 245, 1159, 4496, 30, 3291, 430, 767, 134, 4072, 10830, 569, 1729, 3290, 224, 276, 847, 463, 1002, 737, 832, 1541, 5, 3292, 12690, 431, 4073, 67, 3907, 1487, 1309, 24, 1350, 4281, 8, 20589, 1213, 24, 2839, 4997, 5329, 1487, 4074, 1330, 2236, 2072, 6527, 2407, 2840, 22, 110, 141, 303, 165, 110, 3744, 2237, 20590, 833, 3581, 55, 7688, 977, 3, 21, 25, 420, 811, 110, 119, 8471, 354, 369, 1140, 3168, 6528]\n",
            "------------------------------\n",
            "[    5    21    19   172  2072  1378  1887    11  4996    47     3   226\n",
            " 10828 12688   363   567  2072   615    13  3289  1486  4069    45  2294\n",
            "  2744  2294    34  1888  4491  2295  1015     7   110     3   363   567\n",
            "   343  9480  7054    14   715   206    45    14   114    46     3   524\n",
            "  7054  1983 15531 20585 12689  4492  6522  7684  6523  4493  4754  3290\n",
            "   106  2072   736   670   975   859    34  1648  4493   765  3906  2406\n",
            "  4493     4   593  2072  1015  1349  4755    71    26   950  7054   568\n",
            " 15532  3050  7685  4494  8470  7686  3742  4495   765    48    17  1649\n",
            "  7687  7054  6524   284   288  4493   302     9  2072   976   705  1841\n",
            "  6524   284   288    37 20586   151 20587  1431  2034  6525  1790   688\n",
            "   244  3424     5    72   442 15533   136  3743  4070  1016    54   443\n",
            "   766  4493 20588    42  1683  6526   363   567  4754 15534 10829    24\n",
            "   212     2  5663  6058    65    30  2838  2073     3  4071   219   245\n",
            "  1159  4496    30  3291   430   767   134  4072 10830   569  1729  3290\n",
            "   224   276   847   463  1002   737   832  1541     5  3292 12690   431\n",
            "  4073    67  3907  1487  1309    24  1350  4281     8 20589  1213    24\n",
            "  2839  4997  5329  1487  4074  1330  2236  2072  6527  2407  2840    22\n",
            "   110   141   303   165   110  3744  2237 20590   833  3581    55  7688\n",
            "   977     3    21    25   420   811   110   119  8471   354   369  1140\n",
            "  3168  6528     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download and unzip fasttext binary model for word embeddings"
      ],
      "metadata": {
        "id": "-6fWrvm5rC7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gzip -d cc.en.300.bin.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYdz-1ysqxQg",
        "outputId": "40fe63b2-725d-4eca-81ec-5ab9b4b4dd4e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-18 09:38:24--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.14, 3.163.189.51, 3.163.189.96, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G   115MB/s    in 41s     \n",
            "\n",
            "2024-02-18 09:39:05 (105 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create embedding matrix"
      ],
      "metadata": {
        "id": "JhufSqPelZ0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process**: The loop iterates over the word_index dictionary, which contains word-to-index mappings generated by the tokenizer. For each word in the word_index, it checks if the index is within the limit of *MAX_WORDS*. If so, it retrieves the corresponding word vector from the FastText model using *fasttext_model.get_word_vector(word=key)* and assigns it to the corresponding row in the embedding_matrix."
      ],
      "metadata": {
        "id": "2uAkNWh2oQhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "print(\"Loading embeddings model..\")\n",
        "fasttext_model = fasttext.load_model('cc.en.300.bin')\n",
        "embedding_matrix = np.zeros(shape=((MAX_WORDS + 2), 300))          # +2 because we have reserved indices for padding and out-of-vocabulary tokens\n",
        "\n",
        "for key, value in word_idx.items():\n",
        "    if value <= MAX_WORDS:\n",
        "        embedding_matrix[value] = fasttext_model.get_word_vector(word=key)            #create embedding matrix\n",
        "\n",
        "del fasttext_model      #save memory"
      ],
      "metadata": {
        "id": "_7CLC2WIkh_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create one-hot vectors"
      ],
      "metadata": {
        "id": "Hw7_uglhosv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "target_list = z\n",
        "\n",
        "y_train_1_hot = lb.fit_transform([target_list[x] for x in y_train])\n",
        "y_dev_1_hot = lb.transform([target_list[x] for x in y_dev])\n",
        "\n",
        "#y_train_1_hot = np.argmax(y_train_1_hot, axis=1)\n",
        "#y_dev_1_hot = np.argmax(y_dev_1_hot, axis=1)\n",
        "\n",
        "#print('y_dev_1_hot:', y_dev_1_hot)                             #prints vertically\n",
        "print('y_dev_1_hot:', ' '.join(map(str, y_dev_1_hot)))          #prints horizontally\n"
      ],
      "metadata": {
        "id": "aCVGePpfnQsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, valid_data):\n",
        "        super(Metrics, self).__init__()\n",
        "        self.validation_data = valid_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
        "        val_targ = self.validation_data[1]\n",
        "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
        "            val_targ = np.argmax(val_targ, -1)\n",
        "        val_targ = tf.cast(val_targ,dtype=tf.float32)\n",
        "        _val_f1 = f1_score(val_targ, val_predict,average=\"weighted\")\n",
        "        _val_recall = recall_score(val_targ, val_predict,average=\"weighted\")\n",
        "        _val_precision = precision_score(val_targ, val_predict,average=\"weighted\")\n",
        "        logs['val_f1'] = _val_f1\n",
        "        logs['val_recall'] = _val_recall\n",
        "        logs['val_precision'] = _val_precision\n",
        "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
        "        return"
      ],
      "metadata": {
        "id": "ixmTyQKcpT_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Self attention class"
      ],
      "metadata": {
        "id": "KENECgWVtMBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Layer\n",
        "\n",
        "class SelfAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, mlp_layers=0, units=0, dropout_rate=0, return_attention=False, **kwargs):\n",
        "    super(SelfAttention, self).__init__(**kwargs)\n",
        "    self.mlp_layers = mlp_layers\n",
        "    self.mlp_units = units\n",
        "    self.return_attention = return_attention\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.attention_mlp = self.build_mlp()\n",
        "\n",
        "  def build_mlp(self):\n",
        "    mlp = Sequential()\n",
        "    for i in range(self.mlp_layers):\n",
        "      mlp.add(Dense(self.mlp_units, activation='relu'))\n",
        "      mlp.add(Dropout(self.dropout_rate))\n",
        "    mlp.add(Dense(1))\n",
        "    return mlp\n",
        "\n",
        "  def call(self, x, mask=None):\n",
        "    a = self.attention_mlp(x)\n",
        "    a = tf.squeeze(a, axis=2)\n",
        "\n",
        "    if mask is not None:\n",
        "      mask = tf.keras.backend.cast(mask, tf.keras.backend.floatx())\n",
        "      a -= 100000.0 * (1.0 - mask)\n",
        "\n",
        "    a = tf.keras.backend.expand_dims(tf.keras.backend.softmax(a, axis=-1))\n",
        "    weighted_input = x * a\n",
        "    result = tf.keras.backend.sum(weighted_input, axis=1)\n",
        "\n",
        "    if self.return_attention:\n",
        "      return [result, a]\n",
        "    return result"
      ],
      "metadata": {
        "id": "zD27L6NItPC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "y_dev = tf.keras.utils.to_categorical(y_dev, num_classes=2)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)"
      ],
      "metadata": {
        "id": "zjeoicRn2rd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNN model"
      ],
      "metadata": {
        "id": "AnC0EFNQ4-5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(hp):\n",
        "    GRU_SIZE = hp.Int('gru_size', min_value=100, max_value=500, step=50)\n",
        "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.05)\n",
        "    mlp_layers = hp.Int('mlp_layers', min_value=1, max_value=5, step=1)\n",
        "    mlp_units = hp.Int('mlp_units', min_value=64, max_value=512, step=64)\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(\n",
        "        tf.keras.layers.Embedding(\n",
        "            MAX_WORDS+2,\n",
        "            EMBEDDING_DIM,\n",
        "            weights=[embedding_matrix],\n",
        "            input_length=MAX_SEQUENCE_LENGTH,\n",
        "            mask_zero=True,\n",
        "            trainable=False\n",
        "        )\n",
        "    )\n",
        "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(\n",
        "        tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.GRU(\n",
        "                GRU_SIZE,\n",
        "                return_sequences=True,\n",
        "                recurrent_dropout=dropout_rate\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(SelfAttention(mlp_layers=mlp_layers, units=mlp_units))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        metrics=[\"categorical_accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ih5jqOZz4uUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameter search with Keras Tuner"
      ],
      "metadata": {
        "id": "i2xh27gH5vcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "SbM7UBKW7IrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_categorical_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='keras_tuner_logs',\n",
        "    project_name='hyperparameter_tuning_gru_self_attention'\n",
        ")\n",
        "\n",
        "\n",
        "tuner.search(\n",
        "    train_pad,\n",
        "    y_train,\n",
        "    validation_data=(dev_pad, y_dev),\n",
        "    batch_size=256,\n",
        "    epochs=50,\n",
        "    shuffle=True,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=10, restore_best_weights=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "Vmt3o1f95uzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_gru_size = best_hp.get('gru_size')\n",
        "best_dropout_rate = best_hp.get('dropout_rate')\n",
        "best_mlp_layers = best_hp.get('mlp_layers')\n",
        "best_mlp_units = best_hp.get('mlp_units')\n",
        "\n",
        "print(\"Best hyperparameters:\")\n",
        "print(\"GRU Size:\", best_gru_size)\n",
        "print(\"Dropout Rate:\", best_dropout_rate)\n",
        "print(\"MLP Layers:\", best_mlp_layers)\n",
        "print(\"MLP Units:\", best_mlp_units)\n"
      ],
      "metadata": {
        "id": "mV8wW-T0mBKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_trial = tuner.get_best_trials(num_trials=1)[0]\n",
        "\n",
        "best_model_history = best_trial.keras_model.history.history\n"
      ],
      "metadata": {
        "id": "-5Wb1XXbmsbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualize Model's Training History"
      ],
      "metadata": {
        "id": "w2--OyLgivIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "98j0z4o1ixKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Metrics (Precision, Recall, F1, AUC)"
      ],
      "metadata": {
        "id": "wSi7FQFdi2VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "train_probs = best_model.predict(X_train_svd)                       #Predict probs for training,dev and test\n",
        "dev_probs = best_model.predict(X_dev_svd)\n",
        "test_probs = best_model.predict(X_test_svd)\n",
        "\n",
        "\n",
        "train_preds = (train_probs > 0.5).astype(int)                                 #To get binary predictions\n",
        "dev_preds = (dev_probs > 0.5).astype(int)\n",
        "test_preds = (test_probs > 0.5).astype(int)\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average=None)\n",
        "    recall = recall_score(y_true, y_pred, average=None)\n",
        "    f1 = f1_score(y_true, y_pred, average=None)\n",
        "    return precision, recall, f1\n",
        "\n",
        "train_precision, train_recall, train_f1 = calculate_metrics(y_train, train_preds)\n",
        "dev_precision, dev_recall, dev_f1 = calculate_metrics(y_dev, dev_preds)\n",
        "test_precision, test_recall, test_f1 = calculate_metrics(y_test, test_preds)\n",
        "\n",
        "\n",
        "def calculate_pr_auc(y_true, y_probs):\n",
        "    pr_auc_scores = []\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
        "    pr_auc_scores.append(auc(recall, precision))\n",
        "    return pr_auc_scores\n",
        "\n",
        "train_pr_auc = calculate_pr_auc(y_train, train_probs)\n",
        "dev_pr_auc = calculate_pr_auc(y_dev, dev_probs)\n",
        "test_pr_auc = calculate_pr_auc(y_test, test_probs)"
      ],
      "metadata": {
        "id": "ycBt3UW6i4YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "    print(\"Class \", z[i], \":   (Training)     (Development)      (Test)\")\n",
        "    print(f\"Precision    |  {train_precision[i]:.6f}   |    {dev_precision[i]:.6f}    |   {test_precision[i]:.6f}\")\n",
        "    print(f\"Recall       |  {train_recall[i]:.6f}   |    {dev_recall[i]:.6f}    |   {test_recall[i]:.6f}\")\n",
        "    print(f\"F1-score     |  {train_f1[i]:.6f}   |    {dev_f1[i]:.6f}    |   {test_f1[i]:.6f}\")\n",
        "    print(f\"PR AUC       |  {train_pr_auc[i-1]:.6f}   |    {dev_pr_auc[i-1]:.6f}    |   {test_pr_auc[i-1]:.6f}\")\n",
        "    print(\"-------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "L2N69b-ri6kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_macro_averaged_scores(y_true, y_pred, y_probs):\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, average=None)\n",
        "    recall = recall_score(y_true, y_pred, average=None)\n",
        "    f1 = f1_score(y_true, y_pred, average=None)\n",
        "\n",
        "    def calculate_pr_auc(y_true, y_probs):\n",
        "        precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
        "        pr_auc = auc(recall, precision)\n",
        "        return pr_auc\n",
        "\n",
        "    pr_auc = calculate_pr_auc(y_true, y_probs)\n",
        "\n",
        "\n",
        "    macro_avg_precision = np.mean(precision)\n",
        "    macro_avg_recall = np.mean(recall)\n",
        "    macro_avg_f1 = np.mean(f1)\n",
        "    macro_avg_pr_auc = np.mean(pr_auc)\n",
        "\n",
        "    return macro_avg_precision, macro_avg_recall, macro_avg_f1, macro_avg_pr_auc\n",
        "\n",
        "train_macro_avg_precision, train_macro_avg_recall, train_macro_avg_f1, train_macro_avg_pr_auc = calculate_macro_averaged_scores(y_train, train_preds, train_probs)\n",
        "dev_macro_avg_precision, dev_macro_avg_recall, dev_macro_avg_f1, dev_macro_avg_pr_auc = calculate_macro_averaged_scores(y_dev, dev_preds, dev_probs)\n",
        "test_macro_avg_precision, test_macro_avg_recall, test_macro_avg_f1, test_macro_avg_pr_auc = calculate_macro_averaged_scores(y_test, test_preds, test_probs)\n",
        "\n",
        "\n",
        "print(\"Macro-averaged Scores for Training Subset:\")\n",
        "print(\"===========================================\")\n",
        "print(f\"Macro-averaged Precision: {train_macro_avg_precision:.6f}\")\n",
        "print(f\"Macro-averaged Recall: {train_macro_avg_recall:.6f}\")\n",
        "print(f\"Macro-averaged F1-score: {train_macro_avg_f1:.6f}\")\n",
        "print(f\"Macro-averaged PR AUC: {train_macro_avg_pr_auc:.6f}\")\n",
        "print()\n",
        "\n",
        "print(\"Macro-averaged Scores for Development Subset:\")\n",
        "print(\"===============================================\")\n",
        "print(f\"Macro-averaged Precision: {dev_macro_avg_precision:.6f}\")\n",
        "print(f\"Macro-averaged Recall: {dev_macro_avg_recall:.6f}\")\n",
        "print(f\"Macro-averaged F1-score: {dev_macro_avg_f1:.6f}\")\n",
        "print(f\"Macro-averaged PR AUC: {dev_macro_avg_pr_auc:.6f}\")\n",
        "print()\n",
        "\n",
        "print(\"Macro-averaged Scores for Test Subset:\")\n",
        "print(\"========================================\")\n",
        "print(f\"Macro-averaged Precision: {test_macro_avg_precision:.6f}\")\n",
        "print(f\"Macro-averaged Recall: {test_macro_avg_recall:.6f}\")\n",
        "print(f\"Macro-averaged F1-score: {test_macro_avg_f1:.6f}\")\n",
        "print(f\"Macro-averaged PR AUC: {test_macro_avg_pr_auc:.6f}\")"
      ],
      "metadata": {
        "id": "jAsYRaLJjBpi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}