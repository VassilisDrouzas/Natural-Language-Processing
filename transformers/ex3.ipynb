{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics: 5th Assignment (Part 2: Exercise 3)\n",
    "## MSc in Data Science (2023/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 11:41:29.567118: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-09 11:41:29.567271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-09 11:41:29.654132: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-09 11:41:29.857099: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-09 11:41:31.411432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tasks.preprocessing, tasks.models, tasks.tuning, tasks.util\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "INPUT_DIR = \"input\"\n",
    "INPUT_MODEL_PATH = os.path.join(INPUT_DIR, \"models\")\n",
    "OUTPUT_DIR = \"output\"\n",
    "INTERMEDIATE_DIR = \"intermediate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing with  /physical_device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 11:41:33.528440: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-09 11:41:33.846910: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-09 11:41:33.847809: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"Executing with \", gpus[0].name if len(gpus) != 0 else \"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Acquiring and preprocessing our data with the goal of eventually acquiring a sufficient representation of our text is the most difficult and time-consuming task. We thus split it in distinct phases:\n",
    "\n",
    "* Original dataset acquisition and parsing\n",
    "* Qualitative analysis and preprocessing\n",
    "* Transformation for the NLP task\n",
    "\n",
    "Note that due to the relative custom code complexity, most of the code used in this section was developed and imported from python source files located in the `tasks` module. In-depth documentation and implementation details can be found in these files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset...\n",
      "\tReading data...\n",
      "\tParsing data...\n",
      "\tGetting words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b81bce3354f4204ab577adb3df3ec02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting POS tags...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88fae08431344a78a22ff691cd14830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting Sentence ids...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f761d33d0746b5a84fe2a6546a11cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation dataset...\n",
      "\tReading data...\n",
      "\tParsing data...\n",
      "\tGetting words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eac126792942f2a9e8303bb7858989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting POS tags...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315a7620e69e4d259bffa057040413d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting Sentence ids...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97865accf18e4bd88dc44118ddaf4d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset...\n",
      "\tReading data...\n",
      "\tParsing data...\n",
      "\tGetting words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c15442242e64150ad116fec144dc562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting POS tags...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7a71bbeb4f40e69699db5bc4be691a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting Sentence ids...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b2293084f1491da018617cef4bf715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (207227, 3)\n",
      "Validation data shape: (25511, 3)\n",
      "Test data shape: {test_df.shape}\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training dataset...\")\n",
    "train_df = tasks.preprocessing.conllu_to_pd(\n",
    "    \"input/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    ")\n",
    "print(\"Loading validation dataset...\")\n",
    "val_df = tasks.preprocessing.conllu_to_pd(\n",
    "    \"input/UD_English-EWT/en_ewt-ud-dev.conllu\"\n",
    ")\n",
    "print(\"Loading test dataset...\")\n",
    "test_df = tasks.preprocessing.conllu_to_pd(\n",
    "    \"input/UD_English-EWT/en_ewt-ud-test.conllu\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Training data shape: {train_df.shape}\\nValidation data shape: {val_df.shape}\"\n",
    "    \"\\nTest data shape: {test_df.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see a preview of our parsed training dataset. Our preprocessing exploits pandas's ordering scheme in order to make sure the words are inserted in the order they appear in the sentence. This ordering will prove important later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>al</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zaman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207222</th>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207223</th>\n",
       "      <td>my</td>\n",
       "      <td>PRON</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207224</th>\n",
       "      <td>car</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207225</th>\n",
       "      <td>)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207226</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207227 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           words    pos                                            sent_id\n",
       "0             al  PROPN  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "1              -  PUNCT  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "2          zaman  PROPN  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "3              :  PUNCT  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "4       american    ADJ  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "...          ...    ...                                                ...\n",
       "207222        on    ADP                                reviews-319816-0029\n",
       "207223        my   PRON                                reviews-319816-0029\n",
       "207224       car   NOUN                                reviews-319816-0029\n",
       "207225         )  PUNCT                                reviews-319816-0029\n",
       "207226         .  PUNCT                                reviews-319816-0029\n",
       "\n",
       "[207227 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, our dataset features words connected with punctuation such as \"don't\". These are normally treated as two words, with the first being their intuitive POS tag (\"do\" - AUX) and the second as part of the first (\"n't\" - PART).\n",
    "\n",
    "This dataset contains both the full words and their split versions, with only the latter featuring valid POS tags. The former are instead marked by a pseudo-tag (here \"_\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>won't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-blogspot.com_healingiraq_20040409053012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-blogspot.com_healingiraq_20040409053012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>doesn't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-blogspot.com_healingiraq_20040409053012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207078</th>\n",
       "      <td>couldn't</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207091</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207096</th>\n",
       "      <td>employees'</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207164</th>\n",
       "      <td>i'm</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207186</th>\n",
       "      <td>didn't</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             words pos                                            sent_id\n",
       "176          don't   _  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "704          won't   _  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "868          don't   _  weblog-blogspot.com_healingiraq_20040409053012...\n",
       "1058         don't   _  weblog-blogspot.com_healingiraq_20040409053012...\n",
       "1078       doesn't   _  weblog-blogspot.com_healingiraq_20040409053012...\n",
       "...            ...  ..                                                ...\n",
       "207078    couldn't   _                                reviews-319816-0025\n",
       "207091       don't   _                                reviews-319816-0025\n",
       "207096  employees'   _                                reviews-319816-0025\n",
       "207164         i'm   _                                reviews-319816-0027\n",
       "207186      didn't   _                                reviews-319816-0028\n",
       "\n",
       "[2613 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_idx = train_df.pos == \"_\"\n",
    "train_df[invalid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"don't won't doesn't haven't didn't others it's elena's women's children's i'm people's musharraf's sharon's hamas's right's cannot isn't one's let's reporter's he's that's pakistan's world's bush's military's sharif's can't couldn't\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(train_df[invalid_idx].words.unique()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see an example of a word being contained both times in the dataset, one in full with the pseudo-tag, and the other as split words with valid POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>do</td>\n",
       "      <td>AUX</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>n't</td>\n",
       "      <td>PART</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words   pos                                            sent_id\n",
       "176  don't     _  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "177     do   AUX  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "178    n't  PART  weblog-juancole.com_juancole_20051126063000_EN..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[176:179]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thus remove the full words including the pseudo-tag from our datasets, ensuring that all target POS tags will be compliant with the UPOS scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~invalid_idx]\n",
    "val_df = val_df[val_df.pos != \"_\"]\n",
    "test_df = test_df[test_df.pos != \"_\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analysis\n",
    "\n",
    "We analyze our dataset in two granualities: sentences and individual words. We begin by analyzing how many words are in each sentence, which will give us an idea on the size of context available for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_sentences(df: pd.DataFrame) -> float:\n",
    "    lengths = df.groupby([\"sent_id\"]).agg(lambda x: len(x))\n",
    "    return lengths.words\n",
    "\n",
    "\n",
    "train_length = length_sentences(train_df)\n",
    "val_length = length_sentences(val_df)\n",
    "test_length = length_sentences(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to output/ex_2_dataset_stats.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame({\"words\": pd.concat([train_length, val_length, test_length], ignore_index=True),\n",
    "                        \"type\": len(train_length)*[\"train\"] +\n",
    "                         len(val_length)*[\"validation\"] + \n",
    "                         len(test_length)*[\"test\"]})\n",
    "\n",
    "sns.histplot(x=\"words\", \n",
    "             hue=\"type\", \n",
    "             data=stats_df, \n",
    "             multiple=\"stack\")\n",
    "\n",
    "plt.title(\"Number of sentences by word count\")\n",
    "tasks.util.save_plot(\"ex_2_dataset_stats.png\", OUTPUT_DIR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the graph above, there is a sizable portion of our sentences that feature very few words. In order to make the RNN training more efficient, we choose to discard sentences with very few words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_small_sentences(conllu_df: pd.DataFrame, min_len: int) -> pd.DataFrame:\n",
    "    assert 1 <= min_len\n",
    "\n",
    "    length_df = length_sentences(conllu_df)\n",
    "    valid_length_df = length_df[length_df >= min_len]\n",
    "    valid_ids = set(valid_length_df.index)\n",
    "    return conllu_df[conllu_df.sent_id.isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SENTENCE_LENGTH = 5\n",
    "\n",
    "train_df = exclude_small_sentences(train_df, MIN_SENTENCE_LENGTH)\n",
    "val_df = exclude_small_sentences(val_df, MIN_SENTENCE_LENGTH)\n",
    "test_df = exclude_small_sentences(test_df, MIN_SENTENCE_LENGTH)\n",
    "\n",
    "train_length = length_sentences(train_df)\n",
    "val_length = length_sentences(val_df)\n",
    "test_length = length_sentences(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10539.000000\n",
       "mean        18.967170\n",
       "std         11.782365\n",
       "min          5.000000\n",
       "25%         10.000000\n",
       "50%         16.000000\n",
       "75%         24.000000\n",
       "max        159.000000\n",
       "Name: words, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1538.000000\n",
       "mean       15.607932\n",
       "std        10.050704\n",
       "min         5.000000\n",
       "25%         8.000000\n",
       "50%        13.000000\n",
       "75%        20.000000\n",
       "max        75.000000\n",
       "Name: words, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1535.000000\n",
       "mean       15.512052\n",
       "std        10.332400\n",
       "min         5.000000\n",
       "25%         8.000000\n",
       "50%        13.000000\n",
       "75%        20.000000\n",
       "max        81.000000\n",
       "Name: words, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 15967\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(set(train_df.words))\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count:\n",
      "Training: 199895\n",
      "Validation: 24005\n",
      "Testing: 23811\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total word count:\\nTraining: {train_df.shape[0]}\"\n",
    "      f\"\\nValidation: {val_df.shape[0]}\"\n",
    "      f\"\\nTesting: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentence count:\n",
      "Training: 10539\n",
      "Validation: 1538\n",
      "Testing: 1535\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total sentence count:\\nTraining: {len(set(train_df.sent_id))}\"\n",
    "      f\"\\nValidation: {len(set(val_df.sent_id))}\"\n",
    "      f\"\\nTesting: {len(set(test_df.sent_id))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "In order to make the RNN training more efficient, we choose to discard sentences with very few words. We also set a window size equal to the 90\\% percentile of sentence word count, meaning tht 90\\% of our windows will fully fit the training sentences. The rest will be automatically split into more sentences, and as such don't need to be excluded from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = int(np.quantile(train_length, 0.9))\n",
    "MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a combination of the `keras.preprocessing.Tokenizer` and `keras.utils.pad_sequences` utilities to create custom windows of words to be fed to our model, since it uses Time Distributed outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(tokenizer, values):\n",
    "    return tokenizer.texts_to_sequences(values)\n",
    "\n",
    "\n",
    "def encode_with_padding(tokenizer, max_seq_len, values):\n",
    "    tokens = encode(tokenizer, values)\n",
    "    padded_tokens = keras.utils.pad_sequences(\n",
    "        tokens, maxlen=max_seq_len, padding=\"pre\", truncating=\"post\"\n",
    "    )\n",
    "    return padded_tokens\n",
    "\n",
    "\n",
    "def decode(tokenizer, encoded_sequence, axis=2):\n",
    "    return np.array(\n",
    "        [\n",
    "            tokenizer.index_word[str(x[-1])]\n",
    "            for x in np.argmax(encoded_sequence, axis=axis)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode X\n",
    "word_tokenizer = keras.preprocessing.text.Tokenizer(filters=\"\")\n",
    "word_tokenizer.fit_on_texts(train_df.words.values)\n",
    "\n",
    "train_data = encode_with_padding(\n",
    "    word_tokenizer, MAX_SEQUENCE_LENGTH, train_df.words.values\n",
    ")\n",
    "val_data = encode_with_padding(\n",
    "    word_tokenizer, MAX_SEQUENCE_LENGTH, val_df.words.values\n",
    ")\n",
    "test_data = encode_with_padding(\n",
    "    word_tokenizer, MAX_SEQUENCE_LENGTH, test_df.words.values\n",
    ")\n",
    "\n",
    "tag_tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(train_df.pos.values)\n",
    "\n",
    "# start label counting from 0, since to_categorical assumes argmax = number_of_categories\n",
    "tag_tokenizer.word_index = {\n",
    "    key: value - 1 for key, value in tag_tokenizer.word_index.items()\n",
    "}\n",
    "\n",
    "# start label counting from 0, since to_categorical assumes argmax = number_of_categories\n",
    "tag_tokenizer.index_word = {\n",
    "    str(int(key) - 1): value for key, value in tag_tokenizer.index_word.items()\n",
    "}\n",
    "\n",
    "y_train = keras.utils.to_categorical(\n",
    "    encode_with_padding(tag_tokenizer, MAX_SEQUENCE_LENGTH, train_df.pos.values)\n",
    ")\n",
    "y_valid = keras.utils.to_categorical(\n",
    "    encode_with_padding(tag_tokenizer, MAX_SEQUENCE_LENGTH, val_df.pos.values)\n",
    ")\n",
    "y_test = keras.utils.to_categorical(\n",
    "    encode_with_padding(tag_tokenizer, MAX_SEQUENCE_LENGTH, test_df.pos.values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noun': 0,\n",
       " 'punct': 1,\n",
       " 'verb': 2,\n",
       " 'pron': 3,\n",
       " 'adp': 4,\n",
       " 'det': 5,\n",
       " 'adj': 6,\n",
       " 'aux': 7,\n",
       " 'propn': 8,\n",
       " 'adv': 9,\n",
       " 'cconj': 10,\n",
       " 'part': 11,\n",
       " 'sconj': 12,\n",
       " 'num': 13,\n",
       " 'sym': 14,\n",
       " 'intj': 15,\n",
       " 'x': 16}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that counting is continuous starting from 0\n",
    "tag_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199895, 34, 17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaselineLabelClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaselineLabelClassifier</label><div class=\"sk-toggleable__content\"><pre>BaselineLabelClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaselineLabelClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tasks.models import BaselineLabelClassifier\n",
    "\n",
    "\n",
    "x_base_train = train_df.words\n",
    "x_base_valid = val_df.words\n",
    "x_base_test = test_df.words\n",
    "\n",
    "y_base_train = train_df.pos\n",
    "y_base_valid = val_df.pos\n",
    "y_base_test = test_df.pos\n",
    "\n",
    "base_cls = BaselineLabelClassifier()\n",
    "base_cls.fit(X=x_base_train, y=y_base_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.89      0.89     12854\n",
      "         ADP       0.88      0.67      0.76     17732\n",
      "         ADV       0.61      0.83      0.70      9995\n",
      "         AUX       0.88      0.78      0.83     12746\n",
      "       CCONJ       0.98      0.99      0.99      6656\n",
      "         DET       0.96      0.95      0.95     16228\n",
      "        INTJ       0.65      0.86      0.74       572\n",
      "        NOUN       0.88      0.90      0.89     34011\n",
      "         NUM       0.99      0.88      0.93      3753\n",
      "        PART       0.71      0.89      0.79      5734\n",
      "        PRON       0.90      0.95      0.92     18479\n",
      "       PROPN       0.89      0.83      0.86     11289\n",
      "       PUNCT       0.99      0.99      0.99     22574\n",
      "       SCONJ       0.64      0.42      0.50      3836\n",
      "         SYM       0.89      0.83      0.86       668\n",
      "        VERB       0.83      0.89      0.86     22363\n",
      "           X       0.82      0.58      0.68       405\n",
      "\n",
      "    accuracy                           0.87    199895\n",
      "   macro avg       0.85      0.83      0.83    199895\n",
      "weighted avg       0.88      0.87      0.87    199895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "training_preds = base_cls.predict(x_base_train)\n",
    "print(classification_report(y_base_train, training_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.82      0.85      1666\n",
      "         ADP       0.89      0.67      0.76      2013\n",
      "         ADV       0.62      0.83      0.71      1131\n",
      "         AUX       0.89      0.78      0.83      1521\n",
      "       CCONJ       0.99      0.98      0.99       726\n",
      "         DET       0.96      0.95      0.96      1870\n",
      "        INTJ       0.66      0.73      0.69        86\n",
      "        NOUN       0.67      0.89      0.77      3909\n",
      "         NUM       0.96      0.55      0.70       485\n",
      "        PART       0.70      0.90      0.78       632\n",
      "        PRON       0.91      0.95      0.93      2118\n",
      "       PROPN       0.88      0.48      0.62      1753\n",
      "       PUNCT       0.99      0.98      0.99      2794\n",
      "       SCONJ       0.60      0.44      0.51       382\n",
      "         SYM       0.82      0.86      0.84       101\n",
      "        VERB       0.80      0.82      0.81      2544\n",
      "           X       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.83     23811\n",
      "   macro avg       0.78      0.74      0.75     23811\n",
      "weighted avg       0.84      0.83      0.82     23811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = base_cls.predict(x_base_test)\n",
    "print(classification_report(y_base_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we use is the pre-trained optimal model used in the previous assignment. We follow the same preprocessing and caching steps as in the previous assignment. Since the model is not trained again, we use only a subset of the original training data (25,000 windows) in order to save on scare main-memory resources. We consider this a representative sample for comparison with other classifiers due to the sample size (law of large numbers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_small_sentences(conllu_df: pd.DataFrame, min_len: int) -> pd.DataFrame:\n",
    "    assert 1 <= min_len\n",
    "\n",
    "    length_df = length_sentences(conllu_df)\n",
    "    valid_length_df = length_df[length_df >= min_len]\n",
    "    valid_ids = set(valid_length_df.index)\n",
    "    return conllu_df[conllu_df.sent_id.isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5\n",
    "# training data are used exclusively for training accuracy, thus\n",
    "# we only need a small, representative sample\n",
    "TRAINING_LIM = 25000\n",
    "VALID_LIM = 25000\n",
    "TEST_LIM = 10000\n",
    "SEED = 42\n",
    "PAD_TOKEN = \"<PAD>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘input/fasttext/cc.en.300.bin.gz’ already there; not retrieving.\n",
      "\n",
      "Skipping model file\n"
     ]
    }
   ],
   "source": [
    "# download and unzip only if the download and unzipped files do not exist \n",
    "!wget -nc -P input/fasttext https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
    "\n",
    "![ -f \"input/fasttext/cc.en.300.bin\" ] && echo \"Skipping model file\" || gzip --decompress --keep --force \"input/fasttext/cc.en.300.bin.gz\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "\n",
    "print(\"Loading embedding model...\")\n",
    "fasttext_model = fasttext.load_model(\"input/fasttext/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load intermediate calculations...\n",
      "Loaded cached calculations.\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    x_train_mlp,\n",
    "    x_valid_mlp,\n",
    "    x_test_mlp,\n",
    "    y_train_mlp,\n",
    "    y_valid_mlp,\n",
    "    y_test_mlp,\n",
    "    lb_mlp,\n",
    ") = tasks.preprocessing.mlp_input(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    embed_model=fasttext_model,\n",
    "    intermediate_dir=INTERMEDIATE_DIR,\n",
    "    train_lim=TRAINING_LIM,\n",
    "    val_lim=VALID_LIM,\n",
    "    test_lim=TEST_LIM,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    seed=SEED,\n",
    "    pad_token=PAD_TOKEN,\n",
    ")\n",
    "\n",
    "del fasttext_model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mlp = keras.saving.load_model(os.path.join(INPUT_MODEL_PATH, \"mlp_model.keras\"))\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        lb_mlp.inverse_transform(y_train_mlp),\n",
    "        lb_mlp.inverse_transform(mlp.predict(x_train_mlp)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        lb_mlp.inverse_transform(y_test_mlp),\n",
    "        lb_mlp.inverse_transform(mlp.predict(x_test_mlp)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rnn_model = keras.saving.load_model(\n",
    "    os.path.join(INPUT_MODEL_PATH, \"rnn_model.keras\")\n",
    ")\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        decode(tag_tokenizer, y_train),\n",
    "        decode(tag_tokenizer, rnn_model.predict(train_data)),\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        decode(tag_tokenizer, y_test),\n",
    "        decode(tag_tokenizer, rnn_model.predict(test_data)),\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnn_model = keras.saving.load_model(\n",
    "    os.path.join(INPUT_MODEL_PATH, \"rnn_model.keras\")\n",
    ")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        decode(tag_tokenizer, y_train),\n",
    "        decode(tag_tokenizer, cnn_model.predict(train_data)),\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        decode(tag_tokenizer, y_test),\n",
    "        decode(tag_tokenizer, cnn_model.predict(test_data)),\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dataframe to individual sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c70748b5e34f36aaee248ef288741a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c95edbf8b774f0389a8dc52b668290f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9a14cf7ea9484dbd690e8987eac73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0021f94cab1d4b03aef1a04bd4cc436d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b563f8d99e4660a16599d372a57dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285deeedffb34a13801372b1ecd4f45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'words'],\n",
       "        num_rows: 10539\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['labels', 'words'],\n",
       "        num_rows: 1538\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'words'],\n",
       "        num_rows: 1535\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "\n",
    "def encode_bert(df, col_name):\n",
    "    sentences = []\n",
    "\n",
    "    for sentence_id in tqdm(set(df.sent_id)):\n",
    "        words_df = df[df.sent_id == sentence_id]\n",
    "        sentence = list(words_df[col_name])\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def decode_bert(encoded_sequence, num_classes):\n",
    "    # create dummy class for -100 tokens\n",
    "    return keras.utils.to_categorical(\n",
    "        [x if x != -100 else num_classes for x in encoded_sequence.flatten()],\n",
    "        num_classes=num_classes + 1,\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Converting dataframe to individual sentences...\")\n",
    "data_dict = datasets.DatasetDict(\n",
    "    {\n",
    "        \"train\": datasets.Dataset.from_dict(\n",
    "            {\n",
    "                \"labels\": tag_tokenizer.texts_to_sequences(\n",
    "                    encode_bert(train_df, \"pos\")\n",
    "                ),\n",
    "                \"words\": encode_bert(train_df, \"words\"),\n",
    "            }\n",
    "        ),\n",
    "        \"val\": datasets.Dataset.from_dict(\n",
    "            {\n",
    "                \"labels\": tag_tokenizer.texts_to_sequences(\n",
    "                    encode_bert(val_df, \"pos\")\n",
    "                ),\n",
    "                \"words\": encode_bert(val_df, \"words\"),\n",
    "            }\n",
    "        ),\n",
    "        \"test\": datasets.Dataset.from_dict(\n",
    "            {\n",
    "                \"labels\": tag_tokenizer.texts_to_sequences(\n",
    "                    encode_bert(test_df, \"pos\")\n",
    "                ),\n",
    "                \"words\": encode_bert(test_df, \"words\"),\n",
    "            }\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return transformers.AutoModelForTokenClassification.from_pretrained(\n",
    "        \"TweebankNLP/bertweet-tb2_ewt-pos-tagging\",\n",
    "        num_labels=len(train_df.pos.unique()),\n",
    "    )\n",
    "\n",
    "\n",
    "bert_tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"bert-base-uncased\", use_fast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be890df95d1f40bdade9d5c01fab4b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10539 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70efdbbe196a409981021472bc512417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adc9b51fc254784b8fffb4bd9c13715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'words', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10539\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['labels', 'words', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1538\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'words', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1535\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = bert_tokenizer(\n",
    "        examples[\"words\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(\n",
    "            batch_index=i\n",
    "        )  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif (\n",
    "                word_idx != previous_word_idx\n",
    "            ):  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_data_dict = data_dict.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = decode_bert(pred.label_ids, len(np.unique(pred.label_ids)))\n",
    "    preds = decode_bert(pred.predictions.argmax(-1), len(np.unique(pred.label_ids)))\n",
    "\n",
    "    # ignore dummy label\n",
    "    mask = labels[:, -1] != 1\n",
    "    labels = labels[mask]\n",
    "    preds = preds[mask]\n",
    "\n",
    "    # calculate accuracy using sklearn's function\n",
    "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
    "    precision = sklearn.metrics.precision_score(\n",
    "        labels, preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    recall = sklearn.metrics.recall_score(\n",
    "        labels, preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    f1 = sklearn.metrics.f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"val_accuracy\": acc,\n",
    "        \"val_precision\": precision,\n",
    "        \"val_recall\": recall,\n",
    "        \"val_f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,  # output directory\n",
    "    num_train_epochs=8,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    gradient_accumulation_steps=2,  # Number of update steps (forward passes) to accumulate the gradients for, before performing a backward/update pass\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=\"./logs\",  # directory for storing logs\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    evaluation_strategy=transformers.IntervalStrategy.STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = \"val_accuracy\",\n",
    "    save_total_limit=3,\n",
    "    learning_rate=1e-5,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model_init=model_init,  # the instantiated Transformers model to be trained\n",
    "    args=training_args,  # training arguments, as defined above\n",
    "    train_dataset=tokenized_data_dict[\"train\"],  # training dataset\n",
    "    eval_dataset=tokenized_data_dict[\"val\"],  # evaluation dataset\n",
    "    tokenizer=bert_tokenizer,  # tokenizer\n",
    "    data_collator=data_collator, # batch creator (padding)\n",
    "    callbacks=[\n",
    "        transformers.EarlyStoppingCallback(early_stopping_patience=5)\n",
    "    ], \n",
    "   compute_metrics=compute_metrics    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 11:47:11,869] A new study created in memory with name: no-name-cea47390-d15f-4646-99d4-79d5908072fa\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c966c83b8e8745f9ae9cc3257c746c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d9f19a62404f499c7acd4b8dcbec17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7855286598205566, 'eval_val_accuracy': 0.7420486851457001, 'eval_val_precision': 0.6436000662109692, 'eval_val_recall': 0.5624943335360132, 'eval_val_f1': 0.5794552313608649, 'eval_runtime': 13.98, 'eval_samples_per_second': 110.014, 'eval_steps_per_second': 6.938, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c9908036fb4addad4b60543cf4296f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5491995215415955, 'eval_val_accuracy': 0.8252931769722814, 'eval_val_precision': 0.7089417826188233, 'eval_val_recall': 0.6477136343199547, 'eval_val_f1': 0.6648279561722148, 'eval_runtime': 13.9175, 'eval_samples_per_second': 110.509, 'eval_steps_per_second': 6.97, 'epoch': 0.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522c3529a406483a8d934b56d07b470c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43769571185112, 'eval_val_accuracy': 0.8636282871357498, 'eval_val_precision': 0.7251704719172064, 'eval_val_recall': 0.6873500738238798, 'eval_val_f1': 0.7012577114200716, 'eval_runtime': 13.9587, 'eval_samples_per_second': 110.182, 'eval_steps_per_second': 6.949, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f58a0a1743d4933be4740acbbe83f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41166946291923523, 'eval_val_accuracy': 0.8765991471215352, 'eval_val_precision': 0.7879206492287505, 'eval_val_recall': 0.7025176605059255, 'eval_val_f1': 0.7230999289261388, 'eval_runtime': 13.953, 'eval_samples_per_second': 110.227, 'eval_steps_per_second': 6.952, 'epoch': 1.21}\n",
      "{'loss': 0.8433, 'grad_norm': 1.339958906173706, 'learning_rate': 0.000592989464776177, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81143d0e0c04820be6c1c5ebd9db6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4374358654022217, 'eval_val_accuracy': 0.8800639658848614, 'eval_val_precision': 0.7791601980815785, 'eval_val_recall': 0.7051983705077944, 'eval_val_f1': 0.7231620959657015, 'eval_runtime': 13.8554, 'eval_samples_per_second': 111.004, 'eval_steps_per_second': 7.001, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa7e0eabb0e4206b3147ea9b5dc5f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5081492066383362, 'eval_val_accuracy': 0.8393301350390903, 'eval_val_precision': 0.7743219820869819, 'eval_val_recall': 0.6623284789338575, 'eval_val_f1': 0.6957359672308772, 'eval_runtime': 14.0004, 'eval_samples_per_second': 109.854, 'eval_steps_per_second': 6.928, 'epoch': 1.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc69d1e78a64b808db3e1f40bc5afdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49796947836875916, 'eval_val_accuracy': 0.8564321250888415, 'eval_val_precision': 0.7534132251188099, 'eval_val_recall': 0.6876076237779378, 'eval_val_f1': 0.7068614036446129, 'eval_runtime': 14.0101, 'eval_samples_per_second': 109.778, 'eval_steps_per_second': 6.924, 'epoch': 2.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2058095028449c9229afe09d772c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37769070267677307, 'eval_val_accuracy': 0.8984097370291401, 'eval_val_precision': 0.7892683016751727, 'eval_val_recall': 0.7234947496415655, 'eval_val_f1': 0.7463240414083024, 'eval_runtime': 13.9662, 'eval_samples_per_second': 110.123, 'eval_steps_per_second': 6.945, 'epoch': 2.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e90737aebe49258fabca75a5c9458b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33524855971336365, 'eval_val_accuracy': 0.9027629708599858, 'eval_val_precision': 0.7915693662055702, 'eval_val_recall': 0.735986057562483, 'eval_val_f1': 0.7522205962541079, 'eval_runtime': 13.4349, 'eval_samples_per_second': 114.478, 'eval_steps_per_second': 7.22, 'epoch': 2.73}\n",
      "{'loss': 0.3479, 'grad_norm': 0.8488474488258362, 'learning_rate': 0.00045392064095437184, 'epoch': 3.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173501856b2d471fbb90a1c011b5f0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35294726490974426, 'eval_val_accuracy': 0.9080046197583511, 'eval_val_precision': 0.7769540136420386, 'eval_val_recall': 0.7551727669850687, 'eval_val_f1': 0.7628733979917508, 'eval_runtime': 13.2756, 'eval_samples_per_second': 115.852, 'eval_steps_per_second': 7.307, 'epoch': 3.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42deedc6ac94600bf5078ea0510a00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.369390070438385, 'eval_val_accuracy': 0.9039179104477612, 'eval_val_precision': 0.7768079563265794, 'eval_val_recall': 0.7587805062816754, 'eval_val_f1': 0.763277119555549, 'eval_runtime': 13.428, 'eval_samples_per_second': 114.537, 'eval_steps_per_second': 7.224, 'epoch': 3.34}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2b9c792c7649c2b8d59fd7735aa5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3398725092411041, 'eval_val_accuracy': 0.9112473347547975, 'eval_val_precision': 0.7840879007230156, 'eval_val_recall': 0.7635358776177162, 'eval_val_f1': 0.7695838115239555, 'eval_runtime': 13.442, 'eval_samples_per_second': 114.418, 'eval_steps_per_second': 7.216, 'epoch': 3.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f1586700d748319c1eb32026239d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31598100066185, 'eval_val_accuracy': 0.915911513859275, 'eval_val_precision': 0.7910962659203333, 'eval_val_recall': 0.7644486897653885, 'eval_val_f1': 0.776277779081397, 'eval_runtime': 13.4249, 'eval_samples_per_second': 114.563, 'eval_steps_per_second': 7.225, 'epoch': 3.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6266ad7c9ce54925a617f4e1c0178990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3571102023124695, 'eval_val_accuracy': 0.9108475479744137, 'eval_val_precision': 0.771839324142565, 'eval_val_recall': 0.7596359855058459, 'eval_val_f1': 0.7639641374989853, 'eval_runtime': 13.3992, 'eval_samples_per_second': 114.783, 'eval_steps_per_second': 7.239, 'epoch': 4.25}\n",
      "{'loss': 0.2209, 'grad_norm': 0.8428144454956055, 'learning_rate': 0.00031485181713256674, 'epoch': 4.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a3d8918f7d4a03be4c7eb89086fc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.329332560300827, 'eval_val_accuracy': 0.9183546552949537, 'eval_val_precision': 0.7909526873487455, 'eval_val_recall': 0.7700354024871741, 'eval_val_f1': 0.7790633649012214, 'eval_runtime': 13.3693, 'eval_samples_per_second': 115.04, 'eval_steps_per_second': 7.255, 'epoch': 4.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3b75ca4a604da18119f2d9c88bb17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3495434522628784, 'eval_val_accuracy': 0.9167555081734187, 'eval_val_precision': 0.8046772828972696, 'eval_val_recall': 0.7682388924147846, 'eval_val_f1': 0.7804383848339738, 'eval_runtime': 13.4243, 'eval_samples_per_second': 114.568, 'eval_steps_per_second': 7.226, 'epoch': 4.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7d262bf777497f8a595794e2324e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36273518204689026, 'eval_val_accuracy': 0.9157338308457711, 'eval_val_precision': 0.7958900805864261, 'eval_val_recall': 0.7709491597900417, 'eval_val_f1': 0.7767730654620774, 'eval_runtime': 13.4852, 'eval_samples_per_second': 114.051, 'eval_steps_per_second': 7.193, 'epoch': 5.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f830f49d27674ee1a81192e4f40f1e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36439377069473267, 'eval_val_accuracy': 0.9183546552949537, 'eval_val_precision': 0.7912186655506604, 'eval_val_recall': 0.7744668164432336, 'eval_val_f1': 0.7750648390806367, 'eval_runtime': 13.3956, 'eval_samples_per_second': 114.813, 'eval_steps_per_second': 7.241, 'epoch': 5.46}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1781626d9b354bfa8e98e37284839d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3739423155784607, 'eval_val_accuracy': 0.9193319118692252, 'eval_val_precision': 0.8014772124453905, 'eval_val_recall': 0.76595497015096, 'eval_val_f1': 0.776532637973563, 'eval_runtime': 13.4456, 'eval_samples_per_second': 114.387, 'eval_steps_per_second': 7.214, 'epoch': 5.77}\n",
      "{'loss': 0.0959, 'grad_norm': 0.6719498038291931, 'learning_rate': 0.00017578299331076167, 'epoch': 6.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df149a01b3e4139b6da878cbc58e206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3716049790382385, 'eval_val_accuracy': 0.9196428571428571, 'eval_val_precision': 0.7915779680418684, 'eval_val_recall': 0.7708191400038006, 'eval_val_f1': 0.7800049365707257, 'eval_runtime': 13.262, 'eval_samples_per_second': 115.971, 'eval_steps_per_second': 7.314, 'epoch': 6.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cd182d6e3342d7a15b981c4cbde9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3930085003376007, 'eval_val_accuracy': 0.9216862117981521, 'eval_val_precision': 0.7973007053622213, 'eval_val_recall': 0.7716362158552804, 'eval_val_f1': 0.7825040301556708, 'eval_runtime': 13.389, 'eval_samples_per_second': 114.87, 'eval_steps_per_second': 7.245, 'epoch': 6.37}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cccaacb6f5a43af9838b455de9287da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3913128674030304, 'eval_val_accuracy': 0.921863894811656, 'eval_val_precision': 0.796277803516149, 'eval_val_recall': 0.7764016990069095, 'eval_val_f1': 0.7822151260356615, 'eval_runtime': 13.4242, 'eval_samples_per_second': 114.569, 'eval_steps_per_second': 7.226, 'epoch': 6.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18c76dad1db4b2cae5a72bdebdb9a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4312909245491028, 'eval_val_accuracy': 0.9034737029140014, 'eval_val_precision': 0.7776359239422341, 'eval_val_recall': 0.7495712948379605, 'eval_val_f1': 0.761341572716824, 'eval_runtime': 13.3981, 'eval_samples_per_second': 114.792, 'eval_steps_per_second': 7.24, 'epoch': 6.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0509ad42cb4722ae492ab2064c1ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4452034533023834, 'eval_val_accuracy': 0.9053393745557925, 'eval_val_precision': 0.7692905254129127, 'eval_val_recall': 0.7586783571859692, 'eval_val_f1': 0.7629806236785954, 'eval_runtime': 13.4456, 'eval_samples_per_second': 114.387, 'eval_steps_per_second': 7.214, 'epoch': 7.28}\n",
      "{'loss': 0.0609, 'grad_norm': 0.28794601559638977, 'learning_rate': 3.671416948895655e-05, 'epoch': 7.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdaf47709aa4127bcf2fbc0afb8dc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4652267098426819, 'eval_val_accuracy': 0.8967661691542289, 'eval_val_precision': 0.7581738492805086, 'eval_val_recall': 0.7550017069568312, 'eval_val_f1': 0.7557078461692347, 'eval_runtime': 13.863, 'eval_samples_per_second': 110.943, 'eval_steps_per_second': 6.997, 'epoch': 7.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74936ea23e84e6f8ddc2eff35147044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4336656332015991, 'eval_val_accuracy': 0.9078713574982231, 'eval_val_precision': 0.7746966130496945, 'eval_val_recall': 0.762270397405351, 'eval_val_f1': 0.7672471403490156, 'eval_runtime': 14.0217, 'eval_samples_per_second': 109.687, 'eval_steps_per_second': 6.918, 'epoch': 7.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 12:33:59,945] Trial 0 finished with value: 3.2120855083022843 and parameters: {'learning_rate': 0.000594380153014395, 'weight_decay': 0.05678478274860766, 'warmup_steps': 495}. Best is trial 0 with value: 3.2120855083022843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2806.8899, 'train_samples_per_second': 30.038, 'train_steps_per_second': 0.938, 'train_loss': 0.30135765010462706, 'epoch': 7.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63612bf08b7420e84a056163576af81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cae10b2d3b453fbb8100bad05b7cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7798710465431213, 'eval_val_accuracy': 0.7432036247334755, 'eval_val_precision': 0.6632668847533815, 'eval_val_recall': 0.5558582903507913, 'eval_val_f1': 0.58077716501827, 'eval_runtime': 13.9644, 'eval_samples_per_second': 110.137, 'eval_steps_per_second': 6.946, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbfecba483040418758bcfa4fca0c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.507061779499054, 'eval_val_accuracy': 0.8388859275053305, 'eval_val_precision': 0.7093111925426188, 'eval_val_recall': 0.6536080613771987, 'eval_val_f1': 0.6661779269429711, 'eval_runtime': 13.9825, 'eval_samples_per_second': 109.994, 'eval_steps_per_second': 6.937, 'epoch': 0.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee60384e48f14914a2de3f194a715272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43675413727760315, 'eval_val_accuracy': 0.869314143567875, 'eval_val_precision': 0.7290871394935565, 'eval_val_recall': 0.6841285504589876, 'eval_val_f1': 0.6999786833815417, 'eval_runtime': 14.0851, 'eval_samples_per_second': 109.193, 'eval_steps_per_second': 6.887, 'epoch': 0.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc70e06eae545509fd945e8c240b1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3880676329135895, 'eval_val_accuracy': 0.8836176261549396, 'eval_val_precision': 0.7976478550217072, 'eval_val_recall': 0.7196684314468865, 'eval_val_f1': 0.7299417465348155, 'eval_runtime': 14.0297, 'eval_samples_per_second': 109.624, 'eval_steps_per_second': 6.914, 'epoch': 1.21}\n",
      "{'loss': 0.8064, 'grad_norm': 1.2219971418380737, 'learning_rate': 0.00022279551771948444, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735e6f2ced794a9a936cfc7512af07fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3697710633277893, 'eval_val_accuracy': 0.8922796730632552, 'eval_val_precision': 0.7883366175944813, 'eval_val_recall': 0.733132791756162, 'eval_val_f1': 0.7502059008368004, 'eval_runtime': 13.9208, 'eval_samples_per_second': 110.482, 'eval_steps_per_second': 6.968, 'epoch': 1.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70d2b25c7564e04b75ccd124a1a8f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3235538601875305, 'eval_val_accuracy': 0.90227434257285, 'eval_val_precision': 0.7684717916807894, 'eval_val_recall': 0.7549843692204596, 'eval_val_f1': 0.7584938478190996, 'eval_runtime': 14.0299, 'eval_samples_per_second': 109.623, 'eval_steps_per_second': 6.914, 'epoch': 1.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab9e5b267de49d48b0863d6b4d8aac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33253908157348633, 'eval_val_accuracy': 0.906183368869936, 'eval_val_precision': 0.7740760360893467, 'eval_val_recall': 0.769249001288005, 'eval_val_f1': 0.7695573835563841, 'eval_runtime': 13.9779, 'eval_samples_per_second': 110.031, 'eval_steps_per_second': 6.94, 'epoch': 2.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6299d535050f40699352f29c630d21e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30588147044181824, 'eval_val_accuracy': 0.9124466950959488, 'eval_val_precision': 0.7944435845843819, 'eval_val_recall': 0.7598407300224036, 'eval_val_f1': 0.7707065720213303, 'eval_runtime': 13.9642, 'eval_samples_per_second': 110.139, 'eval_steps_per_second': 6.946, 'epoch': 2.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4dd48476ee427796efa465f4405456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3292745053768158, 'eval_val_accuracy': 0.910270078180526, 'eval_val_precision': 0.7699999121344702, 'eval_val_recall': 0.769531339685076, 'eval_val_f1': 0.7631882205029651, 'eval_runtime': 14.094, 'eval_samples_per_second': 109.125, 'eval_steps_per_second': 6.882, 'epoch': 2.73}\n",
      "{'loss': 0.1855, 'grad_norm': 0.8826872110366821, 'learning_rate': 0.00017054516178151904, 'epoch': 3.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f08725d061a4237b32920429f7bfcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3285481929779053, 'eval_val_accuracy': 0.9193319118692252, 'eval_val_precision': 0.7830740067978985, 'eval_val_recall': 0.7806615110776202, 'eval_val_f1': 0.7804675936771035, 'eval_runtime': 13.8809, 'eval_samples_per_second': 110.8, 'eval_steps_per_second': 6.988, 'epoch': 3.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c4e81090554873bcb76d8e74e3261a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3371947109699249, 'eval_val_accuracy': 0.917866027007818, 'eval_val_precision': 0.7931862212503992, 'eval_val_recall': 0.7749646288749931, 'eval_val_f1': 0.7816392959919266, 'eval_runtime': 14.0964, 'eval_samples_per_second': 109.106, 'eval_steps_per_second': 6.881, 'epoch': 3.34}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6336a4405d74a2c8d2ef8a58d351db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33012786507606506, 'eval_val_accuracy': 0.9152007818052594, 'eval_val_precision': 0.7816587510950598, 'eval_val_recall': 0.7753731743075999, 'eval_val_f1': 0.7764288799287684, 'eval_runtime': 13.9501, 'eval_samples_per_second': 110.25, 'eval_steps_per_second': 6.953, 'epoch': 3.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9555ca7d43ba4a6a9dd0e2690e8b9bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3210579752922058, 'eval_val_accuracy': 0.9173329779673063, 'eval_val_precision': 0.7889596790136096, 'eval_val_recall': 0.7804313837668536, 'eval_val_f1': 0.7830435437464636, 'eval_runtime': 13.9782, 'eval_samples_per_second': 110.028, 'eval_steps_per_second': 6.939, 'epoch': 3.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393c7e809d1f43ea8c7d54f0b0f1f2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33778116106987, 'eval_val_accuracy': 0.9188432835820896, 'eval_val_precision': 0.8008133637193515, 'eval_val_recall': 0.7668094520719615, 'eval_val_f1': 0.7779327118956172, 'eval_runtime': 13.9926, 'eval_samples_per_second': 109.915, 'eval_steps_per_second': 6.932, 'epoch': 4.25}\n",
      "{'loss': 0.0847, 'grad_norm': 1.6530063152313232, 'learning_rate': 0.00011829480584355365, 'epoch': 4.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bff1a7824a485da65d82adde44222f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3386022448539734, 'eval_val_accuracy': 0.9194207533759773, 'eval_val_precision': 0.7960614193755151, 'eval_val_recall': 0.7865637978092603, 'eval_val_f1': 0.7908087176248121, 'eval_runtime': 13.8617, 'eval_samples_per_second': 110.953, 'eval_steps_per_second': 6.998, 'epoch': 4.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a870378255040119a4ebc6ff45da0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34321752190589905, 'eval_val_accuracy': 0.9186211798152096, 'eval_val_precision': 0.7869566278852529, 'eval_val_recall': 0.7830528435862756, 'eval_val_f1': 0.783802163132293, 'eval_runtime': 14.0718, 'eval_samples_per_second': 109.297, 'eval_steps_per_second': 6.893, 'epoch': 4.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d290b5f59d3648bbb3cc3c4236fb741b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3652850091457367, 'eval_val_accuracy': 0.9216862117981521, 'eval_val_precision': 0.7909874157272834, 'eval_val_recall': 0.7854856688381332, 'eval_val_f1': 0.7875095723460761, 'eval_runtime': 13.9932, 'eval_samples_per_second': 109.91, 'eval_steps_per_second': 6.932, 'epoch': 5.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf0f6befb2c4ff280e9c1b361389737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36605405807495117, 'eval_val_accuracy': 0.9225302061122956, 'eval_val_precision': 0.7979635288596176, 'eval_val_recall': 0.7800088057745276, 'eval_val_f1': 0.7875409489287397, 'eval_runtime': 13.9623, 'eval_samples_per_second': 110.154, 'eval_steps_per_second': 6.947, 'epoch': 5.46}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670298a4503d4039b9387b65c6e0b890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38887014985084534, 'eval_val_accuracy': 0.9228411513859275, 'eval_val_precision': 0.8017240986100523, 'eval_val_recall': 0.7834810384883145, 'eval_val_f1': 0.7890466907974049, 'eval_runtime': 14.036, 'eval_samples_per_second': 109.576, 'eval_steps_per_second': 6.911, 'epoch': 5.77}\n",
      "{'loss': 0.0404, 'grad_norm': 0.3718189299106598, 'learning_rate': 6.604444990558824e-05, 'epoch': 6.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67379692cb7f4beb80162f85283a2226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3729333281517029, 'eval_val_accuracy': 0.9253731343283582, 'eval_val_precision': 0.8071942440778862, 'eval_val_recall': 0.7851071285802366, 'eval_val_f1': 0.7934144808764831, 'eval_runtime': 13.8667, 'eval_samples_per_second': 110.913, 'eval_steps_per_second': 6.995, 'epoch': 6.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb364b5b83b479db5456dbc71061dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4056183695793152, 'eval_val_accuracy': 0.9240849324804549, 'eval_val_precision': 0.7989019064570302, 'eval_val_recall': 0.7905362612537162, 'eval_val_f1': 0.7928425993745044, 'eval_runtime': 14.079, 'eval_samples_per_second': 109.241, 'eval_steps_per_second': 6.89, 'epoch': 6.37}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3847fb3a1d4683b776f9fec8fed185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.397192120552063, 'eval_val_accuracy': 0.9253731343283582, 'eval_val_precision': 0.8041297185183138, 'eval_val_recall': 0.7870936693831251, 'eval_val_f1': 0.7936896739059877, 'eval_runtime': 14.0712, 'eval_samples_per_second': 109.302, 'eval_steps_per_second': 6.894, 'epoch': 6.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47a8ebff83048c784385e4b6075abc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40790054202079773, 'eval_val_accuracy': 0.9246179815209666, 'eval_val_precision': 0.8032742932597695, 'eval_val_recall': 0.7863288035397921, 'eval_val_f1': 0.7905790409961557, 'eval_runtime': 13.9953, 'eval_samples_per_second': 109.894, 'eval_steps_per_second': 6.931, 'epoch': 6.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7f4e41238e47b6a4d80fd8ea529133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4333247244358063, 'eval_val_accuracy': 0.923862828713575, 'eval_val_precision': 0.7997739942119978, 'eval_val_recall': 0.7794992162196902, 'eval_val_f1': 0.7876831673859421, 'eval_runtime': 14.0024, 'eval_samples_per_second': 109.838, 'eval_steps_per_second': 6.927, 'epoch': 7.28}\n",
      "{'loss': 0.0149, 'grad_norm': 0.23032887279987335, 'learning_rate': 1.3794093967622863e-05, 'epoch': 7.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d30712377444bd9383114c5a6dea1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4177839756011963, 'eval_val_accuracy': 0.9249289267945985, 'eval_val_precision': 0.7994603200396937, 'eval_val_recall': 0.7801634605933107, 'eval_val_f1': 0.7885140979123438, 'eval_runtime': 13.8488, 'eval_samples_per_second': 111.056, 'eval_steps_per_second': 7.004, 'epoch': 7.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-09 13:20:25,101] Trial 1 finished with value: 3.2930668053399463 and parameters: {'learning_rate': 0.00025341422629913214, 'weight_decay': 1.5042573820551697e-05, 'warmup_steps': 207}. Best is trial 1 with value: 3.2930668053399463.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2784.0612, 'train_samples_per_second': 30.284, 'train_steps_per_second': 0.945, 'train_loss': 0.22637739143371582, 'epoch': 7.59}\n"
     ]
    }
   ],
   "source": [
    "def get_search_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-5, 0.1, log=True),\n",
    "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 100, 500, log=True),\n",
    "    }\n",
    "\n",
    "# default objective is loss on validation set\n",
    "best_run = trainer.hyperparameter_search(\n",
    "    direction=\"maximize\", backend=\"optuna\", n_trials=2, hp_space=get_search_space\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386f985dca2648cda656cf8db2b3eb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 3.95 GiB of which 64.00 KiB is free. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Of the allocated memory 3.66 GiB is allocated by PyTorch, and 171.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 32\u001b[0m\n\u001b[1;32m      1\u001b[0m optimal_training_args \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mOUTPUT_DIR,  \n\u001b[1;32m      3\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,  \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     learning_rate \u001b[38;5;241m=\u001b[39m best_run\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     20\u001b[0m     model_init\u001b[38;5;241m=\u001b[39mmodel_init,  \u001b[38;5;66;03m# the instantiated Transformers model to be trained\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     args\u001b[38;5;241m=\u001b[39moptimal_training_args,  \u001b[38;5;66;03m# training arguments, as defined above\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m    compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics    \n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1967\u001b[0m ):\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/trainer.py:2902\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2901\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2902\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2905\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/trainer.py:2925\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2924\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2925\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1390\u001b[0m, in \u001b[0;36mRobertaForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1390\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1402\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1404\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:835\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    829\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    830\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    834\u001b[0m )\n\u001b[0;32m--> 835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    848\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    513\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    514\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    515\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         output_attentions,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:413\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    403\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:340\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    332\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    339\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 340\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    350\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:270\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    266\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/nn/functional.py:1268\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 3.95 GiB of which 64.00 KiB is free. Including non-PyTorch memory, this process has 3.88 GiB memory in use. Of the allocated memory 3.66 GiB is allocated by PyTorch, and 171.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "optimal_training_args = transformers.TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,  \n",
    "    num_train_epochs=8,  \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16, \n",
    "    gradient_accumulation_steps=2, \n",
    "    logging_dir=\"./logs/final\",  \n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    evaluation_strategy=transformers.IntervalStrategy.STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = \"val_accuracy\",\n",
    "    save_total_limit=3,\n",
    "    warmup_steps = best_run.hyperparameters[\"warmup_steps\"],\n",
    "    weight_decay = best_run.hyperparameters[\"weight_decay\"],\n",
    "    learning_rate = best_run.hyperparameters[\"learning_rate\"]\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model_init=model_init,  # the instantiated Transformers model to be trained\n",
    "    args=optimal_training_args,  # training arguments, as defined above\n",
    "    train_dataset=tokenized_data_dict[\"train\"],  # training dataset\n",
    "    eval_dataset=tokenized_data_dict[\"val\"],  # evaluation dataset\n",
    "    tokenizer=bert_tokenizer,  # tokenizer\n",
    "    data_collator=data_collator, # batch creator (padding)\n",
    "    callbacks=[\n",
    "        transformers.EarlyStoppingCallback(early_stopping_patience=5)\n",
    "    ], \n",
    "   compute_metrics=compute_metrics    \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
