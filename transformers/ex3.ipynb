{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics: 5th Assignment (Part 2: Exercise 3)\n",
    "## MSc in Data Science (2023/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 20:03:41.160670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-08 20:03:41.160894: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-08 20:03:41.237912: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-08 20:03:41.407134: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-08 20:03:43.089472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tasks.preprocessing, tasks.models, tasks.tuning, tasks.util\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "INPUT_DIR = \"input\"\n",
    "INPUT_MODEL_PATH = os.path.join(INPUT_DIR, \"models\")\n",
    "OUTPUT_DIR = \"output\"\n",
    "INTERMEDIATE_DIR = \"intermediate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing with  /physical_device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 20:03:45.196248: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 20:03:45.550503: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 20:03:45.551727: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"Executing with \", gpus[0].name if len(gpus) != 0 else \"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Acquiring and preprocessing our data with the goal of eventually acquiring a sufficient representation of our text is the most difficult and time-consuming task. We thus split it in distinct phases:\n",
    "\n",
    "* Original dataset acquisition and parsing\n",
    "* Qualitative analysis and preprocessing\n",
    "* Transformation for the NLP task\n",
    "\n",
    "Note that due to the relative custom code complexity, most of the code used in this section was developed and imported from python source files located in the `tasks` module. In-depth documentation and implementation details can be found in these files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset...\n",
      "\tReading data...\n",
      "\tParsing data...\n",
      "\tGetting words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054fa0ece6b94017b9b187d184634910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting POS tags...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2daf8fee449460dad1123de53af4670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting Sentence ids...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5215e1637bbd4aafa6d36af3d33f1dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation dataset...\n",
      "\tReading data...\n",
      "\tParsing data...\n",
      "\tGetting words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342465cc7bfb4c749777c6436457f7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting POS tags...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ea63f404c3491f8efd81c48d41e126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting Sentence ids...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757fb0043eed415bb4a03492ed20a4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset...\n",
      "\tReading data...\n",
      "\tParsing data...\n",
      "\tGetting words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f820c9d3eb114bb3989a41bda6d0c9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting POS tags...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d97af0906d44a8a22915d628b318ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGetting Sentence ids...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434ee93e07b2443481cd2e89c352e4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (207227, 3)\n",
      "Validation data shape: (25511, 3)\n",
      "Test data shape: {test_df.shape}\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training dataset...\")\n",
    "train_df = tasks.preprocessing.conllu_to_pd(\n",
    "    \"input/UD_English-EWT/en_ewt-ud-train.conllu\"\n",
    ")\n",
    "print(\"Loading validation dataset...\")\n",
    "val_df = tasks.preprocessing.conllu_to_pd(\n",
    "    \"input/UD_English-EWT/en_ewt-ud-dev.conllu\"\n",
    ")\n",
    "print(\"Loading test dataset...\")\n",
    "test_df = tasks.preprocessing.conllu_to_pd(\n",
    "    \"input/UD_English-EWT/en_ewt-ud-test.conllu\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Training data shape: {train_df.shape}\\nValidation data shape: {val_df.shape}\"\n",
    "    \"\\nTest data shape: {test_df.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see a preview of our parsed training dataset. Our preprocessing exploits pandas's ordering scheme in order to make sure the words are inserted in the order they appear in the sentence. This ordering will prove important later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>al</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zaman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207222</th>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207223</th>\n",
       "      <td>my</td>\n",
       "      <td>PRON</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207224</th>\n",
       "      <td>car</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207225</th>\n",
       "      <td>)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207226</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>reviews-319816-0029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207227 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           words    pos                                            sent_id\n",
       "0             al  PROPN  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "1              -  PUNCT  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "2          zaman  PROPN  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "3              :  PUNCT  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "4       american    ADJ  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "...          ...    ...                                                ...\n",
       "207222        on    ADP                                reviews-319816-0029\n",
       "207223        my   PRON                                reviews-319816-0029\n",
       "207224       car   NOUN                                reviews-319816-0029\n",
       "207225         )  PUNCT                                reviews-319816-0029\n",
       "207226         .  PUNCT                                reviews-319816-0029\n",
       "\n",
       "[207227 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, our dataset features words connected with punctuation such as \"don't\". These are normally treated as two words, with the first being their intuitive POS tag (\"do\" - AUX) and the second as part of the first (\"n't\" - PART).\n",
    "\n",
    "This dataset contains both the full words and their split versions, with only the latter featuring valid POS tags. The former are instead marked by a pseudo-tag (here \"_\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>won't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-blogspot.com_healingiraq_20040409053012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-blogspot.com_healingiraq_20040409053012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>doesn't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-blogspot.com_healingiraq_20040409053012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207078</th>\n",
       "      <td>couldn't</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207091</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207096</th>\n",
       "      <td>employees'</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207164</th>\n",
       "      <td>i'm</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207186</th>\n",
       "      <td>didn't</td>\n",
       "      <td>_</td>\n",
       "      <td>reviews-319816-0028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             words pos                                            sent_id\n",
       "176          don't   _  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "704          won't   _  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "868          don't   _  weblog-blogspot.com_healingiraq_20040409053012...\n",
       "1058         don't   _  weblog-blogspot.com_healingiraq_20040409053012...\n",
       "1078       doesn't   _  weblog-blogspot.com_healingiraq_20040409053012...\n",
       "...            ...  ..                                                ...\n",
       "207078    couldn't   _                                reviews-319816-0025\n",
       "207091       don't   _                                reviews-319816-0025\n",
       "207096  employees'   _                                reviews-319816-0025\n",
       "207164         i'm   _                                reviews-319816-0027\n",
       "207186      didn't   _                                reviews-319816-0028\n",
       "\n",
       "[2613 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_idx = train_df.pos == \"_\"\n",
    "train_df[invalid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"don't won't doesn't haven't didn't others it's elena's women's children's i'm people's musharraf's sharon's hamas's right's cannot isn't one's let's reporter's he's that's pakistan's world's bush's military's sharif's can't couldn't\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(train_df[invalid_idx].words.unique()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see an example of a word being contained both times in the dataset, one in full with the pseudo-tag, and the other as split words with valid POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>pos</th>\n",
       "      <th>sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>don't</td>\n",
       "      <td>_</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>do</td>\n",
       "      <td>AUX</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>n't</td>\n",
       "      <td>PART</td>\n",
       "      <td>weblog-juancole.com_juancole_20051126063000_EN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words   pos                                            sent_id\n",
       "176  don't     _  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "177     do   AUX  weblog-juancole.com_juancole_20051126063000_EN...\n",
       "178    n't  PART  weblog-juancole.com_juancole_20051126063000_EN..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[176:179]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thus remove the full words including the pseudo-tag from our datasets, ensuring that all target POS tags will be compliant with the UPOS scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~invalid_idx]\n",
    "val_df = val_df[val_df.pos != \"_\"]\n",
    "test_df = test_df[test_df.pos != \"_\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analysis\n",
    "\n",
    "We analyze our dataset in two granualities: sentences and individual words. We begin by analyzing how many words are in each sentence, which will give us an idea on the size of context available for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_sentences(df: pd.DataFrame) -> float:\n",
    "    lengths = df.groupby([\"sent_id\"]).agg(lambda x: len(x))\n",
    "    return lengths.words\n",
    "\n",
    "\n",
    "train_length = length_sentences(train_df)\n",
    "val_length = length_sentences(val_df)\n",
    "test_length = length_sentences(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to output/ex_2_dataset_stats.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame({\"words\": pd.concat([train_length, val_length, test_length], ignore_index=True),\n",
    "                        \"type\": len(train_length)*[\"train\"] +\n",
    "                         len(val_length)*[\"validation\"] + \n",
    "                         len(test_length)*[\"test\"]})\n",
    "\n",
    "sns.histplot(x=\"words\", \n",
    "             hue=\"type\", \n",
    "             data=stats_df, \n",
    "             multiple=\"stack\")\n",
    "\n",
    "plt.title(\"Number of sentences by word count\")\n",
    "tasks.util.save_plot(\"ex_2_dataset_stats.png\", OUTPUT_DIR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the graph above, there is a sizable portion of our sentences that feature very few words. In order to make the RNN training more efficient, we choose to discard sentences with very few words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_small_sentences(conllu_df: pd.DataFrame, min_len: int) -> pd.DataFrame:\n",
    "    assert 1 <= min_len\n",
    "\n",
    "    length_df = length_sentences(conllu_df)\n",
    "    valid_length_df = length_df[length_df >= min_len]\n",
    "    valid_ids = set(valid_length_df.index)\n",
    "    return conllu_df[conllu_df.sent_id.isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SENTENCE_LENGTH = 5\n",
    "\n",
    "train_df = exclude_small_sentences(train_df, MIN_SENTENCE_LENGTH)\n",
    "val_df = exclude_small_sentences(val_df, MIN_SENTENCE_LENGTH)\n",
    "test_df = exclude_small_sentences(test_df, MIN_SENTENCE_LENGTH)\n",
    "\n",
    "train_length = length_sentences(train_df)\n",
    "val_length = length_sentences(val_df)\n",
    "test_length = length_sentences(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10539.000000\n",
       "mean        18.967170\n",
       "std         11.782365\n",
       "min          5.000000\n",
       "25%         10.000000\n",
       "50%         16.000000\n",
       "75%         24.000000\n",
       "max        159.000000\n",
       "Name: words, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1538.000000\n",
       "mean       15.607932\n",
       "std        10.050704\n",
       "min         5.000000\n",
       "25%         8.000000\n",
       "50%        13.000000\n",
       "75%        20.000000\n",
       "max        75.000000\n",
       "Name: words, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1535.000000\n",
       "mean       15.512052\n",
       "std        10.332400\n",
       "min         5.000000\n",
       "25%         8.000000\n",
       "50%        13.000000\n",
       "75%        20.000000\n",
       "max        81.000000\n",
       "Name: words, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 15967\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(set(train_df.words))\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count:\n",
      "Training: 199895\n",
      "Validation: 24005\n",
      "Testing: 23811\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total word count:\\nTraining: {train_df.shape[0]}\"\n",
    "      f\"\\nValidation: {val_df.shape[0]}\"\n",
    "      f\"\\nTesting: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentence count:\n",
      "Training: 10539\n",
      "Validation: 1538\n",
      "Testing: 1535\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total sentence count:\\nTraining: {len(set(train_df.sent_id))}\"\n",
    "      f\"\\nValidation: {len(set(val_df.sent_id))}\"\n",
    "      f\"\\nTesting: {len(set(test_df.sent_id))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "In order to make the RNN training more efficient, we choose to discard sentences with very few words. We also set a window size equal to the 90\\% percentile of sentence word count, meaning tht 90\\% of our windows will fully fit the training sentences. The rest will be automatically split into more sentences, and as such don't need to be excluded from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = int(np.quantile(train_length, 0.9))\n",
    "MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a combination of the `keras.preprocessing.Tokenizer` and `keras.utils.pad_sequences` utilities to create custom windows of words to be fed to our model, since it uses Time Distributed outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(tokenizer, values):\n",
    "    return tokenizer.texts_to_sequences(values)\n",
    "\n",
    "\n",
    "def encode_with_padding(tokenizer, max_seq_len, values):\n",
    "    tokens = encode(tokenizer, values)\n",
    "    padded_tokens = keras.utils.pad_sequences(\n",
    "        tokens, maxlen=max_seq_len, padding=\"pre\", truncating=\"post\"\n",
    "    )\n",
    "    return padded_tokens\n",
    "\n",
    "\n",
    "def decode(tokenizer, encoded_sequence, axis=2):\n",
    "    return np.array(\n",
    "        [\n",
    "            tokenizer.index_word[str(x[-1])]\n",
    "            for x in np.argmax(encoded_sequence, axis=axis)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode X\n",
    "word_tokenizer = keras.preprocessing.text.Tokenizer(filters=\"\")\n",
    "word_tokenizer.fit_on_texts(train_df.words.values)\n",
    "\n",
    "train_data = encode_with_padding(\n",
    "    word_tokenizer, MAX_SEQUENCE_LENGTH, train_df.words.values\n",
    ")\n",
    "val_data = encode_with_padding(\n",
    "    word_tokenizer, MAX_SEQUENCE_LENGTH, val_df.words.values\n",
    ")\n",
    "test_data = encode_with_padding(\n",
    "    word_tokenizer, MAX_SEQUENCE_LENGTH, test_df.words.values\n",
    ")\n",
    "\n",
    "tag_tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(train_df.pos.values)\n",
    "\n",
    "# start label counting from 0, since to_categorical assumes argmax = number_of_categories\n",
    "tag_tokenizer.word_index = {\n",
    "    key: value - 1 for key, value in tag_tokenizer.word_index.items()\n",
    "}\n",
    "\n",
    "# start label counting from 0, since to_categorical assumes argmax = number_of_categories\n",
    "tag_tokenizer.index_word = {\n",
    "    str(int(key) - 1): value for key, value in tag_tokenizer.index_word.items()\n",
    "}\n",
    "\n",
    "y_train = keras.utils.to_categorical(\n",
    "    encode_with_padding(tag_tokenizer, MAX_SEQUENCE_LENGTH, train_df.pos.values)\n",
    ")\n",
    "y_valid = keras.utils.to_categorical(\n",
    "    encode_with_padding(tag_tokenizer, MAX_SEQUENCE_LENGTH, val_df.pos.values)\n",
    ")\n",
    "y_test = keras.utils.to_categorical(\n",
    "    encode_with_padding(tag_tokenizer, MAX_SEQUENCE_LENGTH, test_df.pos.values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noun': 0,\n",
       " 'punct': 1,\n",
       " 'verb': 2,\n",
       " 'pron': 3,\n",
       " 'adp': 4,\n",
       " 'det': 5,\n",
       " 'adj': 6,\n",
       " 'aux': 7,\n",
       " 'propn': 8,\n",
       " 'adv': 9,\n",
       " 'cconj': 10,\n",
       " 'part': 11,\n",
       " 'sconj': 12,\n",
       " 'num': 13,\n",
       " 'sym': 14,\n",
       " 'intj': 15,\n",
       " 'x': 16}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that counting is continuous starting from 0\n",
    "tag_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199895, 34, 17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaselineLabelClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaselineLabelClassifier</label><div class=\"sk-toggleable__content\"><pre>BaselineLabelClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaselineLabelClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tasks.models import BaselineLabelClassifier\n",
    "\n",
    "\n",
    "x_base_train = train_df.words\n",
    "x_base_valid = val_df.words\n",
    "x_base_test = test_df.words\n",
    "\n",
    "y_base_train = train_df.pos\n",
    "y_base_valid = val_df.pos\n",
    "y_base_test = test_df.pos\n",
    "\n",
    "base_cls = BaselineLabelClassifier()\n",
    "base_cls.fit(X=x_base_train, y=y_base_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.89      0.89     12854\n",
      "         ADP       0.88      0.67      0.76     17732\n",
      "         ADV       0.61      0.83      0.70      9995\n",
      "         AUX       0.88      0.78      0.83     12746\n",
      "       CCONJ       0.98      0.99      0.99      6656\n",
      "         DET       0.96      0.95      0.95     16228\n",
      "        INTJ       0.65      0.86      0.74       572\n",
      "        NOUN       0.88      0.90      0.89     34011\n",
      "         NUM       0.99      0.88      0.93      3753\n",
      "        PART       0.71      0.89      0.79      5734\n",
      "        PRON       0.90      0.95      0.92     18479\n",
      "       PROPN       0.89      0.83      0.86     11289\n",
      "       PUNCT       0.99      0.99      0.99     22574\n",
      "       SCONJ       0.64      0.42      0.50      3836\n",
      "         SYM       0.89      0.83      0.86       668\n",
      "        VERB       0.83      0.89      0.86     22363\n",
      "           X       0.82      0.58      0.68       405\n",
      "\n",
      "    accuracy                           0.87    199895\n",
      "   macro avg       0.85      0.83      0.83    199895\n",
      "weighted avg       0.88      0.87      0.87    199895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "training_preds = base_cls.predict(x_base_train)\n",
    "print(classification_report(y_base_train, training_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.82      0.85      1666\n",
      "         ADP       0.89      0.67      0.76      2013\n",
      "         ADV       0.62      0.83      0.71      1131\n",
      "         AUX       0.89      0.78      0.83      1521\n",
      "       CCONJ       0.99      0.98      0.99       726\n",
      "         DET       0.96      0.95      0.96      1870\n",
      "        INTJ       0.66      0.73      0.69        86\n",
      "        NOUN       0.67      0.89      0.77      3909\n",
      "         NUM       0.96      0.55      0.70       485\n",
      "        PART       0.70      0.90      0.78       632\n",
      "        PRON       0.91      0.95      0.93      2118\n",
      "       PROPN       0.88      0.48      0.62      1753\n",
      "       PUNCT       0.99      0.98      0.99      2794\n",
      "       SCONJ       0.60      0.44      0.51       382\n",
      "         SYM       0.82      0.86      0.84       101\n",
      "        VERB       0.80      0.82      0.81      2544\n",
      "           X       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.83     23811\n",
      "   macro avg       0.78      0.74      0.75     23811\n",
      "weighted avg       0.84      0.83      0.82     23811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = base_cls.predict(x_base_test)\n",
    "print(classification_report(y_base_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we use is the pre-trained optimal model used in the previous assignment. We follow the same preprocessing and caching steps as in the previous assignment. Since the model is not trained again, we use only a subset of the original training data (25,000 windows) in order to save on scare main-memory resources. We consider this a representative sample for comparison with other classifiers due to the sample size (law of large numbers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_small_sentences(conllu_df: pd.DataFrame, min_len: int) -> pd.DataFrame:\n",
    "    assert 1 <= min_len\n",
    "\n",
    "    length_df = length_sentences(conllu_df)\n",
    "    valid_length_df = length_df[length_df >= min_len]\n",
    "    valid_ids = set(valid_length_df.index)\n",
    "    return conllu_df[conllu_df.sent_id.isin(valid_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5\n",
    "# training data are used exclusively for training accuracy, thus\n",
    "# we only need a small, representative sample\n",
    "TRAINING_LIM = 25000\n",
    "VALID_LIM = 25000\n",
    "TEST_LIM = 10000\n",
    "SEED = 42\n",
    "PAD_TOKEN = \"<PAD>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘input/fasttext/cc.en.300.bin.gz’ already there; not retrieving.\n",
      "\n",
      "Skipping model file\n"
     ]
    }
   ],
   "source": [
    "# download and unzip only if the download and unzipped files do not exist \n",
    "!wget -nc -P input/fasttext https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
    "\n",
    "![ -f \"input/fasttext/cc.en.300.bin\" ] && echo \"Skipping model file\" || gzip --decompress --keep --force \"input/fasttext/cc.en.300.bin.gz\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "\n",
    "print(\"Loading embedding model...\")\n",
    "fasttext_model = fasttext.load_model(\"input/fasttext/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load intermediate calculations...\n",
      "Loaded cached calculations.\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    x_train_mlp,\n",
    "    x_valid_mlp,\n",
    "    x_test_mlp,\n",
    "    y_train_mlp,\n",
    "    y_valid_mlp,\n",
    "    y_test_mlp,\n",
    "    lb_mlp,\n",
    ") = tasks.preprocessing.mlp_input(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    embed_model=fasttext_model,\n",
    "    intermediate_dir=INTERMEDIATE_DIR,\n",
    "    train_lim=TRAINING_LIM,\n",
    "    val_lim=VALID_LIM,\n",
    "    test_lim=TEST_LIM,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    seed=SEED,\n",
    "    pad_token=PAD_TOKEN,\n",
    ")\n",
    "\n",
    "del fasttext_model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mlp = keras.saving.load_model(os.path.join(INPUT_MODEL_PATH, \"mlp_model.keras\"))\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        lb_mlp.inverse_transform(y_train_mlp),\n",
    "        lb_mlp.inverse_transform(mlp.predict(x_train_mlp)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        lb_mlp.inverse_transform(y_test_mlp),\n",
    "        lb_mlp.inverse_transform(mlp.predict(x_test_mlp)),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rnn_model = keras.saving.load_model(\n",
    "    os.path.join(INPUT_MODEL_PATH, \"rnn_model.keras\")\n",
    ")\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        decode(tag_tokenizer, y_train),\n",
    "        decode(tag_tokenizer, rnn_model.predict(train_data)),\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        decode(tag_tokenizer, y_test),\n",
    "        decode(tag_tokenizer, rnn_model.predict(test_data)),\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnn_model = keras.saving.load_model(\n",
    "    os.path.join(INPUT_MODEL_PATH, \"rnn_model.keras\")\n",
    ")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        decode(tag_tokenizer, y_train),\n",
    "        decode(tag_tokenizer, cnn_model.predict(train_data)),\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        decode(tag_tokenizer, y_test),\n",
    "        decode(tag_tokenizer, cnn_model.predict(test_data)),\n",
    "        zero_division=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dataframe to individual sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05d60631e8642c89ac3e79be61bfe61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dbf7d4d3c24a50916367f519f5dd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38af3290f28478aa1e74d67bbe004f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fed76d4a5d24cabb646b7798c5fb708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59afa72349b24c38afce38508412c824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2992e0c142b44c7d980cf9d3e675bc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'words'],\n",
       "        num_rows: 10539\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['labels', 'words'],\n",
       "        num_rows: 1538\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'words'],\n",
       "        num_rows: 1535\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "\n",
    "def encode_bert(df, col_name):\n",
    "    sentences = []\n",
    "\n",
    "    for sentence_id in tqdm(set(df.sent_id)):\n",
    "        words_df = df[df.sent_id == sentence_id]\n",
    "        sentence = list(words_df[col_name])\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "print(\"Converting dataframe to individual sentences...\")\n",
    "data_dict = datasets.DatasetDict(\n",
    "    {\n",
    "        \"train\": datasets.Dataset.from_dict(\n",
    "            {\n",
    "                \"labels\": tag_tokenizer.texts_to_sequences(\n",
    "                    encode_bert(train_df, \"pos\")\n",
    "                ),\n",
    "                \"words\": encode_bert(train_df, \"words\"),\n",
    "            }\n",
    "        ),\n",
    "        \"val\": datasets.Dataset.from_dict(\n",
    "            {\n",
    "                \"labels\": tag_tokenizer.texts_to_sequences(\n",
    "                    encode_bert(val_df, \"pos\")\n",
    "                ),\n",
    "                \"words\": encode_bert(val_df, \"words\"),\n",
    "            }\n",
    "        ),\n",
    "        \"test\": datasets.Dataset.from_dict(\n",
    "            {\n",
    "                \"labels\": tag_tokenizer.texts_to_sequences(\n",
    "                    encode_bert(test_df, \"pos\")\n",
    "                ),\n",
    "                \"words\": encode_bert(test_df, \"words\"),\n",
    "            }\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForTokenClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", use_fast=True\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\",\n",
    "    torch_dtype=torch.float16,\n",
    "    num_labels=len(train_df.pos.unique()),\n",
    ").to(\"cuda\")\n",
    "\n",
    "# \"TweebankNLP/bertweet-tb2_ewt-pos-tagging\"\n",
    "# \"bert-base-uncased\"\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616976e350eb499ea5480c0c575674ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10539 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09094fbd187434fa6bcad39cc8eacc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14a0b83d02f47e2a3ab960b2fb4b538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'words', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10539\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['labels', 'words', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1538\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'words', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1535\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = bert_tokenizer(\n",
    "        examples[\"words\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(\n",
    "            batch_index=i\n",
    "        )  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif (\n",
    "                word_idx != previous_word_idx\n",
    "            ):  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "tokenized_data_dict = data_dict.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_bert(encoded_sequence, num_classes):\n",
    "    # create dummy class for -100 tokens\n",
    "    return keras.utils.to_categorical(\n",
    "        [x if x != -100 else num_classes for x in encoded_sequence.flatten()],\n",
    "        num_classes=num_classes + 1,\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = decode_bert(pred.label_ids, 17)\n",
    "    preds = decode_bert(pred.predictions.argmax(-1), 17)\n",
    "\n",
    "    # ignore dummy label\n",
    "    mask = labels[:, -1] != 1\n",
    "    labels = labels[mask]\n",
    "    preds = preds[mask]\n",
    "\n",
    "    # calculate accuracy using sklearn's function\n",
    "    acc = sklearn.metrics.accuracy_score(labels, preds)\n",
    "    precision = sklearn.metrics.precision_score(labels, preds, average=\"macro\")\n",
    "    recall = sklearn.metrics.recall_score(labels, preds, average=\"macro\")\n",
    "    f1 = sklearn.metrics.f1_score(labels, preds, average=\"macro\")\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"val_accuracy\": acc,\n",
    "        \"val_precision\": precision,\n",
    "        \"val_recall\": recall,\n",
    "        \"val_f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75768c858f1740c98d40b11ec2e82773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,  # output directory\n",
    "    num_train_epochs=8,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    gradient_accumulation_steps=4,  # Number of update steps (forward passes) to accumulate the gradients for, before performing a backward/update pass\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=\"./logs\",  # directory for storing logs\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    evaluation_strategy=transformers.IntervalStrategy.STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "     metric_for_best_model = \"val_accuracy\",\n",
    "    save_total_limit=3,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,  # the instantiated Transformers model to be trained\n",
    "    args=training_args,  # training arguments, as defined above\n",
    "    train_dataset=tokenized_data_dict[\"train\"],  # training dataset\n",
    "    eval_dataset=tokenized_data_dict[\"val\"],  # evaluation dataset\n",
    "    tokenizer=bert_tokenizer,  # tokenizer\n",
    "    data_collator=data_collator, # batch creator (padding)\n",
    "    callbacks=[\n",
    "        transformers.EarlyStoppingCallback(early_stopping_patience=5)\n",
    "    ],  \n",
    "    compute_metrics=compute_metrics    \n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
