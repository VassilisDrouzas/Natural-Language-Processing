{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5bfb9c9-35fe-4522-af77-5c7f9502ae64",
   "metadata": {
    "id": "b5bfb9c9-35fe-4522-af77-5c7f9502ae64"
   },
   "source": [
    "## Dataset : Cornell Movie Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8acb39d-9baf-479f-99a7-feb46f97bbb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8acb39d-9baf-479f-99a7-feb46f97bbb4",
    "outputId": "0bf2fffa-87f2-43f5-be6c-83d62d0cc88f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dimits/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/dimits/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/dimits/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import time\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf95519-3876-485d-b379-8297d977fa20",
   "metadata": {
    "id": "cdf95519-3876-485d-b379-8297d977fa20"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b124fd8c-1035-48e7-9dc2-2fc1b599d94d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b124fd8c-1035-48e7-9dc2-2fc1b599d94d",
    "outputId": "5a075d89-0ed8-4331-dc80-140ae33d7096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-08 10:36:40--  https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3127238 (3,0M) [application/x-gzip]\n",
      "Saving to: ‘review_polarity.tar.gz’\n",
      "\n",
      "review_polarity.tar 100%[===================>]   2,98M  1,05MB/s    in 2,8s    \n",
      "\n",
      "2024-02-08 10:36:43 (1,05 MB/s) - ‘review_polarity.tar.gz’ saved [3127238/3127238]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a9d448-2512-4a32-bb8d-4ddafcdc3c55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91a9d448-2512-4a32-bb8d-4ddafcdc3c55",
    "outputId": "6b5448ba-c246-4263-82ce-e7be61cdd758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt_sentoken/neg/cv000_29416.txt\n",
      "txt_sentoken/neg/cv001_19502.txt\n",
      "txt_sentoken/neg/cv002_17424.txt\n",
      "txt_sentoken/neg/cv003_12683.txt\n",
      "txt_sentoken/neg/cv004_12641.txt\n",
      "txt_sentoken/neg/cv005_29357.txt\n",
      "txt_sentoken/neg/cv006_17022.txt\n",
      "txt_sentoken/neg/cv007_4992.txt\n",
      "txt_sentoken/neg/cv008_29326.txt\n",
      "txt_sentoken/neg/cv009_29417.txt\n",
      "txt_sentoken/neg/cv010_29063.txt\n",
      "txt_sentoken/neg/cv011_13044.txt\n",
      "txt_sentoken/neg/cv012_29411.txt\n",
      "txt_sentoken/neg/cv013_10494.txt\n",
      "txt_sentoken/neg/cv014_15600.txt\n",
      "txt_sentoken/neg/cv015_29356.txt\n",
      "txt_sentoken/neg/cv016_4348.txt\n",
      "txt_sentoken/neg/cv017_23487.txt\n",
      "txt_sentoken/neg/cv018_21672.txt\n",
      "txt_sentoken/neg/cv019_16117.txt\n",
      "txt_sentoken/neg/cv020_9234.txt\n",
      "txt_sentoken/neg/cv021_17313.txt\n",
      "txt_sentoken/neg/cv022_14227.txt\n",
      "txt_sentoken/neg/cv023_13847.txt\n",
      "txt_sentoken/neg/cv024_7033.txt\n",
      "txt_sentoken/neg/cv025_29825.txt\n",
      "txt_sentoken/neg/cv026_29229.txt\n",
      "txt_sentoken/neg/cv027_26270.txt\n",
      "txt_sentoken/neg/cv028_26964.txt\n",
      "txt_sentoken/neg/cv029_19943.txt\n",
      "txt_sentoken/neg/cv030_22893.txt\n",
      "txt_sentoken/neg/cv031_19540.txt\n",
      "txt_sentoken/neg/cv032_23718.txt\n",
      "txt_sentoken/neg/cv033_25680.txt\n",
      "txt_sentoken/neg/cv034_29446.txt\n",
      "txt_sentoken/neg/cv035_3343.txt\n",
      "txt_sentoken/neg/cv036_18385.txt\n",
      "txt_sentoken/neg/cv037_19798.txt\n",
      "txt_sentoken/neg/cv038_9781.txt\n",
      "txt_sentoken/neg/cv039_5963.txt\n",
      "txt_sentoken/neg/cv040_8829.txt\n",
      "txt_sentoken/neg/cv041_22364.txt\n",
      "txt_sentoken/neg/cv042_11927.txt\n",
      "txt_sentoken/neg/cv043_16808.txt\n",
      "txt_sentoken/neg/cv044_18429.txt\n",
      "txt_sentoken/neg/cv045_25077.txt\n",
      "txt_sentoken/neg/cv046_10613.txt\n",
      "txt_sentoken/neg/cv047_18725.txt\n",
      "txt_sentoken/neg/cv048_18380.txt\n",
      "txt_sentoken/neg/cv049_21917.txt\n",
      "txt_sentoken/neg/cv050_12128.txt\n",
      "txt_sentoken/neg/cv051_10751.txt\n",
      "txt_sentoken/neg/cv052_29318.txt\n",
      "txt_sentoken/neg/cv053_23117.txt\n",
      "txt_sentoken/neg/cv054_4101.txt\n",
      "txt_sentoken/neg/cv055_8926.txt\n",
      "txt_sentoken/neg/cv056_14663.txt\n",
      "txt_sentoken/neg/cv057_7962.txt\n",
      "txt_sentoken/neg/cv058_8469.txt\n",
      "txt_sentoken/neg/cv059_28723.txt\n",
      "txt_sentoken/neg/cv060_11754.txt\n",
      "txt_sentoken/neg/cv061_9321.txt\n",
      "txt_sentoken/neg/cv062_24556.txt\n",
      "txt_sentoken/neg/cv063_28852.txt\n",
      "txt_sentoken/neg/cv064_25842.txt\n",
      "txt_sentoken/neg/cv065_16909.txt\n",
      "txt_sentoken/neg/cv066_11668.txt\n",
      "txt_sentoken/neg/cv067_21192.txt\n",
      "txt_sentoken/neg/cv068_14810.txt\n",
      "txt_sentoken/neg/cv069_11613.txt\n",
      "txt_sentoken/neg/cv070_13249.txt\n",
      "txt_sentoken/neg/cv071_12969.txt\n",
      "txt_sentoken/neg/cv072_5928.txt\n",
      "txt_sentoken/neg/cv073_23039.txt\n",
      "txt_sentoken/neg/cv074_7188.txt\n",
      "txt_sentoken/neg/cv075_6250.txt\n",
      "txt_sentoken/neg/cv076_26009.txt\n",
      "txt_sentoken/neg/cv077_23172.txt\n",
      "txt_sentoken/neg/cv078_16506.txt\n",
      "txt_sentoken/neg/cv079_12766.txt\n",
      "txt_sentoken/neg/cv080_14899.txt\n",
      "txt_sentoken/neg/cv081_18241.txt\n",
      "txt_sentoken/neg/cv082_11979.txt\n",
      "txt_sentoken/neg/cv083_25491.txt\n",
      "txt_sentoken/neg/cv084_15183.txt\n",
      "txt_sentoken/neg/cv085_15286.txt\n",
      "txt_sentoken/neg/cv086_19488.txt\n",
      "txt_sentoken/neg/cv087_2145.txt\n",
      "txt_sentoken/neg/cv088_25274.txt\n",
      "txt_sentoken/neg/cv089_12222.txt\n",
      "txt_sentoken/neg/cv090_0049.txt\n",
      "txt_sentoken/neg/cv091_7899.txt\n",
      "txt_sentoken/neg/cv092_27987.txt\n",
      "txt_sentoken/neg/cv093_15606.txt\n",
      "txt_sentoken/neg/cv094_27868.txt\n",
      "txt_sentoken/neg/cv095_28730.txt\n",
      "txt_sentoken/neg/cv096_12262.txt\n",
      "txt_sentoken/neg/cv097_26081.txt\n",
      "txt_sentoken/neg/cv098_17021.txt\n",
      "txt_sentoken/neg/cv099_11189.txt\n",
      "txt_sentoken/neg/cv100_12406.txt\n",
      "txt_sentoken/neg/cv101_10537.txt\n",
      "txt_sentoken/neg/cv102_8306.txt\n",
      "txt_sentoken/neg/cv103_11943.txt\n",
      "txt_sentoken/neg/cv104_19176.txt\n",
      "txt_sentoken/neg/cv105_19135.txt\n",
      "txt_sentoken/neg/cv106_18379.txt\n",
      "txt_sentoken/neg/cv107_25639.txt\n",
      "txt_sentoken/neg/cv108_17064.txt\n",
      "txt_sentoken/neg/cv109_22599.txt\n",
      "txt_sentoken/neg/cv110_27832.txt\n",
      "txt_sentoken/neg/cv111_12253.txt\n",
      "txt_sentoken/neg/cv112_12178.txt\n",
      "txt_sentoken/neg/cv113_24354.txt\n",
      "txt_sentoken/neg/cv114_19501.txt\n",
      "txt_sentoken/neg/cv115_26443.txt\n",
      "txt_sentoken/neg/cv116_28734.txt\n",
      "txt_sentoken/neg/cv117_25625.txt\n",
      "txt_sentoken/neg/cv118_28837.txt\n",
      "txt_sentoken/neg/cv119_9909.txt\n",
      "txt_sentoken/neg/cv120_3793.txt\n",
      "txt_sentoken/neg/cv121_18621.txt\n",
      "txt_sentoken/neg/cv122_7891.txt\n",
      "txt_sentoken/neg/cv123_12165.txt\n",
      "txt_sentoken/neg/cv124_3903.txt\n",
      "txt_sentoken/neg/cv125_9636.txt\n",
      "txt_sentoken/neg/cv126_28821.txt\n",
      "txt_sentoken/neg/cv127_16451.txt\n",
      "txt_sentoken/neg/cv128_29444.txt\n",
      "txt_sentoken/neg/cv129_18373.txt\n",
      "txt_sentoken/neg/cv130_18521.txt\n",
      "txt_sentoken/neg/cv131_11568.txt\n",
      "txt_sentoken/neg/cv132_5423.txt\n",
      "txt_sentoken/neg/cv133_18065.txt\n",
      "txt_sentoken/neg/cv134_23300.txt\n",
      "txt_sentoken/neg/cv135_12506.txt\n",
      "txt_sentoken/neg/cv136_12384.txt\n",
      "txt_sentoken/neg/cv137_17020.txt\n",
      "txt_sentoken/neg/cv138_13903.txt\n",
      "txt_sentoken/neg/cv139_14236.txt\n",
      "txt_sentoken/neg/cv140_7963.txt\n",
      "txt_sentoken/neg/cv141_17179.txt\n",
      "txt_sentoken/neg/cv142_23657.txt\n",
      "txt_sentoken/neg/cv143_21158.txt\n",
      "txt_sentoken/neg/cv144_5010.txt\n",
      "txt_sentoken/neg/cv145_12239.txt\n",
      "txt_sentoken/neg/cv146_19587.txt\n",
      "txt_sentoken/neg/cv147_22625.txt\n",
      "txt_sentoken/neg/cv148_18084.txt\n",
      "txt_sentoken/neg/cv149_17084.txt\n",
      "txt_sentoken/neg/cv150_14279.txt\n",
      "txt_sentoken/neg/cv151_17231.txt\n",
      "txt_sentoken/neg/cv152_9052.txt\n",
      "txt_sentoken/neg/cv153_11607.txt\n",
      "txt_sentoken/neg/cv154_9562.txt\n",
      "txt_sentoken/neg/cv155_7845.txt\n",
      "txt_sentoken/neg/cv156_11119.txt\n",
      "txt_sentoken/neg/cv157_29302.txt\n",
      "txt_sentoken/neg/cv158_10914.txt\n",
      "txt_sentoken/neg/cv159_29374.txt\n",
      "txt_sentoken/neg/cv160_10848.txt\n",
      "txt_sentoken/neg/cv161_12224.txt\n",
      "txt_sentoken/neg/cv162_10977.txt\n",
      "txt_sentoken/neg/cv163_10110.txt\n",
      "txt_sentoken/neg/cv164_23451.txt\n",
      "txt_sentoken/neg/cv165_2389.txt\n",
      "txt_sentoken/neg/cv166_11959.txt\n",
      "txt_sentoken/neg/cv167_18094.txt\n",
      "txt_sentoken/neg/cv168_7435.txt\n",
      "txt_sentoken/neg/cv169_24973.txt\n",
      "txt_sentoken/neg/cv170_29808.txt\n",
      "txt_sentoken/neg/cv171_15164.txt\n",
      "txt_sentoken/neg/cv172_12037.txt\n",
      "txt_sentoken/neg/cv173_4295.txt\n",
      "txt_sentoken/neg/cv174_9735.txt\n",
      "txt_sentoken/neg/cv175_7375.txt\n",
      "txt_sentoken/neg/cv176_14196.txt\n",
      "txt_sentoken/neg/cv177_10904.txt\n",
      "txt_sentoken/neg/cv178_14380.txt\n",
      "txt_sentoken/neg/cv179_9533.txt\n",
      "txt_sentoken/neg/cv180_17823.txt\n",
      "txt_sentoken/neg/cv181_16083.txt\n",
      "txt_sentoken/neg/cv182_7791.txt\n",
      "txt_sentoken/neg/cv183_19826.txt\n",
      "txt_sentoken/neg/cv184_26935.txt\n",
      "txt_sentoken/neg/cv185_28372.txt\n",
      "txt_sentoken/neg/cv186_2396.txt\n",
      "txt_sentoken/neg/cv187_14112.txt\n",
      "txt_sentoken/neg/cv188_20687.txt\n",
      "txt_sentoken/neg/cv189_24248.txt\n",
      "txt_sentoken/neg/cv190_27176.txt\n",
      "txt_sentoken/neg/cv191_29539.txt\n",
      "txt_sentoken/neg/cv192_16079.txt\n",
      "txt_sentoken/neg/cv193_5393.txt\n",
      "txt_sentoken/neg/cv194_12855.txt\n",
      "txt_sentoken/neg/cv195_16146.txt\n",
      "txt_sentoken/neg/cv196_28898.txt\n",
      "txt_sentoken/neg/cv197_29271.txt\n",
      "txt_sentoken/neg/cv198_19313.txt\n",
      "txt_sentoken/neg/cv199_9721.txt\n",
      "txt_sentoken/neg/cv200_29006.txt\n",
      "txt_sentoken/neg/cv201_7421.txt\n",
      "txt_sentoken/neg/cv202_11382.txt\n",
      "txt_sentoken/neg/cv203_19052.txt\n",
      "txt_sentoken/neg/cv204_8930.txt\n",
      "txt_sentoken/neg/cv205_9676.txt\n",
      "txt_sentoken/neg/cv206_15893.txt\n",
      "txt_sentoken/neg/cv207_29141.txt\n",
      "txt_sentoken/neg/cv208_9475.txt\n",
      "txt_sentoken/neg/cv209_28973.txt\n",
      "txt_sentoken/neg/cv210_9557.txt\n",
      "txt_sentoken/neg/cv211_9955.txt\n",
      "txt_sentoken/neg/cv212_10054.txt\n",
      "txt_sentoken/neg/cv213_20300.txt\n",
      "txt_sentoken/neg/cv214_13285.txt\n",
      "txt_sentoken/neg/cv215_23246.txt\n",
      "txt_sentoken/neg/cv216_20165.txt\n",
      "txt_sentoken/neg/cv217_28707.txt\n",
      "txt_sentoken/neg/cv218_25651.txt\n",
      "txt_sentoken/neg/cv219_19874.txt\n",
      "txt_sentoken/neg/cv220_28906.txt\n",
      "txt_sentoken/neg/cv221_27081.txt\n",
      "txt_sentoken/neg/cv222_18720.txt\n",
      "txt_sentoken/neg/cv223_28923.txt\n",
      "txt_sentoken/neg/cv224_18875.txt\n",
      "txt_sentoken/neg/cv225_29083.txt\n",
      "txt_sentoken/neg/cv226_26692.txt\n",
      "txt_sentoken/neg/cv227_25406.txt\n",
      "txt_sentoken/neg/cv228_5644.txt\n",
      "txt_sentoken/neg/cv229_15200.txt\n",
      "txt_sentoken/neg/cv230_7913.txt\n",
      "txt_sentoken/neg/cv231_11028.txt\n",
      "txt_sentoken/neg/cv232_16768.txt\n",
      "txt_sentoken/neg/cv233_17614.txt\n",
      "txt_sentoken/neg/cv234_22123.txt\n",
      "txt_sentoken/neg/cv235_10704.txt\n",
      "txt_sentoken/neg/cv236_12427.txt\n",
      "txt_sentoken/neg/cv237_20635.txt\n",
      "txt_sentoken/neg/cv238_14285.txt\n",
      "txt_sentoken/neg/cv239_29828.txt\n",
      "txt_sentoken/neg/cv240_15948.txt\n",
      "txt_sentoken/neg/cv241_24602.txt\n",
      "txt_sentoken/neg/cv242_11354.txt\n",
      "txt_sentoken/neg/cv243_22164.txt\n",
      "txt_sentoken/neg/cv244_22935.txt\n",
      "txt_sentoken/neg/cv245_8938.txt\n",
      "txt_sentoken/neg/cv246_28668.txt\n",
      "txt_sentoken/neg/cv247_14668.txt\n",
      "txt_sentoken/neg/cv248_15672.txt\n",
      "txt_sentoken/neg/cv249_12674.txt\n",
      "txt_sentoken/neg/cv250_26462.txt\n",
      "txt_sentoken/neg/cv251_23901.txt\n",
      "txt_sentoken/neg/cv252_24974.txt\n",
      "txt_sentoken/neg/cv253_10190.txt\n",
      "txt_sentoken/neg/cv254_5870.txt\n",
      "txt_sentoken/neg/cv255_15267.txt\n",
      "txt_sentoken/neg/cv256_16529.txt\n",
      "txt_sentoken/neg/cv257_11856.txt\n",
      "txt_sentoken/neg/cv258_5627.txt\n",
      "txt_sentoken/neg/cv259_11827.txt\n",
      "txt_sentoken/neg/cv260_15652.txt\n",
      "txt_sentoken/neg/cv261_11855.txt\n",
      "txt_sentoken/neg/cv262_13812.txt\n",
      "txt_sentoken/neg/cv263_20693.txt\n",
      "txt_sentoken/neg/cv264_14108.txt\n",
      "txt_sentoken/neg/cv265_11625.txt\n",
      "txt_sentoken/neg/cv266_26644.txt\n",
      "txt_sentoken/neg/cv267_16618.txt\n",
      "txt_sentoken/neg/cv268_20288.txt\n",
      "txt_sentoken/neg/cv269_23018.txt\n",
      "txt_sentoken/neg/cv270_5873.txt\n",
      "txt_sentoken/neg/cv271_15364.txt\n",
      "txt_sentoken/neg/cv272_20313.txt\n",
      "txt_sentoken/neg/cv273_28961.txt\n",
      "txt_sentoken/neg/cv274_26379.txt\n",
      "txt_sentoken/neg/cv275_28725.txt\n",
      "txt_sentoken/neg/cv276_17126.txt\n",
      "txt_sentoken/neg/cv277_20467.txt\n",
      "txt_sentoken/neg/cv278_14533.txt\n",
      "txt_sentoken/neg/cv279_19452.txt\n",
      "txt_sentoken/neg/cv280_8651.txt\n",
      "txt_sentoken/neg/cv281_24711.txt\n",
      "txt_sentoken/neg/cv282_6833.txt\n",
      "txt_sentoken/neg/cv283_11963.txt\n",
      "txt_sentoken/neg/cv284_20530.txt\n",
      "txt_sentoken/neg/cv285_18186.txt\n",
      "txt_sentoken/neg/cv286_26156.txt\n",
      "txt_sentoken/neg/cv287_17410.txt\n",
      "txt_sentoken/neg/cv288_20212.txt\n",
      "txt_sentoken/neg/cv289_6239.txt\n",
      "txt_sentoken/neg/cv290_11981.txt\n",
      "txt_sentoken/neg/cv291_26844.txt\n",
      "txt_sentoken/neg/cv292_7804.txt\n",
      "txt_sentoken/neg/cv293_29731.txt\n",
      "txt_sentoken/neg/cv294_12695.txt\n",
      "txt_sentoken/neg/cv295_17060.txt\n",
      "txt_sentoken/neg/cv296_13146.txt\n",
      "txt_sentoken/neg/cv297_10104.txt\n",
      "txt_sentoken/neg/cv298_24487.txt\n",
      "txt_sentoken/neg/cv299_17950.txt\n",
      "txt_sentoken/neg/cv300_23302.txt\n",
      "txt_sentoken/neg/cv301_13010.txt\n",
      "txt_sentoken/neg/cv302_26481.txt\n",
      "txt_sentoken/neg/cv303_27366.txt\n",
      "txt_sentoken/neg/cv304_28489.txt\n",
      "txt_sentoken/neg/cv305_9937.txt\n",
      "txt_sentoken/neg/cv306_10859.txt\n",
      "txt_sentoken/neg/cv307_26382.txt\n",
      "txt_sentoken/neg/cv308_5079.txt\n",
      "txt_sentoken/neg/cv309_23737.txt\n",
      "txt_sentoken/neg/cv310_14568.txt\n",
      "txt_sentoken/neg/cv311_17708.txt\n",
      "txt_sentoken/neg/cv312_29308.txt\n",
      "txt_sentoken/neg/cv313_19337.txt\n",
      "txt_sentoken/neg/cv314_16095.txt\n",
      "txt_sentoken/neg/cv315_12638.txt\n",
      "txt_sentoken/neg/cv316_5972.txt\n",
      "txt_sentoken/neg/cv317_25111.txt\n",
      "txt_sentoken/neg/cv318_11146.txt\n",
      "txt_sentoken/neg/cv319_16459.txt\n",
      "txt_sentoken/neg/cv320_9693.txt\n",
      "txt_sentoken/neg/cv321_14191.txt\n",
      "txt_sentoken/neg/cv322_21820.txt\n",
      "txt_sentoken/neg/cv323_29633.txt\n",
      "txt_sentoken/neg/cv324_7502.txt\n",
      "txt_sentoken/neg/cv325_18330.txt\n",
      "txt_sentoken/neg/cv326_14777.txt\n",
      "txt_sentoken/neg/cv327_21743.txt\n",
      "txt_sentoken/neg/cv328_10908.txt\n",
      "txt_sentoken/neg/cv329_29293.txt\n",
      "txt_sentoken/neg/cv330_29675.txt\n",
      "txt_sentoken/neg/cv331_8656.txt\n",
      "txt_sentoken/neg/cv332_17997.txt\n",
      "txt_sentoken/neg/cv333_9443.txt\n",
      "txt_sentoken/neg/cv334_0074.txt\n",
      "txt_sentoken/neg/cv335_16299.txt\n",
      "txt_sentoken/neg/cv336_10363.txt\n",
      "txt_sentoken/neg/cv337_29061.txt\n",
      "txt_sentoken/neg/cv338_9183.txt\n",
      "txt_sentoken/neg/cv339_22452.txt\n",
      "txt_sentoken/neg/cv340_14776.txt\n",
      "txt_sentoken/neg/cv341_25667.txt\n",
      "txt_sentoken/neg/cv342_20917.txt\n",
      "txt_sentoken/neg/cv343_10906.txt\n",
      "txt_sentoken/neg/cv344_5376.txt\n",
      "txt_sentoken/neg/cv345_9966.txt\n",
      "txt_sentoken/neg/cv346_19198.txt\n",
      "txt_sentoken/neg/cv347_14722.txt\n",
      "txt_sentoken/neg/cv348_19207.txt\n",
      "txt_sentoken/neg/cv349_15032.txt\n",
      "txt_sentoken/neg/cv350_22139.txt\n",
      "txt_sentoken/neg/cv351_17029.txt\n",
      "txt_sentoken/neg/cv352_5414.txt\n",
      "txt_sentoken/neg/cv353_19197.txt\n",
      "txt_sentoken/neg/cv354_8573.txt\n",
      "txt_sentoken/neg/cv355_18174.txt\n",
      "txt_sentoken/neg/cv356_26170.txt\n",
      "txt_sentoken/neg/cv357_14710.txt\n",
      "txt_sentoken/neg/cv358_11557.txt\n",
      "txt_sentoken/neg/cv359_6751.txt\n",
      "txt_sentoken/neg/cv360_8927.txt\n",
      "txt_sentoken/neg/cv361_28738.txt\n",
      "txt_sentoken/neg/cv362_16985.txt\n",
      "txt_sentoken/neg/cv363_29273.txt\n",
      "txt_sentoken/neg/cv364_14254.txt\n",
      "txt_sentoken/neg/cv365_12442.txt\n",
      "txt_sentoken/neg/cv366_10709.txt\n",
      "txt_sentoken/neg/cv367_24065.txt\n",
      "txt_sentoken/neg/cv368_11090.txt\n",
      "txt_sentoken/neg/cv369_14245.txt\n",
      "txt_sentoken/neg/cv370_5338.txt\n",
      "txt_sentoken/neg/cv371_8197.txt\n",
      "txt_sentoken/neg/cv372_6654.txt\n",
      "txt_sentoken/neg/cv373_21872.txt\n",
      "txt_sentoken/neg/cv374_26455.txt\n",
      "txt_sentoken/neg/cv375_9932.txt\n",
      "txt_sentoken/neg/cv376_20883.txt\n",
      "txt_sentoken/neg/cv377_8440.txt\n",
      "txt_sentoken/neg/cv378_21982.txt\n",
      "txt_sentoken/neg/cv379_23167.txt\n",
      "txt_sentoken/neg/cv380_8164.txt\n",
      "txt_sentoken/neg/cv381_21673.txt\n",
      "txt_sentoken/neg/cv382_8393.txt\n",
      "txt_sentoken/neg/cv383_14662.txt\n",
      "txt_sentoken/neg/cv384_18536.txt\n",
      "txt_sentoken/neg/cv385_29621.txt\n",
      "txt_sentoken/neg/cv386_10229.txt\n",
      "txt_sentoken/neg/cv387_12391.txt\n",
      "txt_sentoken/neg/cv388_12810.txt\n",
      "txt_sentoken/neg/cv389_9611.txt\n",
      "txt_sentoken/neg/cv390_12187.txt\n",
      "txt_sentoken/neg/cv391_11615.txt\n",
      "txt_sentoken/neg/cv392_12238.txt\n",
      "txt_sentoken/neg/cv393_29234.txt\n",
      "txt_sentoken/neg/cv394_5311.txt\n",
      "txt_sentoken/neg/cv395_11761.txt\n",
      "txt_sentoken/neg/cv396_19127.txt\n",
      "txt_sentoken/neg/cv397_28890.txt\n",
      "txt_sentoken/neg/cv398_17047.txt\n",
      "txt_sentoken/neg/cv399_28593.txt\n",
      "txt_sentoken/neg/cv400_20631.txt\n",
      "txt_sentoken/neg/cv401_13758.txt\n",
      "txt_sentoken/neg/cv402_16097.txt\n",
      "txt_sentoken/neg/cv403_6721.txt\n",
      "txt_sentoken/neg/cv404_21805.txt\n",
      "txt_sentoken/neg/cv405_21868.txt\n",
      "txt_sentoken/neg/cv406_22199.txt\n",
      "txt_sentoken/neg/cv407_23928.txt\n",
      "txt_sentoken/neg/cv408_5367.txt\n",
      "txt_sentoken/neg/cv409_29625.txt\n",
      "txt_sentoken/neg/cv410_25624.txt\n",
      "txt_sentoken/neg/cv411_16799.txt\n",
      "txt_sentoken/neg/cv412_25254.txt\n",
      "txt_sentoken/neg/cv413_7893.txt\n",
      "txt_sentoken/neg/cv414_11161.txt\n",
      "txt_sentoken/neg/cv415_23674.txt\n",
      "txt_sentoken/neg/cv416_12048.txt\n",
      "txt_sentoken/neg/cv417_14653.txt\n",
      "txt_sentoken/neg/cv418_16562.txt\n",
      "txt_sentoken/neg/cv419_14799.txt\n",
      "txt_sentoken/neg/cv420_28631.txt\n",
      "txt_sentoken/neg/cv421_9752.txt\n",
      "txt_sentoken/neg/cv422_9632.txt\n",
      "txt_sentoken/neg/cv423_12089.txt\n",
      "txt_sentoken/neg/cv424_9268.txt\n",
      "txt_sentoken/neg/cv425_8603.txt\n",
      "txt_sentoken/neg/cv426_10976.txt\n",
      "txt_sentoken/neg/cv427_11693.txt\n",
      "txt_sentoken/neg/cv428_12202.txt\n",
      "txt_sentoken/neg/cv429_7937.txt\n",
      "txt_sentoken/neg/cv430_18662.txt\n",
      "txt_sentoken/neg/cv431_7538.txt\n",
      "txt_sentoken/neg/cv432_15873.txt\n",
      "txt_sentoken/neg/cv433_10443.txt\n",
      "txt_sentoken/neg/cv434_5641.txt\n",
      "txt_sentoken/neg/cv435_24355.txt\n",
      "txt_sentoken/neg/cv436_20564.txt\n",
      "txt_sentoken/neg/cv437_24070.txt\n",
      "txt_sentoken/neg/cv438_8500.txt\n",
      "txt_sentoken/neg/cv439_17633.txt\n",
      "txt_sentoken/neg/cv440_16891.txt\n",
      "txt_sentoken/neg/cv441_15276.txt\n",
      "txt_sentoken/neg/cv442_15499.txt\n",
      "txt_sentoken/neg/cv443_22367.txt\n",
      "txt_sentoken/neg/cv444_9975.txt\n",
      "txt_sentoken/neg/cv445_26683.txt\n",
      "txt_sentoken/neg/cv446_12209.txt\n",
      "txt_sentoken/neg/cv447_27334.txt\n",
      "txt_sentoken/neg/cv448_16409.txt\n",
      "txt_sentoken/neg/cv449_9126.txt\n",
      "txt_sentoken/neg/cv450_8319.txt\n",
      "txt_sentoken/neg/cv451_11502.txt\n",
      "txt_sentoken/neg/cv452_5179.txt\n",
      "txt_sentoken/neg/cv453_10911.txt\n",
      "txt_sentoken/neg/cv454_21961.txt\n",
      "txt_sentoken/neg/cv455_28866.txt\n",
      "txt_sentoken/neg/cv456_20370.txt\n",
      "txt_sentoken/neg/cv457_19546.txt\n",
      "txt_sentoken/neg/cv458_9000.txt\n",
      "txt_sentoken/neg/cv459_21834.txt\n",
      "txt_sentoken/neg/cv460_11723.txt\n",
      "txt_sentoken/neg/cv461_21124.txt\n",
      "txt_sentoken/neg/cv462_20788.txt\n",
      "txt_sentoken/neg/cv463_10846.txt\n",
      "txt_sentoken/neg/cv464_17076.txt\n",
      "txt_sentoken/neg/cv465_23401.txt\n",
      "txt_sentoken/neg/cv466_20092.txt\n",
      "txt_sentoken/neg/cv467_26610.txt\n",
      "txt_sentoken/neg/cv468_16844.txt\n",
      "txt_sentoken/neg/cv469_21998.txt\n",
      "txt_sentoken/neg/cv470_17444.txt\n",
      "txt_sentoken/neg/cv471_18405.txt\n",
      "txt_sentoken/neg/cv472_29140.txt\n",
      "txt_sentoken/neg/cv473_7869.txt\n",
      "txt_sentoken/neg/cv474_10682.txt\n",
      "txt_sentoken/neg/cv475_22978.txt\n",
      "txt_sentoken/neg/cv476_18402.txt\n",
      "txt_sentoken/neg/cv477_23530.txt\n",
      "txt_sentoken/neg/cv478_15921.txt\n",
      "txt_sentoken/neg/cv479_5450.txt\n",
      "txt_sentoken/neg/cv480_21195.txt\n",
      "txt_sentoken/neg/cv481_7930.txt\n",
      "txt_sentoken/neg/cv482_11233.txt\n",
      "txt_sentoken/neg/cv483_18103.txt\n",
      "txt_sentoken/neg/cv484_26169.txt\n",
      "txt_sentoken/neg/cv485_26879.txt\n",
      "txt_sentoken/neg/cv486_9788.txt\n",
      "txt_sentoken/neg/cv487_11058.txt\n",
      "txt_sentoken/neg/cv488_21453.txt\n",
      "txt_sentoken/neg/cv489_19046.txt\n",
      "txt_sentoken/neg/cv490_18986.txt\n",
      "txt_sentoken/neg/cv491_12992.txt\n",
      "txt_sentoken/neg/cv492_19370.txt\n",
      "txt_sentoken/neg/cv493_14135.txt\n",
      "txt_sentoken/neg/cv494_18689.txt\n",
      "txt_sentoken/neg/cv495_16121.txt\n",
      "txt_sentoken/neg/cv496_11185.txt\n",
      "txt_sentoken/neg/cv497_27086.txt\n",
      "txt_sentoken/neg/cv498_9288.txt\n",
      "txt_sentoken/neg/cv499_11407.txt\n",
      "txt_sentoken/neg/cv500_10722.txt\n",
      "txt_sentoken/neg/cv501_12675.txt\n",
      "txt_sentoken/neg/cv502_10970.txt\n",
      "txt_sentoken/neg/cv503_11196.txt\n",
      "txt_sentoken/neg/cv504_29120.txt\n",
      "txt_sentoken/neg/cv505_12926.txt\n",
      "txt_sentoken/neg/cv506_17521.txt\n",
      "txt_sentoken/neg/cv507_9509.txt\n",
      "txt_sentoken/neg/cv508_17742.txt\n",
      "txt_sentoken/neg/cv509_17354.txt\n",
      "txt_sentoken/neg/cv510_24758.txt\n",
      "txt_sentoken/neg/cv511_10360.txt\n",
      "txt_sentoken/neg/cv512_17618.txt\n",
      "txt_sentoken/neg/cv513_7236.txt\n",
      "txt_sentoken/neg/cv514_12173.txt\n",
      "txt_sentoken/neg/cv515_18484.txt\n",
      "txt_sentoken/neg/cv516_12117.txt\n",
      "txt_sentoken/neg/cv517_20616.txt\n",
      "txt_sentoken/neg/cv518_14798.txt\n",
      "txt_sentoken/neg/cv519_16239.txt\n",
      "txt_sentoken/neg/cv520_13297.txt\n",
      "txt_sentoken/neg/cv521_1730.txt\n",
      "txt_sentoken/neg/cv522_5418.txt\n",
      "txt_sentoken/neg/cv523_18285.txt\n",
      "txt_sentoken/neg/cv524_24885.txt\n",
      "txt_sentoken/neg/cv525_17930.txt\n",
      "txt_sentoken/neg/cv526_12868.txt\n",
      "txt_sentoken/neg/cv527_10338.txt\n",
      "txt_sentoken/neg/cv528_11669.txt\n",
      "txt_sentoken/neg/cv529_10972.txt\n",
      "txt_sentoken/neg/cv530_17949.txt\n",
      "txt_sentoken/neg/cv531_26838.txt\n",
      "txt_sentoken/neg/cv532_6495.txt\n",
      "txt_sentoken/neg/cv533_9843.txt\n",
      "txt_sentoken/neg/cv534_15683.txt\n",
      "txt_sentoken/neg/cv535_21183.txt\n",
      "txt_sentoken/neg/cv536_27221.txt\n",
      "txt_sentoken/neg/cv537_13516.txt\n",
      "txt_sentoken/neg/cv538_28485.txt\n",
      "txt_sentoken/neg/cv539_21865.txt\n",
      "txt_sentoken/neg/cv540_3092.txt\n",
      "txt_sentoken/neg/cv541_28683.txt\n",
      "txt_sentoken/neg/cv542_20359.txt\n",
      "txt_sentoken/neg/cv543_5107.txt\n",
      "txt_sentoken/neg/cv544_5301.txt\n",
      "txt_sentoken/neg/cv545_12848.txt\n",
      "txt_sentoken/neg/cv546_12723.txt\n",
      "txt_sentoken/neg/cv547_18043.txt\n",
      "txt_sentoken/neg/cv548_18944.txt\n",
      "txt_sentoken/neg/cv549_22771.txt\n",
      "txt_sentoken/neg/cv550_23226.txt\n",
      "txt_sentoken/neg/cv551_11214.txt\n",
      "txt_sentoken/neg/cv552_0150.txt\n",
      "txt_sentoken/neg/cv553_26965.txt\n",
      "txt_sentoken/neg/cv554_14678.txt\n",
      "txt_sentoken/neg/cv555_25047.txt\n",
      "txt_sentoken/neg/cv556_16563.txt\n",
      "txt_sentoken/neg/cv557_12237.txt\n",
      "txt_sentoken/neg/cv558_29376.txt\n",
      "txt_sentoken/neg/cv559_0057.txt\n",
      "txt_sentoken/neg/cv560_18608.txt\n",
      "txt_sentoken/neg/cv561_9484.txt\n",
      "txt_sentoken/neg/cv562_10847.txt\n",
      "txt_sentoken/neg/cv563_18610.txt\n",
      "txt_sentoken/neg/cv564_12011.txt\n",
      "txt_sentoken/neg/cv565_29403.txt\n",
      "txt_sentoken/neg/cv566_8967.txt\n",
      "txt_sentoken/neg/cv567_29420.txt\n",
      "txt_sentoken/neg/cv568_17065.txt\n",
      "txt_sentoken/neg/cv569_26750.txt\n",
      "txt_sentoken/neg/cv570_28960.txt\n",
      "txt_sentoken/neg/cv571_29292.txt\n",
      "txt_sentoken/neg/cv572_20053.txt\n",
      "txt_sentoken/neg/cv573_29384.txt\n",
      "txt_sentoken/neg/cv574_23191.txt\n",
      "txt_sentoken/neg/cv575_22598.txt\n",
      "txt_sentoken/neg/cv576_15688.txt\n",
      "txt_sentoken/neg/cv577_28220.txt\n",
      "txt_sentoken/neg/cv578_16825.txt\n",
      "txt_sentoken/neg/cv579_12542.txt\n",
      "txt_sentoken/neg/cv580_15681.txt\n",
      "txt_sentoken/neg/cv581_20790.txt\n",
      "txt_sentoken/neg/cv582_6678.txt\n",
      "txt_sentoken/neg/cv583_29465.txt\n",
      "txt_sentoken/neg/cv584_29549.txt\n",
      "txt_sentoken/neg/cv585_23576.txt\n",
      "txt_sentoken/neg/cv586_8048.txt\n",
      "txt_sentoken/neg/cv587_20532.txt\n",
      "txt_sentoken/neg/cv588_14467.txt\n",
      "txt_sentoken/neg/cv589_12853.txt\n",
      "txt_sentoken/neg/cv590_20712.txt\n",
      "txt_sentoken/neg/cv591_24887.txt\n",
      "txt_sentoken/neg/cv592_23391.txt\n",
      "txt_sentoken/neg/cv593_11931.txt\n",
      "txt_sentoken/neg/cv594_11945.txt\n",
      "txt_sentoken/neg/cv595_26420.txt\n",
      "txt_sentoken/neg/cv596_4367.txt\n",
      "txt_sentoken/neg/cv597_26744.txt\n",
      "txt_sentoken/neg/cv598_18184.txt\n",
      "txt_sentoken/neg/cv599_22197.txt\n",
      "txt_sentoken/neg/cv600_25043.txt\n",
      "txt_sentoken/neg/cv601_24759.txt\n",
      "txt_sentoken/neg/cv602_8830.txt\n",
      "txt_sentoken/neg/cv603_18885.txt\n",
      "txt_sentoken/neg/cv604_23339.txt\n",
      "txt_sentoken/neg/cv605_12730.txt\n",
      "txt_sentoken/neg/cv606_17672.txt\n",
      "txt_sentoken/neg/cv607_8235.txt\n",
      "txt_sentoken/neg/cv608_24647.txt\n",
      "txt_sentoken/neg/cv609_25038.txt\n",
      "txt_sentoken/neg/cv610_24153.txt\n",
      "txt_sentoken/neg/cv611_2253.txt\n",
      "txt_sentoken/neg/cv612_5396.txt\n",
      "txt_sentoken/neg/cv613_23104.txt\n",
      "txt_sentoken/neg/cv614_11320.txt\n",
      "txt_sentoken/neg/cv615_15734.txt\n",
      "txt_sentoken/neg/cv616_29187.txt\n",
      "txt_sentoken/neg/cv617_9561.txt\n",
      "txt_sentoken/neg/cv618_9469.txt\n",
      "txt_sentoken/neg/cv619_13677.txt\n",
      "txt_sentoken/neg/cv620_2556.txt\n",
      "txt_sentoken/neg/cv621_15984.txt\n",
      "txt_sentoken/neg/cv622_8583.txt\n",
      "txt_sentoken/neg/cv623_16988.txt\n",
      "txt_sentoken/neg/cv624_11601.txt\n",
      "txt_sentoken/neg/cv625_13518.txt\n",
      "txt_sentoken/neg/cv626_7907.txt\n",
      "txt_sentoken/neg/cv627_12603.txt\n",
      "txt_sentoken/neg/cv628_20758.txt\n",
      "txt_sentoken/neg/cv629_16604.txt\n",
      "txt_sentoken/neg/cv630_10152.txt\n",
      "txt_sentoken/neg/cv631_4782.txt\n",
      "txt_sentoken/neg/cv632_9704.txt\n",
      "txt_sentoken/neg/cv633_29730.txt\n",
      "txt_sentoken/neg/cv634_11989.txt\n",
      "txt_sentoken/neg/cv635_0984.txt\n",
      "txt_sentoken/neg/cv636_16954.txt\n",
      "txt_sentoken/neg/cv637_13682.txt\n",
      "txt_sentoken/neg/cv638_29394.txt\n",
      "txt_sentoken/neg/cv639_10797.txt\n",
      "txt_sentoken/neg/cv640_5380.txt\n",
      "txt_sentoken/neg/cv641_13412.txt\n",
      "txt_sentoken/neg/cv642_29788.txt\n",
      "txt_sentoken/neg/cv643_29282.txt\n",
      "txt_sentoken/neg/cv644_18551.txt\n",
      "txt_sentoken/neg/cv645_17078.txt\n",
      "txt_sentoken/neg/cv646_16817.txt\n",
      "txt_sentoken/neg/cv647_15275.txt\n",
      "txt_sentoken/neg/cv648_17277.txt\n",
      "txt_sentoken/neg/cv649_13947.txt\n",
      "txt_sentoken/neg/cv650_15974.txt\n",
      "txt_sentoken/neg/cv651_11120.txt\n",
      "txt_sentoken/neg/cv652_15653.txt\n",
      "txt_sentoken/neg/cv653_2107.txt\n",
      "txt_sentoken/neg/cv654_19345.txt\n",
      "txt_sentoken/neg/cv655_12055.txt\n",
      "txt_sentoken/neg/cv656_25395.txt\n",
      "txt_sentoken/neg/cv657_25835.txt\n",
      "txt_sentoken/neg/cv658_11186.txt\n",
      "txt_sentoken/neg/cv659_21483.txt\n",
      "txt_sentoken/neg/cv660_23140.txt\n",
      "txt_sentoken/neg/cv661_25780.txt\n",
      "txt_sentoken/neg/cv662_14791.txt\n",
      "txt_sentoken/neg/cv663_14484.txt\n",
      "txt_sentoken/neg/cv664_4264.txt\n",
      "txt_sentoken/neg/cv665_29386.txt\n",
      "txt_sentoken/neg/cv666_20301.txt\n",
      "txt_sentoken/neg/cv667_19672.txt\n",
      "txt_sentoken/neg/cv668_18848.txt\n",
      "txt_sentoken/neg/cv669_24318.txt\n",
      "txt_sentoken/neg/cv670_2666.txt\n",
      "txt_sentoken/neg/cv671_5164.txt\n",
      "txt_sentoken/neg/cv672_27988.txt\n",
      "txt_sentoken/neg/cv673_25874.txt\n",
      "txt_sentoken/neg/cv674_11593.txt\n",
      "txt_sentoken/neg/cv675_22871.txt\n",
      "txt_sentoken/neg/cv676_22202.txt\n",
      "txt_sentoken/neg/cv677_18938.txt\n",
      "txt_sentoken/neg/cv678_14887.txt\n",
      "txt_sentoken/neg/cv679_28221.txt\n",
      "txt_sentoken/neg/cv680_10533.txt\n",
      "txt_sentoken/neg/cv681_9744.txt\n",
      "txt_sentoken/neg/cv682_17947.txt\n",
      "txt_sentoken/neg/cv683_13047.txt\n",
      "txt_sentoken/neg/cv684_12727.txt\n",
      "txt_sentoken/neg/cv685_5710.txt\n",
      "txt_sentoken/neg/cv686_15553.txt\n",
      "txt_sentoken/neg/cv687_22207.txt\n",
      "txt_sentoken/neg/cv688_7884.txt\n",
      "txt_sentoken/neg/cv689_13701.txt\n",
      "txt_sentoken/neg/cv690_5425.txt\n",
      "txt_sentoken/neg/cv691_5090.txt\n",
      "txt_sentoken/neg/cv692_17026.txt\n",
      "txt_sentoken/neg/cv693_19147.txt\n",
      "txt_sentoken/neg/cv694_4526.txt\n",
      "txt_sentoken/neg/cv695_22268.txt\n",
      "txt_sentoken/neg/cv696_29619.txt\n",
      "txt_sentoken/neg/cv697_12106.txt\n",
      "txt_sentoken/neg/cv698_16930.txt\n",
      "txt_sentoken/neg/cv699_7773.txt\n",
      "txt_sentoken/neg/cv700_23163.txt\n",
      "txt_sentoken/neg/cv701_15880.txt\n",
      "txt_sentoken/neg/cv702_12371.txt\n",
      "txt_sentoken/neg/cv703_17948.txt\n",
      "txt_sentoken/neg/cv704_17622.txt\n",
      "txt_sentoken/neg/cv705_11973.txt\n",
      "txt_sentoken/neg/cv706_25883.txt\n",
      "txt_sentoken/neg/cv707_11421.txt\n",
      "txt_sentoken/neg/cv708_28539.txt\n",
      "txt_sentoken/neg/cv709_11173.txt\n",
      "txt_sentoken/neg/cv710_23745.txt\n",
      "txt_sentoken/neg/cv711_12687.txt\n",
      "txt_sentoken/neg/cv712_24217.txt\n",
      "txt_sentoken/neg/cv713_29002.txt\n",
      "txt_sentoken/neg/cv714_19704.txt\n",
      "txt_sentoken/neg/cv715_19246.txt\n",
      "txt_sentoken/neg/cv716_11153.txt\n",
      "txt_sentoken/neg/cv717_17472.txt\n",
      "txt_sentoken/neg/cv718_12227.txt\n",
      "txt_sentoken/neg/cv719_5581.txt\n",
      "txt_sentoken/neg/cv720_5383.txt\n",
      "txt_sentoken/neg/cv721_28993.txt\n",
      "txt_sentoken/neg/cv722_7571.txt\n",
      "txt_sentoken/neg/cv723_9002.txt\n",
      "txt_sentoken/neg/cv724_15265.txt\n",
      "txt_sentoken/neg/cv725_10266.txt\n",
      "txt_sentoken/neg/cv726_4365.txt\n",
      "txt_sentoken/neg/cv727_5006.txt\n",
      "txt_sentoken/neg/cv728_17931.txt\n",
      "txt_sentoken/neg/cv729_10475.txt\n",
      "txt_sentoken/neg/cv730_10729.txt\n",
      "txt_sentoken/neg/cv731_3968.txt\n",
      "txt_sentoken/neg/cv732_13092.txt\n",
      "txt_sentoken/neg/cv733_9891.txt\n",
      "txt_sentoken/neg/cv734_22821.txt\n",
      "txt_sentoken/neg/cv735_20218.txt\n",
      "txt_sentoken/neg/cv736_24947.txt\n",
      "txt_sentoken/neg/cv737_28733.txt\n",
      "txt_sentoken/neg/cv738_10287.txt\n",
      "txt_sentoken/neg/cv739_12179.txt\n",
      "txt_sentoken/neg/cv740_13643.txt\n",
      "txt_sentoken/neg/cv741_12765.txt\n",
      "txt_sentoken/neg/cv742_8279.txt\n",
      "txt_sentoken/neg/cv743_17023.txt\n",
      "txt_sentoken/neg/cv744_10091.txt\n",
      "txt_sentoken/neg/cv745_14009.txt\n",
      "txt_sentoken/neg/cv746_10471.txt\n",
      "txt_sentoken/neg/cv747_18189.txt\n",
      "txt_sentoken/neg/cv748_14044.txt\n",
      "txt_sentoken/neg/cv749_18960.txt\n",
      "txt_sentoken/neg/cv750_10606.txt\n",
      "txt_sentoken/neg/cv751_17208.txt\n",
      "txt_sentoken/neg/cv752_25330.txt\n",
      "txt_sentoken/neg/cv753_11812.txt\n",
      "txt_sentoken/neg/cv754_7709.txt\n",
      "txt_sentoken/neg/cv755_24881.txt\n",
      "txt_sentoken/neg/cv756_23676.txt\n",
      "txt_sentoken/neg/cv757_10668.txt\n",
      "txt_sentoken/neg/cv758_9740.txt\n",
      "txt_sentoken/neg/cv759_15091.txt\n",
      "txt_sentoken/neg/cv760_8977.txt\n",
      "txt_sentoken/neg/cv761_13769.txt\n",
      "txt_sentoken/neg/cv762_15604.txt\n",
      "txt_sentoken/neg/cv763_16486.txt\n",
      "txt_sentoken/neg/cv764_12701.txt\n",
      "txt_sentoken/neg/cv765_20429.txt\n",
      "txt_sentoken/neg/cv766_7983.txt\n",
      "txt_sentoken/neg/cv767_15673.txt\n",
      "txt_sentoken/neg/cv768_12709.txt\n",
      "txt_sentoken/neg/cv769_8565.txt\n",
      "txt_sentoken/neg/cv770_11061.txt\n",
      "txt_sentoken/neg/cv771_28466.txt\n",
      "txt_sentoken/neg/cv772_12971.txt\n",
      "txt_sentoken/neg/cv773_20264.txt\n",
      "txt_sentoken/neg/cv774_15488.txt\n",
      "txt_sentoken/neg/cv775_17966.txt\n",
      "txt_sentoken/neg/cv776_21934.txt\n",
      "txt_sentoken/neg/cv777_10247.txt\n",
      "txt_sentoken/neg/cv778_18629.txt\n",
      "txt_sentoken/neg/cv779_18989.txt\n",
      "txt_sentoken/neg/cv780_8467.txt\n",
      "txt_sentoken/neg/cv781_5358.txt\n",
      "txt_sentoken/neg/cv782_21078.txt\n",
      "txt_sentoken/neg/cv783_14724.txt\n",
      "txt_sentoken/neg/cv784_16077.txt\n",
      "txt_sentoken/neg/cv785_23748.txt\n",
      "txt_sentoken/neg/cv786_23608.txt\n",
      "txt_sentoken/neg/cv787_15277.txt\n",
      "txt_sentoken/neg/cv788_26409.txt\n",
      "txt_sentoken/neg/cv789_12991.txt\n",
      "txt_sentoken/neg/cv790_16202.txt\n",
      "txt_sentoken/neg/cv791_17995.txt\n",
      "txt_sentoken/neg/cv792_3257.txt\n",
      "txt_sentoken/neg/cv793_15235.txt\n",
      "txt_sentoken/neg/cv794_17353.txt\n",
      "txt_sentoken/neg/cv795_10291.txt\n",
      "txt_sentoken/neg/cv796_17243.txt\n",
      "txt_sentoken/neg/cv797_7245.txt\n",
      "txt_sentoken/neg/cv798_24779.txt\n",
      "txt_sentoken/neg/cv799_19812.txt\n",
      "txt_sentoken/neg/cv800_13494.txt\n",
      "txt_sentoken/neg/cv801_26335.txt\n",
      "txt_sentoken/neg/cv802_28381.txt\n",
      "txt_sentoken/neg/cv803_8584.txt\n",
      "txt_sentoken/neg/cv804_11763.txt\n",
      "txt_sentoken/neg/cv805_21128.txt\n",
      "txt_sentoken/neg/cv806_9405.txt\n",
      "txt_sentoken/neg/cv807_23024.txt\n",
      "txt_sentoken/neg/cv808_13773.txt\n",
      "txt_sentoken/neg/cv809_5012.txt\n",
      "txt_sentoken/neg/cv810_13660.txt\n",
      "txt_sentoken/neg/cv811_22646.txt\n",
      "txt_sentoken/neg/cv812_19051.txt\n",
      "txt_sentoken/neg/cv813_6649.txt\n",
      "txt_sentoken/neg/cv814_20316.txt\n",
      "txt_sentoken/neg/cv815_23466.txt\n",
      "txt_sentoken/neg/cv816_15257.txt\n",
      "txt_sentoken/neg/cv817_3675.txt\n",
      "txt_sentoken/neg/cv818_10698.txt\n",
      "txt_sentoken/neg/cv819_9567.txt\n",
      "txt_sentoken/neg/cv820_24157.txt\n",
      "txt_sentoken/neg/cv821_29283.txt\n",
      "txt_sentoken/neg/cv822_21545.txt\n",
      "txt_sentoken/neg/cv823_17055.txt\n",
      "txt_sentoken/neg/cv824_9335.txt\n",
      "txt_sentoken/neg/cv825_5168.txt\n",
      "txt_sentoken/neg/cv826_12761.txt\n",
      "txt_sentoken/neg/cv827_19479.txt\n",
      "txt_sentoken/neg/cv828_21392.txt\n",
      "txt_sentoken/neg/cv829_21725.txt\n",
      "txt_sentoken/neg/cv830_5778.txt\n",
      "txt_sentoken/neg/cv831_16325.txt\n",
      "txt_sentoken/neg/cv832_24713.txt\n",
      "txt_sentoken/neg/cv833_11961.txt\n",
      "txt_sentoken/neg/cv834_23192.txt\n",
      "txt_sentoken/neg/cv835_20531.txt\n",
      "txt_sentoken/neg/cv836_14311.txt\n",
      "txt_sentoken/neg/cv837_27232.txt\n",
      "txt_sentoken/neg/cv838_25886.txt\n",
      "txt_sentoken/neg/cv839_22807.txt\n",
      "txt_sentoken/neg/cv840_18033.txt\n",
      "txt_sentoken/neg/cv841_3367.txt\n",
      "txt_sentoken/neg/cv842_5702.txt\n",
      "txt_sentoken/neg/cv843_17054.txt\n",
      "txt_sentoken/neg/cv844_13890.txt\n",
      "txt_sentoken/neg/cv845_15886.txt\n",
      "txt_sentoken/neg/cv846_29359.txt\n",
      "txt_sentoken/neg/cv847_20855.txt\n",
      "txt_sentoken/neg/cv848_10061.txt\n",
      "txt_sentoken/neg/cv849_17215.txt\n",
      "txt_sentoken/neg/cv850_18185.txt\n",
      "txt_sentoken/neg/cv851_21895.txt\n",
      "txt_sentoken/neg/cv852_27512.txt\n",
      "txt_sentoken/neg/cv853_29119.txt\n",
      "txt_sentoken/neg/cv854_18955.txt\n",
      "txt_sentoken/neg/cv855_22134.txt\n",
      "txt_sentoken/neg/cv856_28882.txt\n",
      "txt_sentoken/neg/cv857_17527.txt\n",
      "txt_sentoken/neg/cv858_20266.txt\n",
      "txt_sentoken/neg/cv859_15689.txt\n",
      "txt_sentoken/neg/cv860_15520.txt\n",
      "txt_sentoken/neg/cv861_12809.txt\n",
      "txt_sentoken/neg/cv862_15924.txt\n",
      "txt_sentoken/neg/cv863_7912.txt\n",
      "txt_sentoken/neg/cv864_3087.txt\n",
      "txt_sentoken/neg/cv865_28796.txt\n",
      "txt_sentoken/neg/cv866_29447.txt\n",
      "txt_sentoken/neg/cv867_18362.txt\n",
      "txt_sentoken/neg/cv868_12799.txt\n",
      "txt_sentoken/neg/cv869_24782.txt\n",
      "txt_sentoken/neg/cv870_18090.txt\n",
      "txt_sentoken/neg/cv871_25971.txt\n",
      "txt_sentoken/neg/cv872_13710.txt\n",
      "txt_sentoken/neg/cv873_19937.txt\n",
      "txt_sentoken/neg/cv874_12182.txt\n",
      "txt_sentoken/neg/cv875_5622.txt\n",
      "txt_sentoken/neg/cv876_9633.txt\n",
      "txt_sentoken/neg/cv877_29132.txt\n",
      "txt_sentoken/neg/cv878_17204.txt\n",
      "txt_sentoken/neg/cv879_16585.txt\n",
      "txt_sentoken/neg/cv880_29629.txt\n",
      "txt_sentoken/neg/cv881_14767.txt\n",
      "txt_sentoken/neg/cv882_10042.txt\n",
      "txt_sentoken/neg/cv883_27621.txt\n",
      "txt_sentoken/neg/cv884_15230.txt\n",
      "txt_sentoken/neg/cv885_13390.txt\n",
      "txt_sentoken/neg/cv886_19210.txt\n",
      "txt_sentoken/neg/cv887_5306.txt\n",
      "txt_sentoken/neg/cv888_25678.txt\n",
      "txt_sentoken/neg/cv889_22670.txt\n",
      "txt_sentoken/neg/cv890_3515.txt\n",
      "txt_sentoken/neg/cv891_6035.txt\n",
      "txt_sentoken/neg/cv892_18788.txt\n",
      "txt_sentoken/neg/cv893_26731.txt\n",
      "txt_sentoken/neg/cv894_22140.txt\n",
      "txt_sentoken/neg/cv895_22200.txt\n",
      "txt_sentoken/neg/cv896_17819.txt\n",
      "txt_sentoken/neg/cv897_11703.txt\n",
      "txt_sentoken/neg/cv898_1576.txt\n",
      "txt_sentoken/neg/cv899_17812.txt\n",
      "txt_sentoken/neg/cv900_10800.txt\n",
      "txt_sentoken/neg/cv901_11934.txt\n",
      "txt_sentoken/neg/cv902_13217.txt\n",
      "txt_sentoken/neg/cv903_18981.txt\n",
      "txt_sentoken/neg/cv904_25663.txt\n",
      "txt_sentoken/neg/cv905_28965.txt\n",
      "txt_sentoken/neg/cv906_12332.txt\n",
      "txt_sentoken/neg/cv907_3193.txt\n",
      "txt_sentoken/neg/cv908_17779.txt\n",
      "txt_sentoken/neg/cv909_9973.txt\n",
      "txt_sentoken/neg/cv910_21930.txt\n",
      "txt_sentoken/neg/cv911_21695.txt\n",
      "txt_sentoken/neg/cv912_5562.txt\n",
      "txt_sentoken/neg/cv913_29127.txt\n",
      "txt_sentoken/neg/cv914_2856.txt\n",
      "txt_sentoken/neg/cv915_9342.txt\n",
      "txt_sentoken/neg/cv916_17034.txt\n",
      "txt_sentoken/neg/cv917_29484.txt\n",
      "txt_sentoken/neg/cv918_27080.txt\n",
      "txt_sentoken/neg/cv919_18155.txt\n",
      "txt_sentoken/neg/cv920_29423.txt\n",
      "txt_sentoken/neg/cv921_13988.txt\n",
      "txt_sentoken/neg/cv922_10185.txt\n",
      "txt_sentoken/neg/cv923_11951.txt\n",
      "txt_sentoken/neg/cv924_29397.txt\n",
      "txt_sentoken/neg/cv925_9459.txt\n",
      "txt_sentoken/neg/cv926_18471.txt\n",
      "txt_sentoken/neg/cv927_11471.txt\n",
      "txt_sentoken/neg/cv928_9478.txt\n",
      "txt_sentoken/neg/cv929_1841.txt\n",
      "txt_sentoken/neg/cv930_14949.txt\n",
      "txt_sentoken/neg/cv931_18783.txt\n",
      "txt_sentoken/neg/cv932_14854.txt\n",
      "txt_sentoken/neg/cv933_24953.txt\n",
      "txt_sentoken/neg/cv934_20426.txt\n",
      "txt_sentoken/neg/cv935_24977.txt\n",
      "txt_sentoken/neg/cv936_17473.txt\n",
      "txt_sentoken/neg/cv937_9816.txt\n",
      "txt_sentoken/neg/cv938_10706.txt\n",
      "txt_sentoken/neg/cv939_11247.txt\n",
      "txt_sentoken/neg/cv940_18935.txt\n",
      "txt_sentoken/neg/cv941_10718.txt\n",
      "txt_sentoken/neg/cv942_18509.txt\n",
      "txt_sentoken/neg/cv943_23547.txt\n",
      "txt_sentoken/neg/cv944_15042.txt\n",
      "txt_sentoken/neg/cv945_13012.txt\n",
      "txt_sentoken/neg/cv946_20084.txt\n",
      "txt_sentoken/neg/cv947_11316.txt\n",
      "txt_sentoken/neg/cv948_25870.txt\n",
      "txt_sentoken/neg/cv949_21565.txt\n",
      "txt_sentoken/neg/cv950_13478.txt\n",
      "txt_sentoken/neg/cv951_11816.txt\n",
      "txt_sentoken/neg/cv952_26375.txt\n",
      "txt_sentoken/neg/cv953_7078.txt\n",
      "txt_sentoken/neg/cv954_19932.txt\n",
      "txt_sentoken/neg/cv955_26154.txt\n",
      "txt_sentoken/neg/cv956_12547.txt\n",
      "txt_sentoken/neg/cv957_9059.txt\n",
      "txt_sentoken/neg/cv958_13020.txt\n",
      "txt_sentoken/neg/cv959_16218.txt\n",
      "txt_sentoken/neg/cv960_28877.txt\n",
      "txt_sentoken/neg/cv961_5578.txt\n",
      "txt_sentoken/neg/cv962_9813.txt\n",
      "txt_sentoken/neg/cv963_7208.txt\n",
      "txt_sentoken/neg/cv964_5794.txt\n",
      "txt_sentoken/neg/cv965_26688.txt\n",
      "txt_sentoken/neg/cv966_28671.txt\n",
      "txt_sentoken/neg/cv967_5626.txt\n",
      "txt_sentoken/neg/cv968_25413.txt\n",
      "txt_sentoken/neg/cv969_14760.txt\n",
      "txt_sentoken/neg/cv970_19532.txt\n",
      "txt_sentoken/neg/cv971_11790.txt\n",
      "txt_sentoken/neg/cv972_26837.txt\n",
      "txt_sentoken/neg/cv973_10171.txt\n",
      "txt_sentoken/neg/cv974_24303.txt\n",
      "txt_sentoken/neg/cv975_11920.txt\n",
      "txt_sentoken/neg/cv976_10724.txt\n",
      "txt_sentoken/neg/cv977_4776.txt\n",
      "txt_sentoken/neg/cv978_22192.txt\n",
      "txt_sentoken/neg/cv979_2029.txt\n",
      "txt_sentoken/neg/cv980_11851.txt\n",
      "txt_sentoken/neg/cv981_16679.txt\n",
      "txt_sentoken/neg/cv982_22209.txt\n",
      "txt_sentoken/neg/cv983_24219.txt\n",
      "txt_sentoken/neg/cv984_14006.txt\n",
      "txt_sentoken/neg/cv985_5964.txt\n",
      "txt_sentoken/neg/cv986_15092.txt\n",
      "txt_sentoken/neg/cv987_7394.txt\n",
      "txt_sentoken/neg/cv988_20168.txt\n",
      "txt_sentoken/neg/cv989_17297.txt\n",
      "txt_sentoken/neg/cv990_12443.txt\n",
      "txt_sentoken/neg/cv991_19973.txt\n",
      "txt_sentoken/neg/cv992_12806.txt\n",
      "txt_sentoken/neg/cv993_29565.txt\n",
      "txt_sentoken/neg/cv994_13229.txt\n",
      "txt_sentoken/neg/cv995_23113.txt\n",
      "txt_sentoken/neg/cv996_12447.txt\n",
      "txt_sentoken/neg/cv997_5152.txt\n",
      "txt_sentoken/neg/cv998_15691.txt\n",
      "txt_sentoken/neg/cv999_14636.txt\n",
      "txt_sentoken/pos/cv000_29590.txt\n",
      "txt_sentoken/pos/cv001_18431.txt\n",
      "txt_sentoken/pos/cv002_15918.txt\n",
      "txt_sentoken/pos/cv003_11664.txt\n",
      "txt_sentoken/pos/cv004_11636.txt\n",
      "txt_sentoken/pos/cv005_29443.txt\n",
      "txt_sentoken/pos/cv006_15448.txt\n",
      "txt_sentoken/pos/cv007_4968.txt\n",
      "txt_sentoken/pos/cv008_29435.txt\n",
      "txt_sentoken/pos/cv009_29592.txt\n",
      "txt_sentoken/pos/cv010_29198.txt\n",
      "txt_sentoken/pos/cv011_12166.txt\n",
      "txt_sentoken/pos/cv012_29576.txt\n",
      "txt_sentoken/pos/cv013_10159.txt\n",
      "txt_sentoken/pos/cv014_13924.txt\n",
      "txt_sentoken/pos/cv015_29439.txt\n",
      "txt_sentoken/pos/cv016_4659.txt\n",
      "txt_sentoken/pos/cv017_22464.txt\n",
      "txt_sentoken/pos/cv018_20137.txt\n",
      "txt_sentoken/pos/cv019_14482.txt\n",
      "txt_sentoken/pos/cv020_8825.txt\n",
      "txt_sentoken/pos/cv021_15838.txt\n",
      "txt_sentoken/pos/cv022_12864.txt\n",
      "txt_sentoken/pos/cv023_12672.txt\n",
      "txt_sentoken/pos/cv024_6778.txt\n",
      "txt_sentoken/pos/cv025_3108.txt\n",
      "txt_sentoken/pos/cv026_29325.txt\n",
      "txt_sentoken/pos/cv027_25219.txt\n",
      "txt_sentoken/pos/cv028_26746.txt\n",
      "txt_sentoken/pos/cv029_18643.txt\n",
      "txt_sentoken/pos/cv030_21593.txt\n",
      "txt_sentoken/pos/cv031_18452.txt\n",
      "txt_sentoken/pos/cv032_22550.txt\n",
      "txt_sentoken/pos/cv033_24444.txt\n",
      "txt_sentoken/pos/cv034_29647.txt\n",
      "txt_sentoken/pos/cv035_3954.txt\n",
      "txt_sentoken/pos/cv036_16831.txt\n",
      "txt_sentoken/pos/cv037_18510.txt\n",
      "txt_sentoken/pos/cv038_9749.txt\n",
      "txt_sentoken/pos/cv039_6170.txt\n",
      "txt_sentoken/pos/cv040_8276.txt\n",
      "txt_sentoken/pos/cv041_21113.txt\n",
      "txt_sentoken/pos/cv042_10982.txt\n",
      "txt_sentoken/pos/cv043_15013.txt\n",
      "txt_sentoken/pos/cv044_16969.txt\n",
      "txt_sentoken/pos/cv045_23923.txt\n",
      "txt_sentoken/pos/cv046_10188.txt\n",
      "txt_sentoken/pos/cv047_1754.txt\n",
      "txt_sentoken/pos/cv048_16828.txt\n",
      "txt_sentoken/pos/cv049_20471.txt\n",
      "txt_sentoken/pos/cv050_11175.txt\n",
      "txt_sentoken/pos/cv051_10306.txt\n",
      "txt_sentoken/pos/cv052_29378.txt\n",
      "txt_sentoken/pos/cv053_21822.txt\n",
      "txt_sentoken/pos/cv054_4230.txt\n",
      "txt_sentoken/pos/cv055_8338.txt\n",
      "txt_sentoken/pos/cv056_13133.txt\n",
      "txt_sentoken/pos/cv057_7453.txt\n",
      "txt_sentoken/pos/cv058_8025.txt\n",
      "txt_sentoken/pos/cv059_28885.txt\n",
      "txt_sentoken/pos/cv060_10844.txt\n",
      "txt_sentoken/pos/cv061_8837.txt\n",
      "txt_sentoken/pos/cv062_23115.txt\n",
      "txt_sentoken/pos/cv063_28997.txt\n",
      "txt_sentoken/pos/cv064_24576.txt\n",
      "txt_sentoken/pos/cv065_15248.txt\n",
      "txt_sentoken/pos/cv066_10821.txt\n",
      "txt_sentoken/pos/cv067_19774.txt\n",
      "txt_sentoken/pos/cv068_13400.txt\n",
      "txt_sentoken/pos/cv069_10801.txt\n",
      "txt_sentoken/pos/cv070_12289.txt\n",
      "txt_sentoken/pos/cv071_12095.txt\n",
      "txt_sentoken/pos/cv072_6169.txt\n",
      "txt_sentoken/pos/cv073_21785.txt\n",
      "txt_sentoken/pos/cv074_6875.txt\n",
      "txt_sentoken/pos/cv075_6500.txt\n",
      "txt_sentoken/pos/cv076_24945.txt\n",
      "txt_sentoken/pos/cv077_22138.txt\n",
      "txt_sentoken/pos/cv078_14730.txt\n",
      "txt_sentoken/pos/cv079_11933.txt\n",
      "txt_sentoken/pos/cv080_13465.txt\n",
      "txt_sentoken/pos/cv081_16582.txt\n",
      "txt_sentoken/pos/cv082_11080.txt\n",
      "txt_sentoken/pos/cv083_24234.txt\n",
      "txt_sentoken/pos/cv084_13566.txt\n",
      "txt_sentoken/pos/cv085_1381.txt\n",
      "txt_sentoken/pos/cv086_18371.txt\n",
      "txt_sentoken/pos/cv087_1989.txt\n",
      "txt_sentoken/pos/cv088_24113.txt\n",
      "txt_sentoken/pos/cv089_11418.txt\n",
      "txt_sentoken/pos/cv090_0042.txt\n",
      "txt_sentoken/pos/cv091_7400.txt\n",
      "txt_sentoken/pos/cv092_28017.txt\n",
      "txt_sentoken/pos/cv093_13951.txt\n",
      "txt_sentoken/pos/cv094_27889.txt\n",
      "txt_sentoken/pos/cv095_28892.txt\n",
      "txt_sentoken/pos/cv096_11474.txt\n",
      "txt_sentoken/pos/cv097_24970.txt\n",
      "txt_sentoken/pos/cv098_15435.txt\n",
      "txt_sentoken/pos/cv099_10534.txt\n",
      "txt_sentoken/pos/cv100_11528.txt\n",
      "txt_sentoken/pos/cv101_10175.txt\n",
      "txt_sentoken/pos/cv102_7846.txt\n",
      "txt_sentoken/pos/cv103_11021.txt\n",
      "txt_sentoken/pos/cv104_18134.txt\n",
      "txt_sentoken/pos/cv105_17990.txt\n",
      "txt_sentoken/pos/cv106_16807.txt\n",
      "txt_sentoken/pos/cv107_24319.txt\n",
      "txt_sentoken/pos/cv108_15571.txt\n",
      "txt_sentoken/pos/cv109_21172.txt\n",
      "txt_sentoken/pos/cv110_27788.txt\n",
      "txt_sentoken/pos/cv111_11473.txt\n",
      "txt_sentoken/pos/cv112_11193.txt\n",
      "txt_sentoken/pos/cv113_23102.txt\n",
      "txt_sentoken/pos/cv114_18398.txt\n",
      "txt_sentoken/pos/cv115_25396.txt\n",
      "txt_sentoken/pos/cv116_28942.txt\n",
      "txt_sentoken/pos/cv117_24295.txt\n",
      "txt_sentoken/pos/cv118_28980.txt\n",
      "txt_sentoken/pos/cv119_9867.txt\n",
      "txt_sentoken/pos/cv120_4111.txt\n",
      "txt_sentoken/pos/cv121_17302.txt\n",
      "txt_sentoken/pos/cv122_7392.txt\n",
      "txt_sentoken/pos/cv123_11182.txt\n",
      "txt_sentoken/pos/cv124_4122.txt\n",
      "txt_sentoken/pos/cv125_9391.txt\n",
      "txt_sentoken/pos/cv126_28971.txt\n",
      "txt_sentoken/pos/cv127_14711.txt\n",
      "txt_sentoken/pos/cv128_29627.txt\n",
      "txt_sentoken/pos/cv129_16741.txt\n",
      "txt_sentoken/pos/cv130_17083.txt\n",
      "txt_sentoken/pos/cv131_10713.txt\n",
      "txt_sentoken/pos/cv132_5618.txt\n",
      "txt_sentoken/pos/cv133_16336.txt\n",
      "txt_sentoken/pos/cv134_22246.txt\n",
      "txt_sentoken/pos/cv135_11603.txt\n",
      "txt_sentoken/pos/cv136_11505.txt\n",
      "txt_sentoken/pos/cv137_15422.txt\n",
      "txt_sentoken/pos/cv138_12721.txt\n",
      "txt_sentoken/pos/cv139_12873.txt\n",
      "txt_sentoken/pos/cv140_7479.txt\n",
      "txt_sentoken/pos/cv141_15686.txt\n",
      "txt_sentoken/pos/cv142_22516.txt\n",
      "txt_sentoken/pos/cv143_19666.txt\n",
      "txt_sentoken/pos/cv144_5007.txt\n",
      "txt_sentoken/pos/cv145_11472.txt\n",
      "txt_sentoken/pos/cv146_18458.txt\n",
      "txt_sentoken/pos/cv147_21193.txt\n",
      "txt_sentoken/pos/cv148_16345.txt\n",
      "txt_sentoken/pos/cv149_15670.txt\n",
      "txt_sentoken/pos/cv150_12916.txt\n",
      "txt_sentoken/pos/cv151_15771.txt\n",
      "txt_sentoken/pos/cv152_8736.txt\n",
      "txt_sentoken/pos/cv153_10779.txt\n",
      "txt_sentoken/pos/cv154_9328.txt\n",
      "txt_sentoken/pos/cv155_7308.txt\n",
      "txt_sentoken/pos/cv156_10481.txt\n",
      "txt_sentoken/pos/cv157_29372.txt\n",
      "txt_sentoken/pos/cv158_10390.txt\n",
      "txt_sentoken/pos/cv159_29505.txt\n",
      "txt_sentoken/pos/cv160_10362.txt\n",
      "txt_sentoken/pos/cv161_11425.txt\n",
      "txt_sentoken/pos/cv162_10424.txt\n",
      "txt_sentoken/pos/cv163_10052.txt\n",
      "txt_sentoken/pos/cv164_22447.txt\n",
      "txt_sentoken/pos/cv165_22619.txt\n",
      "txt_sentoken/pos/cv166_11052.txt\n",
      "txt_sentoken/pos/cv167_16376.txt\n",
      "txt_sentoken/pos/cv168_7050.txt\n",
      "txt_sentoken/pos/cv169_23778.txt\n",
      "txt_sentoken/pos/cv170_3006.txt\n",
      "txt_sentoken/pos/cv171_13537.txt\n",
      "txt_sentoken/pos/cv172_11131.txt\n",
      "txt_sentoken/pos/cv173_4471.txt\n",
      "txt_sentoken/pos/cv174_9659.txt\n",
      "txt_sentoken/pos/cv175_6964.txt\n",
      "txt_sentoken/pos/cv176_12857.txt\n",
      "txt_sentoken/pos/cv177_10367.txt\n",
      "txt_sentoken/pos/cv178_12972.txt\n",
      "txt_sentoken/pos/cv179_9228.txt\n",
      "txt_sentoken/pos/cv180_16113.txt\n",
      "txt_sentoken/pos/cv181_14401.txt\n",
      "txt_sentoken/pos/cv182_7281.txt\n",
      "txt_sentoken/pos/cv183_18612.txt\n",
      "txt_sentoken/pos/cv184_2673.txt\n",
      "txt_sentoken/pos/cv185_28654.txt\n",
      "txt_sentoken/pos/cv186_2269.txt\n",
      "txt_sentoken/pos/cv187_12829.txt\n",
      "txt_sentoken/pos/cv188_19226.txt\n",
      "txt_sentoken/pos/cv189_22934.txt\n",
      "txt_sentoken/pos/cv190_27052.txt\n",
      "txt_sentoken/pos/cv191_29719.txt\n",
      "txt_sentoken/pos/cv192_14395.txt\n",
      "txt_sentoken/pos/cv193_5416.txt\n",
      "txt_sentoken/pos/cv194_12079.txt\n",
      "txt_sentoken/pos/cv195_14528.txt\n",
      "txt_sentoken/pos/cv196_29027.txt\n",
      "txt_sentoken/pos/cv197_29328.txt\n",
      "txt_sentoken/pos/cv198_18180.txt\n",
      "txt_sentoken/pos/cv199_9629.txt\n",
      "txt_sentoken/pos/cv200_2915.txt\n",
      "txt_sentoken/pos/cv201_6997.txt\n",
      "txt_sentoken/pos/cv202_10654.txt\n",
      "txt_sentoken/pos/cv203_17986.txt\n",
      "txt_sentoken/pos/cv204_8451.txt\n",
      "txt_sentoken/pos/cv205_9457.txt\n",
      "txt_sentoken/pos/cv206_14293.txt\n",
      "txt_sentoken/pos/cv207_29284.txt\n",
      "txt_sentoken/pos/cv208_9020.txt\n",
      "txt_sentoken/pos/cv209_29118.txt\n",
      "txt_sentoken/pos/cv210_9312.txt\n",
      "txt_sentoken/pos/cv211_9953.txt\n",
      "txt_sentoken/pos/cv212_10027.txt\n",
      "txt_sentoken/pos/cv213_18934.txt\n",
      "txt_sentoken/pos/cv214_12294.txt\n",
      "txt_sentoken/pos/cv215_22240.txt\n",
      "txt_sentoken/pos/cv216_18738.txt\n",
      "txt_sentoken/pos/cv217_28842.txt\n",
      "txt_sentoken/pos/cv218_24352.txt\n",
      "txt_sentoken/pos/cv219_18626.txt\n",
      "txt_sentoken/pos/cv220_29059.txt\n",
      "txt_sentoken/pos/cv221_2695.txt\n",
      "txt_sentoken/pos/cv222_17395.txt\n",
      "txt_sentoken/pos/cv223_29066.txt\n",
      "txt_sentoken/pos/cv224_17661.txt\n",
      "txt_sentoken/pos/cv225_29224.txt\n",
      "txt_sentoken/pos/cv226_2618.txt\n",
      "txt_sentoken/pos/cv227_24215.txt\n",
      "txt_sentoken/pos/cv228_5806.txt\n",
      "txt_sentoken/pos/cv229_13611.txt\n",
      "txt_sentoken/pos/cv230_7428.txt\n",
      "txt_sentoken/pos/cv231_10425.txt\n",
      "txt_sentoken/pos/cv232_14991.txt\n",
      "txt_sentoken/pos/cv233_15964.txt\n",
      "txt_sentoken/pos/cv234_20643.txt\n",
      "txt_sentoken/pos/cv235_10217.txt\n",
      "txt_sentoken/pos/cv236_11565.txt\n",
      "txt_sentoken/pos/cv237_19221.txt\n",
      "txt_sentoken/pos/cv238_12931.txt\n",
      "txt_sentoken/pos/cv239_3385.txt\n",
      "txt_sentoken/pos/cv240_14336.txt\n",
      "txt_sentoken/pos/cv241_23130.txt\n",
      "txt_sentoken/pos/cv242_10638.txt\n",
      "txt_sentoken/pos/cv243_20728.txt\n",
      "txt_sentoken/pos/cv244_21649.txt\n",
      "txt_sentoken/pos/cv245_8569.txt\n",
      "txt_sentoken/pos/cv246_28807.txt\n",
      "txt_sentoken/pos/cv247_13142.txt\n",
      "txt_sentoken/pos/cv248_13987.txt\n",
      "txt_sentoken/pos/cv249_11640.txt\n",
      "txt_sentoken/pos/cv250_25616.txt\n",
      "txt_sentoken/pos/cv251_22636.txt\n",
      "txt_sentoken/pos/cv252_23779.txt\n",
      "txt_sentoken/pos/cv253_10077.txt\n",
      "txt_sentoken/pos/cv254_6027.txt\n",
      "txt_sentoken/pos/cv255_13683.txt\n",
      "txt_sentoken/pos/cv256_14740.txt\n",
      "txt_sentoken/pos/cv257_10975.txt\n",
      "txt_sentoken/pos/cv258_5792.txt\n",
      "txt_sentoken/pos/cv259_10934.txt\n",
      "txt_sentoken/pos/cv260_13959.txt\n",
      "txt_sentoken/pos/cv261_10954.txt\n",
      "txt_sentoken/pos/cv262_12649.txt\n",
      "txt_sentoken/pos/cv263_19259.txt\n",
      "txt_sentoken/pos/cv264_12801.txt\n",
      "txt_sentoken/pos/cv265_10814.txt\n",
      "txt_sentoken/pos/cv266_25779.txt\n",
      "txt_sentoken/pos/cv267_14952.txt\n",
      "txt_sentoken/pos/cv268_18834.txt\n",
      "txt_sentoken/pos/cv269_21732.txt\n",
      "txt_sentoken/pos/cv270_6079.txt\n",
      "txt_sentoken/pos/cv271_13837.txt\n",
      "txt_sentoken/pos/cv272_18974.txt\n",
      "txt_sentoken/pos/cv273_29112.txt\n",
      "txt_sentoken/pos/cv274_25253.txt\n",
      "txt_sentoken/pos/cv275_28887.txt\n",
      "txt_sentoken/pos/cv276_15684.txt\n",
      "txt_sentoken/pos/cv277_19091.txt\n",
      "txt_sentoken/pos/cv278_13041.txt\n",
      "txt_sentoken/pos/cv279_18329.txt\n",
      "txt_sentoken/pos/cv280_8267.txt\n",
      "txt_sentoken/pos/cv281_23253.txt\n",
      "txt_sentoken/pos/cv282_6653.txt\n",
      "txt_sentoken/pos/cv283_11055.txt\n",
      "txt_sentoken/pos/cv284_19119.txt\n",
      "txt_sentoken/pos/cv285_16494.txt\n",
      "txt_sentoken/pos/cv286_25050.txt\n",
      "txt_sentoken/pos/cv287_15900.txt\n",
      "txt_sentoken/pos/cv288_18791.txt\n",
      "txt_sentoken/pos/cv289_6463.txt\n",
      "txt_sentoken/pos/cv290_11084.txt\n",
      "txt_sentoken/pos/cv291_26635.txt\n",
      "txt_sentoken/pos/cv292_7282.txt\n",
      "txt_sentoken/pos/cv293_29856.txt\n",
      "txt_sentoken/pos/cv294_11684.txt\n",
      "txt_sentoken/pos/cv295_15570.txt\n",
      "txt_sentoken/pos/cv296_12251.txt\n",
      "txt_sentoken/pos/cv297_10047.txt\n",
      "txt_sentoken/pos/cv298_23111.txt\n",
      "txt_sentoken/pos/cv299_16214.txt\n",
      "txt_sentoken/pos/cv300_22284.txt\n",
      "txt_sentoken/pos/cv301_12146.txt\n",
      "txt_sentoken/pos/cv302_25649.txt\n",
      "txt_sentoken/pos/cv303_27520.txt\n",
      "txt_sentoken/pos/cv304_28706.txt\n",
      "txt_sentoken/pos/cv305_9946.txt\n",
      "txt_sentoken/pos/cv306_10364.txt\n",
      "txt_sentoken/pos/cv307_25270.txt\n",
      "txt_sentoken/pos/cv308_5016.txt\n",
      "txt_sentoken/pos/cv309_22571.txt\n",
      "txt_sentoken/pos/cv310_13091.txt\n",
      "txt_sentoken/pos/cv311_16002.txt\n",
      "txt_sentoken/pos/cv312_29377.txt\n",
      "txt_sentoken/pos/cv313_18198.txt\n",
      "txt_sentoken/pos/cv314_14422.txt\n",
      "txt_sentoken/pos/cv315_11629.txt\n",
      "txt_sentoken/pos/cv316_6370.txt\n",
      "txt_sentoken/pos/cv317_24049.txt\n",
      "txt_sentoken/pos/cv318_10493.txt\n",
      "txt_sentoken/pos/cv319_14727.txt\n",
      "txt_sentoken/pos/cv320_9530.txt\n",
      "txt_sentoken/pos/cv321_12843.txt\n",
      "txt_sentoken/pos/cv322_20318.txt\n",
      "txt_sentoken/pos/cv323_29805.txt\n",
      "txt_sentoken/pos/cv324_7082.txt\n",
      "txt_sentoken/pos/cv325_16629.txt\n",
      "txt_sentoken/pos/cv326_13295.txt\n",
      "txt_sentoken/pos/cv327_20292.txt\n",
      "txt_sentoken/pos/cv328_10373.txt\n",
      "txt_sentoken/pos/cv329_29370.txt\n",
      "txt_sentoken/pos/cv330_29809.txt\n",
      "txt_sentoken/pos/cv331_8273.txt\n",
      "txt_sentoken/pos/cv332_16307.txt\n",
      "txt_sentoken/pos/cv333_8916.txt\n",
      "txt_sentoken/pos/cv334_10001.txt\n",
      "txt_sentoken/pos/cv335_14665.txt\n",
      "txt_sentoken/pos/cv336_10143.txt\n",
      "txt_sentoken/pos/cv337_29181.txt\n",
      "txt_sentoken/pos/cv338_8821.txt\n",
      "txt_sentoken/pos/cv339_21119.txt\n",
      "txt_sentoken/pos/cv340_13287.txt\n",
      "txt_sentoken/pos/cv341_24430.txt\n",
      "txt_sentoken/pos/cv342_19456.txt\n",
      "txt_sentoken/pos/cv343_10368.txt\n",
      "txt_sentoken/pos/cv344_5312.txt\n",
      "txt_sentoken/pos/cv345_9954.txt\n",
      "txt_sentoken/pos/cv346_18168.txt\n",
      "txt_sentoken/pos/cv347_13194.txt\n",
      "txt_sentoken/pos/cv348_18176.txt\n",
      "txt_sentoken/pos/cv349_13507.txt\n",
      "txt_sentoken/pos/cv350_20670.txt\n",
      "txt_sentoken/pos/cv351_15458.txt\n",
      "txt_sentoken/pos/cv352_5524.txt\n",
      "txt_sentoken/pos/cv353_18159.txt\n",
      "txt_sentoken/pos/cv354_8132.txt\n",
      "txt_sentoken/pos/cv355_16413.txt\n",
      "txt_sentoken/pos/cv356_25163.txt\n",
      "txt_sentoken/pos/cv357_13156.txt\n",
      "txt_sentoken/pos/cv358_10691.txt\n",
      "txt_sentoken/pos/cv359_6647.txt\n",
      "txt_sentoken/pos/cv360_8398.txt\n",
      "txt_sentoken/pos/cv361_28944.txt\n",
      "txt_sentoken/pos/cv362_15341.txt\n",
      "txt_sentoken/pos/cv363_29332.txt\n",
      "txt_sentoken/pos/cv364_12901.txt\n",
      "txt_sentoken/pos/cv365_11576.txt\n",
      "txt_sentoken/pos/cv366_10221.txt\n",
      "txt_sentoken/pos/cv367_22792.txt\n",
      "txt_sentoken/pos/cv368_10466.txt\n",
      "txt_sentoken/pos/cv369_12886.txt\n",
      "txt_sentoken/pos/cv370_5221.txt\n",
      "txt_sentoken/pos/cv371_7630.txt\n",
      "txt_sentoken/pos/cv372_6552.txt\n",
      "txt_sentoken/pos/cv373_20404.txt\n",
      "txt_sentoken/pos/cv374_25436.txt\n",
      "txt_sentoken/pos/cv375_9929.txt\n",
      "txt_sentoken/pos/cv376_19435.txt\n",
      "txt_sentoken/pos/cv377_7946.txt\n",
      "txt_sentoken/pos/cv378_20629.txt\n",
      "txt_sentoken/pos/cv379_21963.txt\n",
      "txt_sentoken/pos/cv380_7574.txt\n",
      "txt_sentoken/pos/cv381_20172.txt\n",
      "txt_sentoken/pos/cv382_7897.txt\n",
      "txt_sentoken/pos/cv383_13116.txt\n",
      "txt_sentoken/pos/cv384_17140.txt\n",
      "txt_sentoken/pos/cv385_29741.txt\n",
      "txt_sentoken/pos/cv386_10080.txt\n",
      "txt_sentoken/pos/cv387_11507.txt\n",
      "txt_sentoken/pos/cv388_12009.txt\n",
      "txt_sentoken/pos/cv389_9369.txt\n",
      "txt_sentoken/pos/cv390_11345.txt\n",
      "txt_sentoken/pos/cv391_10802.txt\n",
      "txt_sentoken/pos/cv392_11458.txt\n",
      "txt_sentoken/pos/cv393_29327.txt\n",
      "txt_sentoken/pos/cv394_5137.txt\n",
      "txt_sentoken/pos/cv395_10849.txt\n",
      "txt_sentoken/pos/cv396_17989.txt\n",
      "txt_sentoken/pos/cv397_29023.txt\n",
      "txt_sentoken/pos/cv398_15537.txt\n",
      "txt_sentoken/pos/cv399_2877.txt\n",
      "txt_sentoken/pos/cv400_19220.txt\n",
      "txt_sentoken/pos/cv401_12605.txt\n",
      "txt_sentoken/pos/cv402_14425.txt\n",
      "txt_sentoken/pos/cv403_6621.txt\n",
      "txt_sentoken/pos/cv404_20315.txt\n",
      "txt_sentoken/pos/cv405_20399.txt\n",
      "txt_sentoken/pos/cv406_21020.txt\n",
      "txt_sentoken/pos/cv407_22637.txt\n",
      "txt_sentoken/pos/cv408_5297.txt\n",
      "txt_sentoken/pos/cv409_29786.txt\n",
      "txt_sentoken/pos/cv410_24266.txt\n",
      "txt_sentoken/pos/cv411_15007.txt\n",
      "txt_sentoken/pos/cv412_24095.txt\n",
      "txt_sentoken/pos/cv413_7398.txt\n",
      "txt_sentoken/pos/cv414_10518.txt\n",
      "txt_sentoken/pos/cv415_22517.txt\n",
      "txt_sentoken/pos/cv416_11136.txt\n",
      "txt_sentoken/pos/cv417_13115.txt\n",
      "txt_sentoken/pos/cv418_14774.txt\n",
      "txt_sentoken/pos/cv419_13394.txt\n",
      "txt_sentoken/pos/cv420_28795.txt\n",
      "txt_sentoken/pos/cv421_9709.txt\n",
      "txt_sentoken/pos/cv422_9381.txt\n",
      "txt_sentoken/pos/cv423_11155.txt\n",
      "txt_sentoken/pos/cv424_8831.txt\n",
      "txt_sentoken/pos/cv425_8250.txt\n",
      "txt_sentoken/pos/cv426_10421.txt\n",
      "txt_sentoken/pos/cv427_10825.txt\n",
      "txt_sentoken/pos/cv428_11347.txt\n",
      "txt_sentoken/pos/cv429_7439.txt\n",
      "txt_sentoken/pos/cv430_17351.txt\n",
      "txt_sentoken/pos/cv431_7085.txt\n",
      "txt_sentoken/pos/cv432_14224.txt\n",
      "txt_sentoken/pos/cv433_10144.txt\n",
      "txt_sentoken/pos/cv434_5793.txt\n",
      "txt_sentoken/pos/cv435_23110.txt\n",
      "txt_sentoken/pos/cv436_19179.txt\n",
      "txt_sentoken/pos/cv437_22849.txt\n",
      "txt_sentoken/pos/cv438_8043.txt\n",
      "txt_sentoken/pos/cv439_15970.txt\n",
      "txt_sentoken/pos/cv440_15243.txt\n",
      "txt_sentoken/pos/cv441_13711.txt\n",
      "txt_sentoken/pos/cv442_13846.txt\n",
      "txt_sentoken/pos/cv443_21118.txt\n",
      "txt_sentoken/pos/cv444_9974.txt\n",
      "txt_sentoken/pos/cv445_25882.txt\n",
      "txt_sentoken/pos/cv446_11353.txt\n",
      "txt_sentoken/pos/cv447_27332.txt\n",
      "txt_sentoken/pos/cv448_14695.txt\n",
      "txt_sentoken/pos/cv449_8785.txt\n",
      "txt_sentoken/pos/cv450_7890.txt\n",
      "txt_sentoken/pos/cv451_10690.txt\n",
      "txt_sentoken/pos/cv452_5088.txt\n",
      "txt_sentoken/pos/cv453_10379.txt\n",
      "txt_sentoken/pos/cv454_2053.txt\n",
      "txt_sentoken/pos/cv455_29000.txt\n",
      "txt_sentoken/pos/cv456_18985.txt\n",
      "txt_sentoken/pos/cv457_18453.txt\n",
      "txt_sentoken/pos/cv458_8604.txt\n",
      "txt_sentoken/pos/cv459_20319.txt\n",
      "txt_sentoken/pos/cv460_10842.txt\n",
      "txt_sentoken/pos/cv461_19600.txt\n",
      "txt_sentoken/pos/cv462_19350.txt\n",
      "txt_sentoken/pos/cv463_10343.txt\n",
      "txt_sentoken/pos/cv464_15650.txt\n",
      "txt_sentoken/pos/cv465_22431.txt\n",
      "txt_sentoken/pos/cv466_18722.txt\n",
      "txt_sentoken/pos/cv467_25773.txt\n",
      "txt_sentoken/pos/cv468_15228.txt\n",
      "txt_sentoken/pos/cv469_20630.txt\n",
      "txt_sentoken/pos/cv470_15952.txt\n",
      "txt_sentoken/pos/cv471_16858.txt\n",
      "txt_sentoken/pos/cv472_29280.txt\n",
      "txt_sentoken/pos/cv473_7367.txt\n",
      "txt_sentoken/pos/cv474_10209.txt\n",
      "txt_sentoken/pos/cv475_21692.txt\n",
      "txt_sentoken/pos/cv476_16856.txt\n",
      "txt_sentoken/pos/cv477_22479.txt\n",
      "txt_sentoken/pos/cv478_14309.txt\n",
      "txt_sentoken/pos/cv479_5649.txt\n",
      "txt_sentoken/pos/cv480_19817.txt\n",
      "txt_sentoken/pos/cv481_7436.txt\n",
      "txt_sentoken/pos/cv482_10580.txt\n",
      "txt_sentoken/pos/cv483_16378.txt\n",
      "txt_sentoken/pos/cv484_25054.txt\n",
      "txt_sentoken/pos/cv485_26649.txt\n",
      "txt_sentoken/pos/cv486_9799.txt\n",
      "txt_sentoken/pos/cv487_10446.txt\n",
      "txt_sentoken/pos/cv488_19856.txt\n",
      "txt_sentoken/pos/cv489_17906.txt\n",
      "txt_sentoken/pos/cv490_17872.txt\n",
      "txt_sentoken/pos/cv491_12145.txt\n",
      "txt_sentoken/pos/cv492_18271.txt\n",
      "txt_sentoken/pos/cv493_12839.txt\n",
      "txt_sentoken/pos/cv494_17389.txt\n",
      "txt_sentoken/pos/cv495_14518.txt\n",
      "txt_sentoken/pos/cv496_10530.txt\n",
      "txt_sentoken/pos/cv497_26980.txt\n",
      "txt_sentoken/pos/cv498_8832.txt\n",
      "txt_sentoken/pos/cv499_10658.txt\n",
      "txt_sentoken/pos/cv500_10251.txt\n",
      "txt_sentoken/pos/cv501_11657.txt\n",
      "txt_sentoken/pos/cv502_10406.txt\n",
      "txt_sentoken/pos/cv503_10558.txt\n",
      "txt_sentoken/pos/cv504_29243.txt\n",
      "txt_sentoken/pos/cv505_12090.txt\n",
      "txt_sentoken/pos/cv506_15956.txt\n",
      "txt_sentoken/pos/cv507_9220.txt\n",
      "txt_sentoken/pos/cv508_16006.txt\n",
      "txt_sentoken/pos/cv509_15888.txt\n",
      "txt_sentoken/pos/cv510_23360.txt\n",
      "txt_sentoken/pos/cv511_10132.txt\n",
      "txt_sentoken/pos/cv512_15965.txt\n",
      "txt_sentoken/pos/cv513_6923.txt\n",
      "txt_sentoken/pos/cv514_11187.txt\n",
      "txt_sentoken/pos/cv515_17069.txt\n",
      "txt_sentoken/pos/cv516_11172.txt\n",
      "txt_sentoken/pos/cv517_19219.txt\n",
      "txt_sentoken/pos/cv518_13331.txt\n",
      "txt_sentoken/pos/cv519_14661.txt\n",
      "txt_sentoken/pos/cv520_12295.txt\n",
      "txt_sentoken/pos/cv521_15828.txt\n",
      "txt_sentoken/pos/cv522_5583.txt\n",
      "txt_sentoken/pos/cv523_16615.txt\n",
      "txt_sentoken/pos/cv524_23627.txt\n",
      "txt_sentoken/pos/cv525_16122.txt\n",
      "txt_sentoken/pos/cv526_12083.txt\n",
      "txt_sentoken/pos/cv527_10123.txt\n",
      "txt_sentoken/pos/cv528_10822.txt\n",
      "txt_sentoken/pos/cv529_10420.txt\n",
      "txt_sentoken/pos/cv530_16212.txt\n",
      "txt_sentoken/pos/cv531_26486.txt\n",
      "txt_sentoken/pos/cv532_6522.txt\n",
      "txt_sentoken/pos/cv533_9821.txt\n",
      "txt_sentoken/pos/cv534_14083.txt\n",
      "txt_sentoken/pos/cv535_19728.txt\n",
      "txt_sentoken/pos/cv536_27134.txt\n",
      "txt_sentoken/pos/cv537_12370.txt\n",
      "txt_sentoken/pos/cv538_28667.txt\n",
      "txt_sentoken/pos/cv539_20347.txt\n",
      "txt_sentoken/pos/cv540_3421.txt\n",
      "txt_sentoken/pos/cv541_28835.txt\n",
      "txt_sentoken/pos/cv542_18980.txt\n",
      "txt_sentoken/pos/cv543_5045.txt\n",
      "txt_sentoken/pos/cv544_5108.txt\n",
      "txt_sentoken/pos/cv545_12014.txt\n",
      "txt_sentoken/pos/cv546_11767.txt\n",
      "txt_sentoken/pos/cv547_16324.txt\n",
      "txt_sentoken/pos/cv548_17731.txt\n",
      "txt_sentoken/pos/cv549_21443.txt\n",
      "txt_sentoken/pos/cv550_22211.txt\n",
      "txt_sentoken/pos/cv551_10565.txt\n",
      "txt_sentoken/pos/cv552_10016.txt\n",
      "txt_sentoken/pos/cv553_26915.txt\n",
      "txt_sentoken/pos/cv554_13151.txt\n",
      "txt_sentoken/pos/cv555_23922.txt\n",
      "txt_sentoken/pos/cv556_14808.txt\n",
      "txt_sentoken/pos/cv557_11449.txt\n",
      "txt_sentoken/pos/cv558_29507.txt\n",
      "txt_sentoken/pos/cv559_0050.txt\n",
      "txt_sentoken/pos/cv560_17175.txt\n",
      "txt_sentoken/pos/cv561_9201.txt\n",
      "txt_sentoken/pos/cv562_10359.txt\n",
      "txt_sentoken/pos/cv563_17257.txt\n",
      "txt_sentoken/pos/cv564_11110.txt\n",
      "txt_sentoken/pos/cv565_29572.txt\n",
      "txt_sentoken/pos/cv566_8581.txt\n",
      "txt_sentoken/pos/cv567_29611.txt\n",
      "txt_sentoken/pos/cv568_15638.txt\n",
      "txt_sentoken/pos/cv569_26381.txt\n",
      "txt_sentoken/pos/cv570_29082.txt\n",
      "txt_sentoken/pos/cv571_29366.txt\n",
      "txt_sentoken/pos/cv572_18657.txt\n",
      "txt_sentoken/pos/cv573_29525.txt\n",
      "txt_sentoken/pos/cv574_22156.txt\n",
      "txt_sentoken/pos/cv575_21150.txt\n",
      "txt_sentoken/pos/cv576_14094.txt\n",
      "txt_sentoken/pos/cv577_28549.txt\n",
      "txt_sentoken/pos/cv578_15094.txt\n",
      "txt_sentoken/pos/cv579_11605.txt\n",
      "txt_sentoken/pos/cv580_14064.txt\n",
      "txt_sentoken/pos/cv581_19381.txt\n",
      "txt_sentoken/pos/cv582_6559.txt\n",
      "txt_sentoken/pos/cv583_29692.txt\n",
      "txt_sentoken/pos/cv584_29722.txt\n",
      "txt_sentoken/pos/cv585_22496.txt\n",
      "txt_sentoken/pos/cv586_7543.txt\n",
      "txt_sentoken/pos/cv587_19162.txt\n",
      "txt_sentoken/pos/cv588_13008.txt\n",
      "txt_sentoken/pos/cv589_12064.txt\n",
      "txt_sentoken/pos/cv590_19290.txt\n",
      "txt_sentoken/pos/cv591_23640.txt\n",
      "txt_sentoken/pos/cv592_22315.txt\n",
      "txt_sentoken/pos/cv593_10987.txt\n",
      "txt_sentoken/pos/cv594_11039.txt\n",
      "txt_sentoken/pos/cv595_25335.txt\n",
      "txt_sentoken/pos/cv596_28311.txt\n",
      "txt_sentoken/pos/cv597_26360.txt\n",
      "txt_sentoken/pos/cv598_16452.txt\n",
      "txt_sentoken/pos/cv599_20988.txt\n",
      "txt_sentoken/pos/cv600_23878.txt\n",
      "txt_sentoken/pos/cv601_23453.txt\n",
      "txt_sentoken/pos/cv602_8300.txt\n",
      "txt_sentoken/pos/cv603_17694.txt\n",
      "txt_sentoken/pos/cv604_2230.txt\n",
      "txt_sentoken/pos/cv605_11800.txt\n",
      "txt_sentoken/pos/cv606_15985.txt\n",
      "txt_sentoken/pos/cv607_7717.txt\n",
      "txt_sentoken/pos/cv608_23231.txt\n",
      "txt_sentoken/pos/cv609_23877.txt\n",
      "txt_sentoken/pos/cv610_2287.txt\n",
      "txt_sentoken/pos/cv611_21120.txt\n",
      "txt_sentoken/pos/cv612_5461.txt\n",
      "txt_sentoken/pos/cv613_21796.txt\n",
      "txt_sentoken/pos/cv614_10626.txt\n",
      "txt_sentoken/pos/cv615_14182.txt\n",
      "txt_sentoken/pos/cv616_29319.txt\n",
      "txt_sentoken/pos/cv617_9322.txt\n",
      "txt_sentoken/pos/cv618_8974.txt\n",
      "txt_sentoken/pos/cv619_12462.txt\n",
      "txt_sentoken/pos/cv620_24265.txt\n",
      "txt_sentoken/pos/cv621_14368.txt\n",
      "txt_sentoken/pos/cv622_8147.txt\n",
      "txt_sentoken/pos/cv623_15356.txt\n",
      "txt_sentoken/pos/cv624_10744.txt\n",
      "txt_sentoken/pos/cv625_12440.txt\n",
      "txt_sentoken/pos/cv626_7410.txt\n",
      "txt_sentoken/pos/cv627_11620.txt\n",
      "txt_sentoken/pos/cv628_19325.txt\n",
      "txt_sentoken/pos/cv629_14909.txt\n",
      "txt_sentoken/pos/cv630_10057.txt\n",
      "txt_sentoken/pos/cv631_4967.txt\n",
      "txt_sentoken/pos/cv632_9610.txt\n",
      "txt_sentoken/pos/cv633_29837.txt\n",
      "txt_sentoken/pos/cv634_11101.txt\n",
      "txt_sentoken/pos/cv635_10022.txt\n",
      "txt_sentoken/pos/cv636_15279.txt\n",
      "txt_sentoken/pos/cv637_1250.txt\n",
      "txt_sentoken/pos/cv638_2953.txt\n",
      "txt_sentoken/pos/cv639_10308.txt\n",
      "txt_sentoken/pos/cv640_5378.txt\n",
      "txt_sentoken/pos/cv641_12349.txt\n",
      "txt_sentoken/pos/cv642_29867.txt\n",
      "txt_sentoken/pos/cv643_29349.txt\n",
      "txt_sentoken/pos/cv644_17154.txt\n",
      "txt_sentoken/pos/cv645_15668.txt\n",
      "txt_sentoken/pos/cv646_15065.txt\n",
      "txt_sentoken/pos/cv647_13691.txt\n",
      "txt_sentoken/pos/cv648_15792.txt\n",
      "txt_sentoken/pos/cv649_12735.txt\n",
      "txt_sentoken/pos/cv650_14340.txt\n",
      "txt_sentoken/pos/cv651_10492.txt\n",
      "txt_sentoken/pos/cv652_13972.txt\n",
      "txt_sentoken/pos/cv653_19583.txt\n",
      "txt_sentoken/pos/cv654_18246.txt\n",
      "txt_sentoken/pos/cv655_11154.txt\n",
      "txt_sentoken/pos/cv656_24201.txt\n",
      "txt_sentoken/pos/cv657_24513.txt\n",
      "txt_sentoken/pos/cv658_10532.txt\n",
      "txt_sentoken/pos/cv659_19944.txt\n",
      "txt_sentoken/pos/cv660_21893.txt\n",
      "txt_sentoken/pos/cv661_2450.txt\n",
      "txt_sentoken/pos/cv662_13320.txt\n",
      "txt_sentoken/pos/cv663_13019.txt\n",
      "txt_sentoken/pos/cv664_4389.txt\n",
      "txt_sentoken/pos/cv665_29538.txt\n",
      "txt_sentoken/pos/cv666_18963.txt\n",
      "txt_sentoken/pos/cv667_18467.txt\n",
      "txt_sentoken/pos/cv668_17604.txt\n",
      "txt_sentoken/pos/cv669_22995.txt\n",
      "txt_sentoken/pos/cv670_25826.txt\n",
      "txt_sentoken/pos/cv671_5054.txt\n",
      "txt_sentoken/pos/cv672_28083.txt\n",
      "txt_sentoken/pos/cv673_24714.txt\n",
      "txt_sentoken/pos/cv674_10732.txt\n",
      "txt_sentoken/pos/cv675_21588.txt\n",
      "txt_sentoken/pos/cv676_21090.txt\n",
      "txt_sentoken/pos/cv677_17715.txt\n",
      "txt_sentoken/pos/cv678_13419.txt\n",
      "txt_sentoken/pos/cv679_28559.txt\n",
      "txt_sentoken/pos/cv680_10160.txt\n",
      "txt_sentoken/pos/cv681_9692.txt\n",
      "txt_sentoken/pos/cv682_16139.txt\n",
      "txt_sentoken/pos/cv683_12167.txt\n",
      "txt_sentoken/pos/cv684_11798.txt\n",
      "txt_sentoken/pos/cv685_5947.txt\n",
      "txt_sentoken/pos/cv686_13900.txt\n",
      "txt_sentoken/pos/cv687_21100.txt\n",
      "txt_sentoken/pos/cv688_7368.txt\n",
      "txt_sentoken/pos/cv689_12587.txt\n",
      "txt_sentoken/pos/cv690_5619.txt\n",
      "txt_sentoken/pos/cv691_5043.txt\n",
      "txt_sentoken/pos/cv692_15451.txt\n",
      "txt_sentoken/pos/cv693_18063.txt\n",
      "txt_sentoken/pos/cv694_4876.txt\n",
      "txt_sentoken/pos/cv695_21108.txt\n",
      "txt_sentoken/pos/cv696_29740.txt\n",
      "txt_sentoken/pos/cv697_11162.txt\n",
      "txt_sentoken/pos/cv698_15253.txt\n",
      "txt_sentoken/pos/cv699_7223.txt\n",
      "txt_sentoken/pos/cv700_21947.txt\n",
      "txt_sentoken/pos/cv701_14252.txt\n",
      "txt_sentoken/pos/cv702_11500.txt\n",
      "txt_sentoken/pos/cv703_16143.txt\n",
      "txt_sentoken/pos/cv704_15969.txt\n",
      "txt_sentoken/pos/cv705_11059.txt\n",
      "txt_sentoken/pos/cv706_24716.txt\n",
      "txt_sentoken/pos/cv707_10678.txt\n",
      "txt_sentoken/pos/cv708_28729.txt\n",
      "txt_sentoken/pos/cv709_10529.txt\n",
      "txt_sentoken/pos/cv710_22577.txt\n",
      "txt_sentoken/pos/cv711_11665.txt\n",
      "txt_sentoken/pos/cv712_22920.txt\n",
      "txt_sentoken/pos/cv713_29155.txt\n",
      "txt_sentoken/pos/cv714_18502.txt\n",
      "txt_sentoken/pos/cv715_18179.txt\n",
      "txt_sentoken/pos/cv716_10514.txt\n",
      "txt_sentoken/pos/cv717_15953.txt\n",
      "txt_sentoken/pos/cv718_11434.txt\n",
      "txt_sentoken/pos/cv719_5713.txt\n",
      "txt_sentoken/pos/cv720_5389.txt\n",
      "txt_sentoken/pos/cv721_29121.txt\n",
      "txt_sentoken/pos/cv722_7110.txt\n",
      "txt_sentoken/pos/cv723_8648.txt\n",
      "txt_sentoken/pos/cv724_13681.txt\n",
      "txt_sentoken/pos/cv725_10103.txt\n",
      "txt_sentoken/pos/cv726_4719.txt\n",
      "txt_sentoken/pos/cv727_4978.txt\n",
      "txt_sentoken/pos/cv728_16133.txt\n",
      "txt_sentoken/pos/cv729_10154.txt\n",
      "txt_sentoken/pos/cv730_10279.txt\n",
      "txt_sentoken/pos/cv731_4136.txt\n",
      "txt_sentoken/pos/cv732_12245.txt\n",
      "txt_sentoken/pos/cv733_9839.txt\n",
      "txt_sentoken/pos/cv734_21568.txt\n",
      "txt_sentoken/pos/cv735_18801.txt\n",
      "txt_sentoken/pos/cv736_23670.txt\n",
      "txt_sentoken/pos/cv737_28907.txt\n",
      "txt_sentoken/pos/cv738_10116.txt\n",
      "txt_sentoken/pos/cv739_11209.txt\n",
      "txt_sentoken/pos/cv740_12445.txt\n",
      "txt_sentoken/pos/cv741_11890.txt\n",
      "txt_sentoken/pos/cv742_7751.txt\n",
      "txt_sentoken/pos/cv743_15449.txt\n",
      "txt_sentoken/pos/cv744_10038.txt\n",
      "txt_sentoken/pos/cv745_12773.txt\n",
      "txt_sentoken/pos/cv746_10147.txt\n",
      "txt_sentoken/pos/cv747_16556.txt\n",
      "txt_sentoken/pos/cv748_12786.txt\n",
      "txt_sentoken/pos/cv749_17765.txt\n",
      "txt_sentoken/pos/cv750_10180.txt\n",
      "txt_sentoken/pos/cv751_15719.txt\n",
      "txt_sentoken/pos/cv752_24155.txt\n",
      "txt_sentoken/pos/cv753_10875.txt\n",
      "txt_sentoken/pos/cv754_7216.txt\n",
      "txt_sentoken/pos/cv755_23616.txt\n",
      "txt_sentoken/pos/cv756_22540.txt\n",
      "txt_sentoken/pos/cv757_10189.txt\n",
      "txt_sentoken/pos/cv758_9671.txt\n",
      "txt_sentoken/pos/cv759_13522.txt\n",
      "txt_sentoken/pos/cv760_8597.txt\n",
      "txt_sentoken/pos/cv761_12620.txt\n",
      "txt_sentoken/pos/cv762_13927.txt\n",
      "txt_sentoken/pos/cv763_14729.txt\n",
      "txt_sentoken/pos/cv764_11739.txt\n",
      "txt_sentoken/pos/cv765_19037.txt\n",
      "txt_sentoken/pos/cv766_7540.txt\n",
      "txt_sentoken/pos/cv767_14062.txt\n",
      "txt_sentoken/pos/cv768_11751.txt\n",
      "txt_sentoken/pos/cv769_8123.txt\n",
      "txt_sentoken/pos/cv770_10451.txt\n",
      "txt_sentoken/pos/cv771_28665.txt\n",
      "txt_sentoken/pos/cv772_12119.txt\n",
      "txt_sentoken/pos/cv773_18817.txt\n",
      "txt_sentoken/pos/cv774_13845.txt\n",
      "txt_sentoken/pos/cv775_16237.txt\n",
      "txt_sentoken/pos/cv776_20529.txt\n",
      "txt_sentoken/pos/cv777_10094.txt\n",
      "txt_sentoken/pos/cv778_17330.txt\n",
      "txt_sentoken/pos/cv779_17881.txt\n",
      "txt_sentoken/pos/cv780_7984.txt\n",
      "txt_sentoken/pos/cv781_5262.txt\n",
      "txt_sentoken/pos/cv782_19526.txt\n",
      "txt_sentoken/pos/cv783_13227.txt\n",
      "txt_sentoken/pos/cv784_14394.txt\n",
      "txt_sentoken/pos/cv785_22600.txt\n",
      "txt_sentoken/pos/cv786_22497.txt\n",
      "txt_sentoken/pos/cv787_13743.txt\n",
      "txt_sentoken/pos/cv788_25272.txt\n",
      "txt_sentoken/pos/cv789_12136.txt\n",
      "txt_sentoken/pos/cv790_14600.txt\n",
      "txt_sentoken/pos/cv791_16302.txt\n",
      "txt_sentoken/pos/cv792_3832.txt\n",
      "txt_sentoken/pos/cv793_13650.txt\n",
      "txt_sentoken/pos/cv794_15868.txt\n",
      "txt_sentoken/pos/cv795_10122.txt\n",
      "txt_sentoken/pos/cv796_15782.txt\n",
      "txt_sentoken/pos/cv797_6957.txt\n",
      "txt_sentoken/pos/cv798_23531.txt\n",
      "txt_sentoken/pos/cv799_18543.txt\n",
      "txt_sentoken/pos/cv800_12368.txt\n",
      "txt_sentoken/pos/cv801_25228.txt\n",
      "txt_sentoken/pos/cv802_28664.txt\n",
      "txt_sentoken/pos/cv803_8207.txt\n",
      "txt_sentoken/pos/cv804_10862.txt\n",
      "txt_sentoken/pos/cv805_19601.txt\n",
      "txt_sentoken/pos/cv806_8842.txt\n",
      "txt_sentoken/pos/cv807_21740.txt\n",
      "txt_sentoken/pos/cv808_12635.txt\n",
      "txt_sentoken/pos/cv809_5009.txt\n",
      "txt_sentoken/pos/cv810_12458.txt\n",
      "txt_sentoken/pos/cv811_21386.txt\n",
      "txt_sentoken/pos/cv812_17924.txt\n",
      "txt_sentoken/pos/cv813_6534.txt\n",
      "txt_sentoken/pos/cv814_18975.txt\n",
      "txt_sentoken/pos/cv815_22456.txt\n",
      "txt_sentoken/pos/cv816_13655.txt\n",
      "txt_sentoken/pos/cv817_4041.txt\n",
      "txt_sentoken/pos/cv818_10211.txt\n",
      "txt_sentoken/pos/cv819_9364.txt\n",
      "txt_sentoken/pos/cv820_22892.txt\n",
      "txt_sentoken/pos/cv821_29364.txt\n",
      "txt_sentoken/pos/cv822_20049.txt\n",
      "txt_sentoken/pos/cv823_15569.txt\n",
      "txt_sentoken/pos/cv824_8838.txt\n",
      "txt_sentoken/pos/cv825_5063.txt\n",
      "txt_sentoken/pos/cv826_11834.txt\n",
      "txt_sentoken/pos/cv827_18331.txt\n",
      "txt_sentoken/pos/cv828_19831.txt\n",
      "txt_sentoken/pos/cv829_20289.txt\n",
      "txt_sentoken/pos/cv830_6014.txt\n",
      "txt_sentoken/pos/cv831_14689.txt\n",
      "txt_sentoken/pos/cv832_23275.txt\n",
      "txt_sentoken/pos/cv833_11053.txt\n",
      "txt_sentoken/pos/cv834_22195.txt\n",
      "txt_sentoken/pos/cv835_19159.txt\n",
      "txt_sentoken/pos/cv836_12968.txt\n",
      "txt_sentoken/pos/cv837_27325.txt\n",
      "txt_sentoken/pos/cv838_24728.txt\n",
      "txt_sentoken/pos/cv839_21467.txt\n",
      "txt_sentoken/pos/cv840_16321.txt\n",
      "txt_sentoken/pos/cv841_3967.txt\n",
      "txt_sentoken/pos/cv842_5866.txt\n",
      "txt_sentoken/pos/cv843_15544.txt\n",
      "txt_sentoken/pos/cv844_12690.txt\n",
      "txt_sentoken/pos/cv845_14290.txt\n",
      "txt_sentoken/pos/cv846_29497.txt\n",
      "txt_sentoken/pos/cv847_1941.txt\n",
      "txt_sentoken/pos/cv848_10036.txt\n",
      "txt_sentoken/pos/cv849_15729.txt\n",
      "txt_sentoken/pos/cv850_16466.txt\n",
      "txt_sentoken/pos/cv851_20469.txt\n",
      "txt_sentoken/pos/cv852_27523.txt\n",
      "txt_sentoken/pos/cv853_29233.txt\n",
      "txt_sentoken/pos/cv854_17740.txt\n",
      "txt_sentoken/pos/cv855_20661.txt\n",
      "txt_sentoken/pos/cv856_29013.txt\n",
      "txt_sentoken/pos/cv857_15958.txt\n",
      "txt_sentoken/pos/cv858_18819.txt\n",
      "txt_sentoken/pos/cv859_14107.txt\n",
      "txt_sentoken/pos/cv860_13853.txt\n",
      "txt_sentoken/pos/cv861_1198.txt\n",
      "txt_sentoken/pos/cv862_14324.txt\n",
      "txt_sentoken/pos/cv863_7424.txt\n",
      "txt_sentoken/pos/cv864_3416.txt\n",
      "txt_sentoken/pos/cv865_2895.txt\n",
      "txt_sentoken/pos/cv866_29691.txt\n",
      "txt_sentoken/pos/cv867_16661.txt\n",
      "txt_sentoken/pos/cv868_11948.txt\n",
      "txt_sentoken/pos/cv869_23611.txt\n",
      "txt_sentoken/pos/cv870_16348.txt\n",
      "txt_sentoken/pos/cv871_24888.txt\n",
      "txt_sentoken/pos/cv872_12591.txt\n",
      "txt_sentoken/pos/cv873_18636.txt\n",
      "txt_sentoken/pos/cv874_11236.txt\n",
      "txt_sentoken/pos/cv875_5754.txt\n",
      "txt_sentoken/pos/cv876_9390.txt\n",
      "txt_sentoken/pos/cv877_29274.txt\n",
      "txt_sentoken/pos/cv878_15694.txt\n",
      "txt_sentoken/pos/cv879_14903.txt\n",
      "txt_sentoken/pos/cv880_29800.txt\n",
      "txt_sentoken/pos/cv881_13254.txt\n",
      "txt_sentoken/pos/cv882_10026.txt\n",
      "txt_sentoken/pos/cv883_27751.txt\n",
      "txt_sentoken/pos/cv884_13632.txt\n",
      "txt_sentoken/pos/cv885_12318.txt\n",
      "txt_sentoken/pos/cv886_18177.txt\n",
      "txt_sentoken/pos/cv887_5126.txt\n",
      "txt_sentoken/pos/cv888_24435.txt\n",
      "txt_sentoken/pos/cv889_21430.txt\n",
      "txt_sentoken/pos/cv890_3977.txt\n",
      "txt_sentoken/pos/cv891_6385.txt\n",
      "txt_sentoken/pos/cv892_17576.txt\n",
      "txt_sentoken/pos/cv893_26269.txt\n",
      "txt_sentoken/pos/cv894_2068.txt\n",
      "txt_sentoken/pos/cv895_21022.txt\n",
      "txt_sentoken/pos/cv896_16071.txt\n",
      "txt_sentoken/pos/cv897_10837.txt\n",
      "txt_sentoken/pos/cv898_14187.txt\n",
      "txt_sentoken/pos/cv899_16014.txt\n",
      "txt_sentoken/pos/cv900_10331.txt\n",
      "txt_sentoken/pos/cv901_11017.txt\n",
      "txt_sentoken/pos/cv902_12256.txt\n",
      "txt_sentoken/pos/cv903_17822.txt\n",
      "txt_sentoken/pos/cv904_24353.txt\n",
      "txt_sentoken/pos/cv905_29114.txt\n",
      "txt_sentoken/pos/cv906_11491.txt\n",
      "txt_sentoken/pos/cv907_3541.txt\n",
      "txt_sentoken/pos/cv908_16009.txt\n",
      "txt_sentoken/pos/cv909_9960.txt\n",
      "txt_sentoken/pos/cv910_20488.txt\n",
      "txt_sentoken/pos/cv911_20260.txt\n",
      "txt_sentoken/pos/cv912_5674.txt\n",
      "txt_sentoken/pos/cv913_29252.txt\n",
      "txt_sentoken/pos/cv914_28742.txt\n",
      "txt_sentoken/pos/cv915_8841.txt\n",
      "txt_sentoken/pos/cv916_15467.txt\n",
      "txt_sentoken/pos/cv917_29715.txt\n",
      "txt_sentoken/pos/cv918_2693.txt\n",
      "txt_sentoken/pos/cv919_16380.txt\n",
      "txt_sentoken/pos/cv920_29622.txt\n",
      "txt_sentoken/pos/cv921_12747.txt\n",
      "txt_sentoken/pos/cv922_10073.txt\n",
      "txt_sentoken/pos/cv923_11051.txt\n",
      "txt_sentoken/pos/cv924_29540.txt\n",
      "txt_sentoken/pos/cv925_8969.txt\n",
      "txt_sentoken/pos/cv926_17059.txt\n",
      "txt_sentoken/pos/cv927_10681.txt\n",
      "txt_sentoken/pos/cv928_9168.txt\n",
      "txt_sentoken/pos/cv929_16908.txt\n",
      "txt_sentoken/pos/cv930_13475.txt\n",
      "txt_sentoken/pos/cv931_17563.txt\n",
      "txt_sentoken/pos/cv932_13401.txt\n",
      "txt_sentoken/pos/cv933_23776.txt\n",
      "txt_sentoken/pos/cv934_19027.txt\n",
      "txt_sentoken/pos/cv935_23841.txt\n",
      "txt_sentoken/pos/cv936_15954.txt\n",
      "txt_sentoken/pos/cv937_9811.txt\n",
      "txt_sentoken/pos/cv938_10220.txt\n",
      "txt_sentoken/pos/cv939_10583.txt\n",
      "txt_sentoken/pos/cv940_17705.txt\n",
      "txt_sentoken/pos/cv941_10246.txt\n",
      "txt_sentoken/pos/cv942_17082.txt\n",
      "txt_sentoken/pos/cv943_22488.txt\n",
      "txt_sentoken/pos/cv944_13521.txt\n",
      "txt_sentoken/pos/cv945_12160.txt\n",
      "txt_sentoken/pos/cv946_18658.txt\n",
      "txt_sentoken/pos/cv947_10601.txt\n",
      "txt_sentoken/pos/cv948_24606.txt\n",
      "txt_sentoken/pos/cv949_20112.txt\n",
      "txt_sentoken/pos/cv950_12350.txt\n",
      "txt_sentoken/pos/cv951_10926.txt\n",
      "txt_sentoken/pos/cv952_25240.txt\n",
      "txt_sentoken/pos/cv953_6836.txt\n",
      "txt_sentoken/pos/cv954_18628.txt\n",
      "txt_sentoken/pos/cv955_25001.txt\n",
      "txt_sentoken/pos/cv956_11609.txt\n",
      "txt_sentoken/pos/cv957_8737.txt\n",
      "txt_sentoken/pos/cv958_12162.txt\n",
      "txt_sentoken/pos/cv959_14611.txt\n",
      "txt_sentoken/pos/cv960_29007.txt\n",
      "txt_sentoken/pos/cv961_5682.txt\n",
      "txt_sentoken/pos/cv962_9803.txt\n",
      "txt_sentoken/pos/cv963_6895.txt\n",
      "txt_sentoken/pos/cv964_6021.txt\n",
      "txt_sentoken/pos/cv965_26071.txt\n",
      "txt_sentoken/pos/cv966_28832.txt\n",
      "txt_sentoken/pos/cv967_5788.txt\n",
      "txt_sentoken/pos/cv968_24218.txt\n",
      "txt_sentoken/pos/cv969_13250.txt\n",
      "txt_sentoken/pos/cv970_18450.txt\n",
      "txt_sentoken/pos/cv971_10874.txt\n",
      "txt_sentoken/pos/cv972_26417.txt\n",
      "txt_sentoken/pos/cv973_10066.txt\n",
      "txt_sentoken/pos/cv974_22941.txt\n",
      "txt_sentoken/pos/cv975_10981.txt\n",
      "txt_sentoken/pos/cv976_10267.txt\n",
      "txt_sentoken/pos/cv977_4938.txt\n",
      "txt_sentoken/pos/cv978_20929.txt\n",
      "txt_sentoken/pos/cv979_18921.txt\n",
      "txt_sentoken/pos/cv980_10953.txt\n",
      "txt_sentoken/pos/cv981_14989.txt\n",
      "txt_sentoken/pos/cv982_21103.txt\n",
      "txt_sentoken/pos/cv983_22928.txt\n",
      "txt_sentoken/pos/cv984_12767.txt\n",
      "txt_sentoken/pos/cv985_6359.txt\n",
      "txt_sentoken/pos/cv986_13527.txt\n",
      "txt_sentoken/pos/cv987_6965.txt\n",
      "txt_sentoken/pos/cv988_18740.txt\n",
      "txt_sentoken/pos/cv989_15824.txt\n",
      "txt_sentoken/pos/cv990_11591.txt\n",
      "txt_sentoken/pos/cv991_18645.txt\n",
      "txt_sentoken/pos/cv992_11962.txt\n",
      "txt_sentoken/pos/cv993_29737.txt\n",
      "txt_sentoken/pos/cv994_12270.txt\n",
      "txt_sentoken/pos/cv995_21821.txt\n",
      "txt_sentoken/pos/cv996_11592.txt\n",
      "txt_sentoken/pos/cv997_5046.txt\n",
      "txt_sentoken/pos/cv998_14111.txt\n",
      "txt_sentoken/pos/cv999_13106.txt\n",
      "poldata.README.2.0\n"
     ]
    }
   ],
   "source": [
    "!tar xvzf review_polarity.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d414c1e2-e967-4384-8d3e-3981c7815862",
   "metadata": {
    "id": "d414c1e2-e967-4384-8d3e-3981c7815862"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "\n",
    "dataset_path = 'txt_sentoken'\n",
    "movie_reviews = load_files(container_path = dataset_path, encoding = 'utf-8')\n",
    "\n",
    "\n",
    "x = movie_reviews.data            #the data\n",
    "y = movie_reviews.target          #the labels\n",
    "z = movie_reviews.target_names    #the names of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a309b1c-5b50-4b6c-bb0b-27392f5949f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a309b1c-5b50-4b6c-bb0b-27392f5949f8",
    "outputId": "125baf1e-7c76-4d98-80c8-fbae70c9514f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090e57a5-8c4d-4887-ace5-8dfc8e8ed3a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "090e57a5-8c4d-4887-ace5-8dfc8e8ed3a6",
    "outputId": "5a668139-ba14-4eb9-daa4-534fc562a3b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9c8b3c-195a-4956-b387-1f514bed48e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf9c8b3c-195a-4956-b387-1f514bed48e0",
    "outputId": "3afca48f-5cf5-4dce-de2a-a1238fe80b09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3d968-7410-4763-b9df-afee4286e36d",
   "metadata": {
    "id": "84c3d968-7410-4763-b9df-afee4286e36d"
   },
   "source": [
    "## Average Document Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4c8cdd-6239-4c5f-b430-acbc6b6bffae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f4c8cdd-6239-4c5f-b430-acbc6b6bffae",
    "outputId": "d7df9d6c-5010-41ef-c19b-dc7a4a2df964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c6f2807-7676-448e-b3aa-01ca9b61cda2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c6f2807-7676-448e-b3aa-01ca9b61cda2",
    "outputId": "a14c8c6b-fba4-4637-8086-84f6b9434a63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3126"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wDNKEYR67iEF",
   "metadata": {
    "id": "wDNKEYR67iEF"
   },
   "outputs": [],
   "source": [
    "def average_doc_length(corpus):\n",
    "    ''' Takes as input a whole corpus\n",
    "      Returns the average number of words and chars per document '''\n",
    "\n",
    "    document_word_lengths = [len(doc.split()) for doc in corpus]                            #length of each doc (in words)\n",
    "    average_doc_length_words = sum(document_word_lengths) / len(document_word_lengths)      #average doc length (in words)\n",
    "\n",
    "    document_char_lengths = [len(doc) for doc in corpus]                                    #length of each doc (in characters)\n",
    "    average_doc_length_chars = sum(document_char_lengths) / len(document_char_lengths)      #average doc length (in characters)\n",
    "\n",
    "    return average_doc_length_words, average_doc_length_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "639a1e2f-8f79-4d85-8289-1bf47238f10e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "639a1e2f-8f79-4d85-8289-1bf47238f10e",
    "outputId": "9e2e496e-37f4-4196-ec46-e7b0328782d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Before preprocessing---\n",
      "Average Document Length (in words): 746.3405\n",
      "Average Document Length (in characters): 3893.002\n"
     ]
    }
   ],
   "source": [
    "#from common import average_doc_length\n",
    "print(\"---Before preprocessing---\")\n",
    "avg_length_words, avg_length_chars = average_doc_length(x)\n",
    "print(\"Average Document Length (in words):\", avg_length_words)\n",
    "print(\"Average Document Length (in characters):\", avg_length_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb82d229-1baa-4e0a-a331-b3b093f6db93",
   "metadata": {
    "id": "fb82d229-1baa-4e0a-a331-b3b093f6db93"
   },
   "source": [
    "## Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ByZOdhlYIrmH",
   "metadata": {
    "id": "ByZOdhlYIrmH"
   },
   "source": [
    "Let's take a look at the 100 most frequent words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0HwWtwMf6hVH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HwWtwMf6hVH",
    "outputId": "45e4434b-15b6-4d35-8236-e76d8fb71bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",: 77717 occurrences\n",
      "the: 76276 occurrences\n",
      ".: 65876 occurrences\n",
      "a: 37995 occurrences\n",
      "and: 35404 occurrences\n",
      "of: 33972 occurrences\n",
      "to: 31772 occurrences\n",
      "is: 26054 occurrences\n",
      "in: 21611 occurrences\n",
      "'s: 18128 occurrences\n",
      "``: 17625 occurrences\n",
      "it: 16059 occurrences\n",
      "that: 15912 occurrences\n",
      "): 11781 occurrences\n",
      "(: 11664 occurrences\n",
      "as: 11349 occurrences\n",
      "with: 10782 occurrences\n",
      "for: 9918 occurrences\n",
      "this: 9573 occurrences\n",
      "his: 9569 occurrences\n",
      "film: 9443 occurrences\n",
      "i: 8850 occurrences\n",
      "he: 8840 occurrences\n",
      "but: 8604 occurrences\n",
      "on: 7249 occurrences\n",
      "are: 7204 occurrences\n",
      "by: 6218 occurrences\n",
      "n't: 6217 occurrences\n",
      "be: 6083 occurrences\n",
      "an: 5742 occurrences\n",
      "who: 5680 occurrences\n",
      "not: 5672 occurrences\n",
      "movie: 5671 occurrences\n",
      "one: 5582 occurrences\n",
      "you: 5286 occurrences\n",
      "was: 5225 occurrences\n",
      "have: 5046 occurrences\n",
      "from: 4987 occurrences\n",
      "at: 4972 occurrences\n",
      "they: 4815 occurrences\n",
      "has: 4811 occurrences\n",
      "her: 4508 occurrences\n",
      "all: 4259 occurrences\n",
      "?: 3771 occurrences\n",
      "there: 3758 occurrences\n",
      "so: 3585 occurrences\n",
      "like: 3547 occurrences\n",
      "about: 3518 occurrences\n",
      "out: 3442 occurrences\n",
      "more: 3342 occurrences\n",
      "what: 3310 occurrences\n",
      "when: 3255 occurrences\n",
      "which: 3160 occurrences\n",
      "she: 3129 occurrences\n",
      "their: 3117 occurrences\n",
      "up: 3108 occurrences\n",
      "or: 3106 occurrences\n",
      "do: 3090 occurrences\n",
      ":: 3042 occurrences\n",
      "some: 2981 occurrences\n",
      "just: 2901 occurrences\n",
      "does: 2834 occurrences\n",
      "if: 2792 occurrences\n",
      "we: 2761 occurrences\n",
      "him: 2631 occurrences\n",
      "into: 2618 occurrences\n",
      "even: 2556 occurrences\n",
      "only: 2485 occurrences\n",
      "than: 2438 occurrences\n",
      "no: 2408 occurrences\n",
      "can: 2379 occurrences\n",
      "good: 2316 occurrences\n",
      "most: 2302 occurrences\n",
      "time: 2282 occurrences\n",
      "its: 2268 occurrences\n",
      "would: 2264 occurrences\n",
      "will: 2213 occurrences\n",
      "story: 2146 occurrences\n",
      "--: 2055 occurrences\n",
      "been: 2045 occurrences\n",
      "much: 2024 occurrences\n",
      "character: 1996 occurrences\n",
      "also: 1965 occurrences\n",
      "other: 1944 occurrences\n",
      "get: 1925 occurrences\n",
      "': 1885 occurrences\n",
      "them: 1877 occurrences\n",
      "very: 1862 occurrences\n",
      "characters: 1858 occurrences\n",
      ";: 1850 occurrences\n",
      "two: 1827 occurrences\n",
      "first: 1769 occurrences\n",
      "after: 1755 occurrences\n",
      "see: 1731 occurrences\n",
      "!: 1713 occurrences\n",
      "because: 1682 occurrences\n",
      "way: 1669 occurrences\n",
      "well: 1656 occurrences\n",
      "could: 1609 occurrences\n",
      "make: 1593 occurrences\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(x)\n",
    "tokens = word_tokenize(text.lower())              #convert to lowercase to treat words case-insensitively\n",
    "#tokens = [token.lower() for token in x]\n",
    "word_counts = Counter(tokens)\n",
    "top_100_words = word_counts.most_common(100)\n",
    "\n",
    "for word, count in top_100_words:\n",
    "  print(f\"{word}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kN30flXUIy1J",
   "metadata": {
    "id": "kN30flXUIy1J"
   },
   "source": [
    "The english stopwords is a package of 179 words that in general, would not help in a sentiment analysis problem. But, since they include terms that are negative, removing them could prove harmful for our case.\n",
    "\n",
    "e.g. imagine the phrase \"I didn't like the film\" to end up \"like film\".\n",
    "\n",
    "So, the plan is to remove all the stop words that include negative meaning before the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "EW31ByWhG80h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EW31ByWhG80h",
    "outputId": "449d5490-b107-4ac0-f6bd-a44ab1c6e086"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oOXMvNL1_x94",
   "metadata": {
    "id": "oOXMvNL1_x94"
   },
   "source": [
    " From these words, we will decide which ones to keep because in fact they have a meaningful impact in our sentiment analysis problem, as we stated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "q4JeOUnaDu_J",
   "metadata": {
    "id": "q4JeOUnaDu_J"
   },
   "outputs": [],
   "source": [
    "set_stop_words = set(stopwords.words('english'))\n",
    "set_x = set(tokens)\n",
    "to_keep_words = ['not', \"don't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"hadn't\", \"hasn't\" , \"shouldn't\", \"haven't\", \"wasn't\", \"weren't\",  \"isn't\", \"doesn\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rWeLNvZcHwvC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWeLNvZcHwvC",
    "outputId": "fab5ab5c-f1cf-4153-d423-55f8ca4070b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "14\n",
      "165\n"
     ]
    }
   ],
   "source": [
    "stopwords_updated = set(stopwords.words('english')) - set(to_keep_words)\n",
    "print(len(stopwords.words('english')))\n",
    "print(len(to_keep_words))\n",
    "print(len(stopwords_updated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b5d72f-a3d8-4504-ae30-8a5216ff038d",
   "metadata": {
    "id": "03b5d72f-a3d8-4504-ae30-8a5216ff038d"
   },
   "outputs": [],
   "source": [
    "def pre_process_text(text):\n",
    "    ''' Function to preprocess text.\n",
    "     input: initial text\n",
    "     output: processed text\n",
    "     Performs pre-processing methods:\n",
    "        1. Combination to a single document.\n",
    "        2. Convertion to lowercase.\n",
    "        3. Lemmatization and stop words extraction\n",
    "        4. Punctuation removal\n",
    "        5. Number removal\n",
    "        6. Single characters removal\n",
    "        7. Converting multiple spaces to single ones\n",
    "        '''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    all_docs = []\n",
    "\n",
    "    single_char = re.compile(r'\\s+[a-z]\\s+')                                          #6. Remove single characters\n",
    "    multiple_space= re.compile(r'\\s+')                                                 #7. Replace multiple space with a single one\n",
    "\n",
    "    stopwords_updated = set(stopwords.words('english')) - set(to_keep_words)\n",
    "    for document in tqdm(x):\n",
    "\n",
    "        combined_text = ' '.join(text)            #1.Combine in one single document\n",
    "\n",
    "        combined_text = combined_text.lower()    #2. Convert to lowercase\n",
    "        combined_text = [lemmatizer.lemmatize(word) for word in document.split() if word not in stopwords_updated]  # 3.Lemmatize and remove stop words\n",
    "\n",
    "\n",
    "        combined_text = ' '.join(combined_text)\n",
    "\n",
    "        combined_text = ''.join([char for char in combined_text if char not in string.punctuation])   #4.remove punctuation\n",
    "        combined_text = ''.join([char for char in combined_text if not char.isdigit()])     #5.remove numbers\n",
    "\n",
    "        res = single_char.sub(combined_text, '')\n",
    "        res2 = multiple_space.sub(combined_text, ' ')\n",
    "        all_docs.append(combined_text)\n",
    "\n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03cecf2b-efb5-487b-94d0-de2666c5b724",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205,
     "referenced_widgets": [
      "efd411dc932e4e22be0c8fac54980f2f",
      "60b3adea3ef44003855d0ff2b80615b2",
      "1f20b5bb7d4047d590feaca68dc42bd4",
      "e3f31da4bba74c78a7391b09073db313",
      "b89cc201689a403fb5a29eb128e2580e",
      "a743fc251bfe4047bec57294de574712",
      "62ca82bacb48437c8f9aacb227dffd19",
      "0c8fef8ac4b54e4d9aaaea5850ab9eff",
      "3b336a10bef144a6844edd1da9a5c023",
      "8f0f0e9457a54be4be063c36b4c488a1",
      "f7d05083994f473b990512ced48c27dc"
     ]
    },
    "id": "03cecf2b-efb5-487b-94d0-de2666c5b724",
    "outputId": "d056f2da-b9f1-4110-ec8d-5139eff60ba5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c1f15e3fd54264a023e113822f9b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['arnold schwarzenegger icon action enthusiast  since late s  lately film sloppy oneliner getting worse  hard seeing arnold mr  freeze batman robin  especially say ton ice joke  hey got  million  whats matter  arnold signed another expensive blockbuster  cant compare like terminator series  true lie even eraser  called dark thriller  devil  gabriel byrne  come upon earth  impregnate woman  robin tunney  happens every  year  basically destroy world  apparently god chosen one man  one man jericho cane  arnold   help trusty sidekick  kevin pollack   stop nothing let devil take world  part actually absurd  would fit right dogma  yes  film weak  better blockbuster right  sleepy hollow   make world not enough look like  star film  anyway  definitely doesnt seem like arnold movie  wasnt type film see  sure gave u chuckle well known oneliner  seemed confused character film going  understandable  especially ending changed according source  aside form  still walked  much like past film  im sorry say arnold maybe end action day  speaking action  film  hardly explosion fight  devil made place explode  arnold wasnt kicking devil butt  ending changed make spiritual  undoubtedly ruined film  least hoping cool ending nothing else occurred  let  also dont know film took long cost much  really super affect  unless consider invisible devil   minute top  worth overpriced budget  budget gone better script  least audience could somewhat entertained instead facing boredom  pitiful see script like get bought made movie  even read thing anymore  sure doesnt seem like  thankfully gabriels performance gave light poor film  walk street searching robin tunney  cant help feel looked like devil  guy creepy looking anyway   glad end movie  dont bother see  expecting solid action flick  neither solid action  another movie suckered seeing  due strategic marketing campaign  save money see world not enough entertaining experience ']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text = pre_process_text(x)\n",
    "\n",
    "processed_text[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tXfE8DYjnbQF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "tXfE8DYjnbQF",
    "outputId": "3849a0ba-b7ba-48e2-f309-ab96025299ca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_counts = [len(doc.split()) for doc in x]\n",
    "\n",
    "# Plotting\n",
    "plt.bar(range(len(word_counts)), word_counts, color='blue')\n",
    "plt.xlabel('Document Index')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Number of Words in Each Document')\n",
    "plt.xticks(range(len(word_counts)), range(1, len(word_counts)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "xQ16A-Fv3M8Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQ16A-Fv3M8Y",
    "outputId": "ccc27345-81a0-4604-9578-f57dfb5b486d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---After preprocessing---\n",
      "Average Document Length (in words): 746.3405\n",
      "Average Document Length (in characters): 3893.002\n"
     ]
    }
   ],
   "source": [
    "print(\"---After preprocessing---\")\n",
    "avg_length_words_after, avg_length_chars_after = average_doc_length(processed_text)\n",
    "print(\"Average Document Length (in words):\", avg_length_words)\n",
    "print(\"Average Document Length (in characters):\", avg_length_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f5f7f-c35e-4598-a662-0201cad098bf",
   "metadata": {
    "id": "c02f5f7f-c35e-4598-a662-0201cad098bf"
   },
   "source": [
    "## Splitting into training set (60%), development set (20%) and test set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4c7b5bf-67cd-4b64-9aa6-397553e4e2dc",
   "metadata": {
    "id": "b4c7b5bf-67cd-4b64-9aa6-397553e4e2dc"
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(processed_text, y, test_size=0.4, random_state=17)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=25)\n",
    "\n",
    "training_text = ' '.join(X_train)                    #Flatten into a single string\n",
    "development_text = ' '.join(X_dev)\n",
    "test_text = ' '.join(X_test)\n",
    "\n",
    "training_words = training_text.split()\n",
    "development_words = development_text.split()\n",
    "test_words = test_text.split()\n",
    "\n",
    "training_vocab = set(training_words)\n",
    "development_vocab = set(development_words)\n",
    "test_vocab = set(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ddd1654-381d-465d-a938-25a278114bcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ddd1654-381d-465d-a938-25a278114bcd",
    "outputId": "cc0bbee6-0c60-456a-fbe3-94e20291ce56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (in documents):  1200\n",
      "Development set size (in documents):  400\n",
      "Test set size (in documents):  400\n",
      "Full size (sanity check):  2000\n",
      "---------------------------------\n",
      "Training vocabulary size (in words):  33949\n",
      "Development vocabulary size (in words):  19699\n",
      "Test vocabulary size (in words):  19872\n",
      "Full vocabulary size (in words):  73520\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size (in documents): \", len(y_train))\n",
    "print(\"Development set size (in documents): \", len(y_dev))\n",
    "print(\"Test set size (in documents): \", len(y_test))\n",
    "print(\"Full size (sanity check): \", len(y_train) + len(y_dev) + len(y_test))\n",
    "print(\"---------------------------------\")\n",
    "print(\"Training vocabulary size (in words): \" , len(training_vocab))\n",
    "print(\"Development vocabulary size (in words): \", len(development_vocab))\n",
    "print(\"Test vocabulary size (in words): \", len(test_vocab))\n",
    "print(\"Full vocabulary size (in words): \", len(training_vocab) + len(development_vocab) + len(test_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7506630-3bcd-484b-a332-9b24e40952a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7506630-3bcd-484b-a332-9b24e40952a8",
    "outputId": "06b0da40-aeec-4ba5-af7c-7dac48d27f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (training data):  (1200, 5000)\n",
      "Shape (development data):  (400, 5000)\n",
      "Shape (test data):  (400, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2),                                        #Using unigram and bigram tf-idf features\n",
    "                             max_features = 5000, sublinear_tf=True)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_dev_tfidf = vectorizer.transform(X_dev)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Shape (training data): \", X_train_tfidf.shape)\n",
    "print(\"Shape (development data): \", X_dev_tfidf.shape)\n",
    "print(\"Shape (test data): \", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1bea4-7deb-4317-b2e4-73bab9cf2d89",
   "metadata": {
    "id": "cee1bea4-7deb-4317-b2e4-73bab9cf2d89"
   },
   "source": [
    "Below we can see that X_test_tfidf is a sparse array, keeping only the non-zero elements. We demonstrate all the elements in the first document with their corresponding TFIDF weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06cbf1eb-2aa8-4f98-af50-1c5fbd030a67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06cbf1eb-2aa8-4f98-af50-1c5fbd030a67",
    "outputId": "018e4032-62bf-49bf-be6c-f50ab4a60df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#Doc,col index)     weight\n",
      "--------------------------------------------\n",
      "  (0, 4978)\t0.08671052066324904\n",
      "  (0, 4976)\t0.03671538334914884\n",
      "  (0, 4924)\t0.10045276741535573\n",
      "  (0, 4847)\t0.058129549966272086\n",
      "  (0, 4825)\t0.03312626408448193\n",
      "  (0, 4781)\t0.16012186931900993\n",
      "  (0, 4655)\t0.10750369282883378\n",
      "  (0, 4600)\t0.04781179045415405\n",
      "  (0, 4529)\t0.06325658248428882\n",
      "  (0, 4495)\t0.027830009808342326\n",
      "  (0, 4471)\t0.0850404565974127\n",
      "  (0, 4392)\t0.05126888044130781\n",
      "  (0, 4357)\t0.06788837492974621\n",
      "  (0, 4296)\t0.10418068147802131\n",
      "  (0, 4295)\t0.06913879445268362\n",
      "  (0, 4252)\t0.08901034885433064\n",
      "  (0, 4220)\t0.03231945245469888\n",
      "  (0, 4198)\t0.08464341657312996\n",
      "  (0, 4173)\t0.043602750222211\n",
      "  (0, 4129)\t0.10550283215887456\n",
      "  (0, 4127)\t0.09260094687406277\n",
      "  (0, 4108)\t0.06090977686007874\n",
      "  (0, 4094)\t0.042223783831714615\n",
      "  (0, 4087)\t0.07342693311508709\n",
      "  (0, 4084)\t0.1523967192627124\n",
      "  :\t:\n",
      "  (0, 602)\t0.05994739128863232\n",
      "  (0, 588)\t0.10418068147802131\n",
      "  (0, 586)\t0.048946168175341885\n",
      "  (0, 547)\t0.18201957441292232\n",
      "  (0, 530)\t0.08276623507063564\n",
      "  (0, 520)\t0.07232142503339328\n",
      "  (0, 518)\t0.06381680708402672\n",
      "  (0, 452)\t0.08425393967775716\n",
      "  (0, 402)\t0.10633497938375054\n",
      "  (0, 401)\t0.07182719622505275\n",
      "  (0, 369)\t0.05036666413937978\n",
      "  (0, 343)\t0.07147813361021413\n",
      "  (0, 334)\t0.0706682487808439\n",
      "  (0, 306)\t0.04020327213136904\n",
      "  (0, 301)\t0.04097838750466902\n",
      "  (0, 220)\t0.10318307295423858\n",
      "  (0, 217)\t0.11298886477294585\n",
      "  (0, 135)\t0.057202402144971354\n",
      "  (0, 121)\t0.056519043638465126\n",
      "  (0, 118)\t0.051039566799194504\n",
      "  (0, 108)\t0.08137947195219927\n",
      "  (0, 106)\t0.11147358508575173\n",
      "  (0, 54)\t0.08276623507063564\n",
      "  (0, 36)\t0.07652245666979834\n",
      "  (0, 35)\t0.0460705756639777\n"
     ]
    }
   ],
   "source": [
    "print(\"(#Doc,col index)     weight\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(X_test_tfidf[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70bdae24-6855-4d76-9e12-e9b21644b7d9",
   "metadata": {
    "id": "70bdae24-6855-4d76-9e12-e9b21644b7d9"
   },
   "outputs": [],
   "source": [
    "x_train_tfidf_array = X_train_tfidf.toarray()                   #from sparse to dense\n",
    "x_dev_tfidf_array = X_dev_tfidf.toarray()\n",
    "x_test_tfidf_array = X_test_tfidf.toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db2561-957a-4242-872a-8869b1ba9b21",
   "metadata": {
    "id": "d1db2561-957a-4242-872a-8869b1ba9b21"
   },
   "source": [
    "## Reducing dimensionality using SVD (from 5000 ---> 500 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d70f7f63-650d-4267-b54a-6a21551e9255",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d70f7f63-650d-4267-b54a-6a21551e9255",
    "outputId": "14e80d09-c1e2-4e77-e413-ce5983b9dcf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (training data) after SVD:  (1200, 500)\n",
      "Shape (development data) after SVD:  (400, 500)\n",
      "Shape (test data) after SVD:  (400, 500)\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=500, random_state=4321)\n",
    "X_train_svd = svd.fit_transform(x_train_tfidf_array)\n",
    "X_dev_svd = svd.transform(x_dev_tfidf_array)\n",
    "X_test_svd = svd.transform(x_test_tfidf_array)\n",
    "\n",
    "print(\"Shape (training data) after SVD: \", X_train_svd.shape)\n",
    "print(\"Shape (development data) after SVD: \", X_dev_svd.shape)\n",
    "print(\"Shape (test data) after SVD: \", X_test_svd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca401852-4cc8-423f-ba64-83be90733a6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca401852-4cc8-423f-ba64-83be90733a6c",
    "outputId": "1b6cd9a1-f647-4bfd-ccfe-79efdef86104"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_svd[0,:]) == 500     #Sanity check if the dimension is 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669ffd59-8a38-4897-b273-04fee1b71f09",
   "metadata": {
    "id": "669ffd59-8a38-4897-b273-04fee1b71f09"
   },
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6eba716-a996-4b15-8704-aa6963a1ed69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6eba716-a996-4b15-8704-aa6963a1ed69",
    "outputId": "d9993993-4f82-4877-973a-738e9d27f6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Development Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.00      0.00      0.00       202\n",
      "         pos       0.49      1.00      0.66       198\n",
      "\n",
      "    accuracy                           0.49       400\n",
      "   macro avg       0.25      0.50      0.33       400\n",
      "weighted avg       0.25      0.49      0.33       400\n",
      "\n",
      "-----------------------------------------------------\n",
      "Classification Report on Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.00      0.00      0.00       589\n",
      "         pos       0.51      1.00      0.67       611\n",
      "\n",
      "    accuracy                           0.51      1200\n",
      "   macro avg       0.25      0.50      0.34      1200\n",
      "weighted avg       0.26      0.51      0.34      1200\n",
      "\n",
      "-----------------------------------------------------\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.00      0.00      0.00       209\n",
      "         pos       0.48      1.00      0.65       191\n",
      "\n",
      "    accuracy                           0.48       400\n",
      "   macro avg       0.24      0.50      0.32       400\n",
      "weighted avg       0.23      0.48      0.31       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\") #assigns the most frequent class\n",
    "dummy_clf.fit(X_train_svd, y_train)\n",
    "\n",
    "\n",
    "y_dev_pred = dummy_clf.predict(X_dev_svd)\n",
    "\n",
    "#classification report -- Development set\n",
    "print(\"Classification Report on Development Set:\")\n",
    "print(classification_report(y_dev, y_dev_pred, target_names=z))\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "#classification report -- Training set\n",
    "y_train_pred = dummy_clf.predict(X_train_svd)\n",
    "print(\"Classification Report on Training Set:\")\n",
    "print(classification_report(y_train, y_train_pred, target_names=z))\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "#classification report -- Test set\n",
    "y_test_pred = dummy_clf.predict(X_test_svd)\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502b238-433a-47e7-9b6a-cab5c0dba2b7",
   "metadata": {
    "id": "7502b238-433a-47e7-9b6a-cab5c0dba2b7"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d4185b7-57fc-47bc-b27d-3a4bc2e6f8d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d4185b7-57fc-47bc-b27d-3a4bc2e6f8d1",
    "outputId": "eb42d49d-43b3-4675-cb35-9dc9ae00cc40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "50 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1178, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.49083333 0.4975     0.50916667 0.50916667        nan        nan\n",
      " 0.49083333 0.4975     0.51666667 0.50916667        nan        nan\n",
      " 0.67416667 0.675      0.81416667 0.8125            nan        nan\n",
      " 0.835      0.83333333 0.84583333 0.84583333        nan        nan\n",
      " 0.85583333 0.855      0.8425     0.84333333        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'solver': ['liblinear', 'saga'],  #solvers to try\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],  #reguralization penalties\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],  #inverse of regularization strength\n",
    "}\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "log_grid_clf = GridSearchCV(log_clf, parameters, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "log_grid_clf.fit(X_train_svd, y_train)\n",
    "print(\"Best hyperparameters:\", log_grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6831ebc0-25a7-40da-a5d4-7aecc5db151d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "6831ebc0-25a7-40da-a5d4-7aecc5db151d",
    "outputId": "8d1134f3-227b-44b8-8428-7fa10b617705"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = log_grid_clf.best_estimator_\n",
    "best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "045cc7ce-8889-4f41-9776-b35454ba7453",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "045cc7ce-8889-4f41-9776-b35454ba7453",
    "outputId": "ba8e358b-effc-417f-d93a-be3907b8f273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Development Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.87      0.82      0.85       202\n",
      "         pos       0.83      0.88      0.85       198\n",
      "\n",
      "    accuracy                           0.85       400\n",
      "   macro avg       0.85      0.85      0.85       400\n",
      "weighted avg       0.85      0.85      0.85       400\n",
      "\n",
      "-----------------------------------------------------\n",
      "Classification Report on Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00       589\n",
      "         pos       1.00      1.00      1.00       611\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "-----------------------------------------------------\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.87      0.86      0.86       209\n",
      "         pos       0.85      0.86      0.85       191\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_clf.fit(X_train_svd, y_train)\n",
    "\n",
    "#classification report -- Development set\n",
    "y_dev_pred = best_clf.predict(X_dev_svd)\n",
    "print(\"\\nClassification Report on Development Set:\")\n",
    "print(classification_report(y_dev, y_dev_pred, target_names=z))\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "#classification report -- Training set\n",
    "y_train_pred = best_clf.predict(X_train_svd)\n",
    "print(\"Classification Report on Training Set:\")\n",
    "print(classification_report(y_train, y_train_pred, target_names=z))\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "#classification report -- Test set\n",
    "y_test_pred = best_clf.predict(X_test_svd)\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fcff45-3931-45c3-b2c8-4e5d0faa5447",
   "metadata": {
    "id": "85fcff45-3931-45c3-b2c8-4e5d0faa5447"
   },
   "source": [
    "## Creating one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7853e3b0-502d-490f-abf3-c3903a5a7339",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7853e3b0-502d-490f-abf3-c3903a5a7339",
    "outputId": "dddb13c3-008c-488b-bb86-88e4c4818c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_1_hot[0]: [0]\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "target_list = z\n",
    "\n",
    "y_train_1_hot = lb.fit_transform([target_list[x] for x in y_train])\n",
    "y_dev_1_hot = lb.transform([target_list[x] for x in y_dev])\n",
    "\n",
    "print('y_train_1_hot[0]: {}'.format(y_train_1_hot[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a083a902-3d3a-4c92-b912-36e64f1272ba",
   "metadata": {
    "id": "a083a902-3d3a-4c92-b912-36e64f1272ba"
   },
   "outputs": [],
   "source": [
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
    "        val_targ = self.validation_data[1]\n",
    "\n",
    "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
    "            val_targ = np.argmax(val_targ, -1)\n",
    "        val_targ = tf.cast(val_targ,dtype=tf.float32)\n",
    "\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average=\"weighted\",\n",
    "                           zero_division=1)\n",
    "        _val_recall = recall_score(val_targ, val_predict, average=\"weighted\",\n",
    "                                   zero_division=1)\n",
    "        _val_precision = precision_score(val_targ, val_predict, average=\"weighted\",\n",
    "                                         zero_division=1)\n",
    "\n",
    "        logs['val_f1'] = _val_f1\n",
    "        logs['val_recall'] = _val_recall\n",
    "        logs['val_precision'] = _val_precision\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1fe580e-830b-47c2-9b7d-83c8cff62495",
   "metadata": {
    "id": "e1fe580e-830b-47c2-9b7d-83c8cff62495"
   },
   "outputs": [],
   "source": [
    "def create_MLP(input_size, activate_func,prob,hid_layers_size, optimizer_alg, bs_size, num_epochs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_size, input_dim = X_train_svd.shape[1], activation = activate_func))\n",
    "    model.add(Dropout(prob))\n",
    "    model.add(Dense(hid_layers_size, activation = activate_func))\n",
    "    model.add(Dropout(prob))\n",
    "    # needed an output layer with sigmoid (pdf-like output) with no dropout after it\n",
    "    model.add(Dense(1,  activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer = optimizer_alg,\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    if not os.path.exists('./checkpoints'):\n",
    "        os.makedirs('./checkpoints')\n",
    "    model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    if not os.path.exists('./checkpoints'):\n",
    "      os.makedirs('./checkpoints')\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "    'checkpoints/weights.hdf5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=2,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    "    )\n",
    "\n",
    "    start_training_time = time.time()\n",
    "    history = model.fit(\n",
    "      X_train_svd,\n",
    "      y_train_1_hot,\n",
    "      validation_data=(X_dev_svd, y_dev_1_hot),\n",
    "      batch_size=bs_size,\n",
    "      epochs=num_epochs,\n",
    "      shuffle=True,\n",
    "      callbacks=[Metrics(valid_data=(X_dev_svd, y_dev_1_hot)), checkpoint]\n",
    "      )\n",
    "    end_training_time = time.time()\n",
    "\n",
    "    print(f'\\nTraining time: {time.strftime(\"%H:%M:%S\", time.gmtime(end_training_time - start_training_time))} sec\\n')\n",
    "\n",
    "    return history, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lz0V9CnkJlay",
   "metadata": {
    "id": "lz0V9CnkJlay"
   },
   "source": [
    "## Setting the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4j-5nMhzJhuD",
   "metadata": {
    "id": "4j-5nMhzJhuD"
   },
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'input_size': [256, 512],\n",
    "    'activate_func': ['relu', 'sigmoid'],\n",
    "    'prob': [0.3, 0.4, 0.5],\n",
    "    'hid_layers_size': [2, 10, 50],\n",
    "    'optimizer_alg': ['adam', 'sgd'],\n",
    "    'bs_size': [32, 64, 128],\n",
    "    'num_epochs': [10, 40, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "N0m-9Jvv9Xv2",
   "metadata": {
    "id": "N0m-9Jvv9Xv2"
   },
   "outputs": [],
   "source": [
    "\n",
    "parameter_grid = {                          #Just to save time (to be deleted later)\n",
    "    'input_size' : [1],\n",
    "    'activate_func' : ['relu'],\n",
    "    'prob' : [0.5],\n",
    "    'hid_layers_size' : [2],\n",
    "    'optimizer_alg' : ['adam'],\n",
    "    'bs_size': [32],\n",
    "    'num_epochs': [100]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "oaEXeC9b7wZ_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8bfc1dd7d99c4aec90323b6a7d88721c",
      "4fbb55f5a77e43b7a45469ffc0a3e7a9",
      "cac6c4b6e34043398e731ec55ff47b56",
      "404eda6f19d8484bb0b03bb5ba1b1440",
      "8581bbea114e4654b1645c6ca33203f6",
      "d176a22127244866a55996f7e20580f9",
      "369278ddbf8a4f8da77e7d8c5f2d164f",
      "44548d7fb95e49bc8997f875d75f844e",
      "0893bb6fc1f44c75b116451c0db08d7b",
      "82e6cd0156f849ecb6af877a20cdb95a",
      "dca058a9f3694a1cab4ed29c413da0ec"
     ]
    },
    "id": "oaEXeC9b7wZ_",
    "outputId": "b7d401fb-9402-4db5-d3ac-e47687b67413"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b486f25a1d3c4ac2a3001b2c10d15bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 1)                 501       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 4         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508 (1.98 KB)\n",
      "Trainable params: 508 (1.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6945 - accuracy: 0.50\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49500, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 2s 15ms/step - loss: 0.6945 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6912 - accuracy: 0.50\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.49500 to 0.53500, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6908 - accuracy: 0.5092 - val_loss: 0.6918 - val_accuracy: 0.5350 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 1ms/steposs: 0.6881 - accuracy: 0.49\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.53500 to 0.56500, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6878 - accuracy: 0.4900 - val_loss: 0.6905 - val_accuracy: 0.5650 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6864 - accuracy: 0.51\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.56500\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6857 - accuracy: 0.5225 - val_loss: 0.6893 - val_accuracy: 0.5625 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6917 - accuracy: 0.50\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.56500 to 0.60750, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6915 - accuracy: 0.5000 - val_loss: 0.6886 - val_accuracy: 0.6075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6857 - accuracy: 0.53\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.60750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6866 - accuracy: 0.5308 - val_loss: 0.6870 - val_accuracy: 0.5900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6851 - accuracy: 0.52\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.60750 to 0.61000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6842 - accuracy: 0.5258 - val_loss: 0.6858 - val_accuracy: 0.6100 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6809 - accuracy: 0.53\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.61000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6815 - accuracy: 0.5325 - val_loss: 0.6836 - val_accuracy: 0.6000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6804 - accuracy: 0.52\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.61000 to 0.62250, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6791 - accuracy: 0.5275 - val_loss: 0.6824 - val_accuracy: 0.6225 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 1ms/steposs: 0.6727 - accuracy: 0.54\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.62250\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6730 - accuracy: 0.5417 - val_loss: 0.6801 - val_accuracy: 0.6100 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6738 - accuracy: 0.53\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 11: val_accuracy improved from 0.62250 to 0.62750, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6750 - accuracy: 0.5375 - val_loss: 0.6783 - val_accuracy: 0.6275 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6767 - accuracy: 0.54\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 12: val_accuracy improved from 0.62750 to 0.64250, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6743 - accuracy: 0.5458 - val_loss: 0.6767 - val_accuracy: 0.6425 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6758 - accuracy: 0.53\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 13: val_accuracy improved from 0.64250 to 0.64750, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6765 - accuracy: 0.5350 - val_loss: 0.6747 - val_accuracy: 0.6475 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6753 - accuracy: 0.54\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 14: val_accuracy improved from 0.64750 to 0.66000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6740 - accuracy: 0.5408 - val_loss: 0.6733 - val_accuracy: 0.6600 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6639 - accuracy: 0.56\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.66000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6634 - accuracy: 0.5625 - val_loss: 0.6700 - val_accuracy: 0.6425 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6574 - accuracy: 0.56\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 16: val_accuracy improved from 0.66000 to 0.66500, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6598 - accuracy: 0.5625 - val_loss: 0.6678 - val_accuracy: 0.6650 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6607 - accuracy: 0.55\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 17: val_accuracy improved from 0.66500 to 0.68750, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6592 - accuracy: 0.5583 - val_loss: 0.6654 - val_accuracy: 0.6875 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6586 - accuracy: 0.56\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 18: val_accuracy improved from 0.68750 to 0.70000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6581 - accuracy: 0.5575 - val_loss: 0.6628 - val_accuracy: 0.7000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6546 - accuracy: 0.57\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 19: val_accuracy improved from 0.70000 to 0.70500, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6548 - accuracy: 0.5692 - val_loss: 0.6601 - val_accuracy: 0.7050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 1ms/steposs: 0.6577 - accuracy: 0.55\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.70500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6587 - accuracy: 0.5533 - val_loss: 0.6572 - val_accuracy: 0.6950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6509 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.70500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6515 - accuracy: 0.5783 - val_loss: 0.6542 - val_accuracy: 0.6825 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6451 - accuracy: 0.56\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.70500\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.6453 - accuracy: 0.5700 - val_loss: 0.6518 - val_accuracy: 0.7025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6353 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 23: val_accuracy improved from 0.70500 to 0.71000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6343 - accuracy: 0.6000 - val_loss: 0.6476 - val_accuracy: 0.7100 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6412 - accuracy: 0.57\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 24: val_accuracy improved from 0.71000 to 0.74250, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6414 - accuracy: 0.5675 - val_loss: 0.6455 - val_accuracy: 0.7425 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6406 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.74250\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6413 - accuracy: 0.5842 - val_loss: 0.6423 - val_accuracy: 0.7175 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6446 - accuracy: 0.56\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 26: val_accuracy improved from 0.74250 to 0.77250, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6433 - accuracy: 0.5717 - val_loss: 0.6405 - val_accuracy: 0.7725 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6398 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.77250\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6402 - accuracy: 0.5808 - val_loss: 0.6373 - val_accuracy: 0.7675 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 1ms/steposs: 0.6412 - accuracy: 0.57\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 28: val_accuracy improved from 0.77250 to 0.79000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6407 - accuracy: 0.5758 - val_loss: 0.6367 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6470 - accuracy: 0.57\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 29: val_accuracy improved from 0.79000 to 0.80750, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.5725 - val_loss: 0.6349 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6324 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6292 - accuracy: 0.5942 - val_loss: 0.6293 - val_accuracy: 0.7425 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6369 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6376 - accuracy: 0.5825 - val_loss: 0.6276 - val_accuracy: 0.7600 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6190 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6197 - accuracy: 0.6033 - val_loss: 0.6249 - val_accuracy: 0.7875 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6395 - accuracy: 0.56\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6384 - accuracy: 0.5750 - val_loss: 0.6241 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6232 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6220 - accuracy: 0.6042 - val_loss: 0.6194 - val_accuracy: 0.7700 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6236 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6236 - accuracy: 0.5942 - val_loss: 0.6192 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6198 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 36: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6206 - accuracy: 0.6033 - val_loss: 0.6149 - val_accuracy: 0.7725 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6217 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6225 - accuracy: 0.5992 - val_loss: 0.6132 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6119 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 38: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6084 - accuracy: 0.6150 - val_loss: 0.6103 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6212 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6216 - accuracy: 0.5983 - val_loss: 0.6083 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 1ms/steposs: 0.6267 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6267 - accuracy: 0.5917 - val_loss: 0.6061 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6163 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 41: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6158 - accuracy: 0.6067 - val_loss: 0.6044 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6080 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6088 - accuracy: 0.6108 - val_loss: 0.6016 - val_accuracy: 0.7850 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6165 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6163 - accuracy: 0.6100 - val_loss: 0.5995 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6266 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6259 - accuracy: 0.5892 - val_loss: 0.5991 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6240 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 45: val_accuracy improved from 0.80750 to 0.81000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6226 - accuracy: 0.5925 - val_loss: 0.5968 - val_accuracy: 0.8100 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6186 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6170 - accuracy: 0.6042 - val_loss: 0.5944 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6102 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.6151 - accuracy: 0.6075 - val_loss: 0.5928 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6188 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 48: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6187 - accuracy: 0.5992 - val_loss: 0.5902 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6101 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6086 - accuracy: 0.6125 - val_loss: 0.5885 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6080 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6075 - accuracy: 0.6150 - val_loss: 0.5883 - val_accuracy: 0.8100 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6185 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6213 - accuracy: 0.5950 - val_loss: 0.5868 - val_accuracy: 0.8100 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6113 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 52: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.6117 - accuracy: 0.6092 - val_loss: 0.5837 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6136 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.6113 - accuracy: 0.6108 - val_loss: 0.5813 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6096 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 54: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.6098 - accuracy: 0.6058 - val_loss: 0.5810 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6171 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 55: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6204 - accuracy: 0.5967 - val_loss: 0.5801 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6122 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 56: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6095 - accuracy: 0.6100 - val_loss: 0.5777 - val_accuracy: 0.7850 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6206 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 57: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6184 - accuracy: 0.5958 - val_loss: 0.5761 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6190 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6183 - accuracy: 0.5967 - val_loss: 0.5761 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 1ms/steposs: 0.6125 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 59: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6102 - accuracy: 0.6075 - val_loss: 0.5750 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6002 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 60: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6025 - accuracy: 0.6200 - val_loss: 0.5717 - val_accuracy: 0.7850 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6121 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 61: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6112 - accuracy: 0.6058 - val_loss: 0.5714 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6130 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 62: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6169 - accuracy: 0.6000 - val_loss: 0.5705 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6116 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 63: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6100 - accuracy: 0.6083 - val_loss: 0.5687 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6212 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6229 - accuracy: 0.5892 - val_loss: 0.5674 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 1ms/steposs: 0.6055 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6055 - accuracy: 0.6125 - val_loss: 0.5663 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6134 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 66: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6148 - accuracy: 0.6000 - val_loss: 0.5651 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6062 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 67: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6067 - accuracy: 0.6117 - val_loss: 0.5637 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6071 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 68: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6071 - accuracy: 0.6117 - val_loss: 0.5622 - val_accuracy: 0.7925 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6106 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 69: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6139 - accuracy: 0.6008 - val_loss: 0.5609 - val_accuracy: 0.7925 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6093 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 70: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6096 - accuracy: 0.6075 - val_loss: 0.5602 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6065 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 71: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6088 - accuracy: 0.6092 - val_loss: 0.5582 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6276 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6241 - accuracy: 0.5867 - val_loss: 0.5601 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6049 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 73: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6058 - accuracy: 0.6133 - val_loss: 0.5572 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5947 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 74: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6029 - accuracy: 0.6167 - val_loss: 0.5547 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5917 - accuracy: 0.63\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 75: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5952 - accuracy: 0.6258 - val_loss: 0.5531 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6031 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 76: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6029 - accuracy: 0.6167 - val_loss: 0.5526 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6155 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 77: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6149 - accuracy: 0.6008 - val_loss: 0.5502 - val_accuracy: 0.7925 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6013 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6001 - accuracy: 0.6175 - val_loss: 0.5506 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6064 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 79: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6085 - accuracy: 0.6083 - val_loss: 0.5494 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6108 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 80: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6108 - accuracy: 0.6058 - val_loss: 0.5492 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5943 - accuracy: 0.63\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 81: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5984 - accuracy: 0.6225 - val_loss: 0.5477 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6088 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 82: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6083 - accuracy: 0.6083 - val_loss: 0.5473 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6060 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 83: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6069 - accuracy: 0.6108 - val_loss: 0.5464 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6107 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 84: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6115 - accuracy: 0.6042 - val_loss: 0.5468 - val_accuracy: 0.8100 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6006 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 85: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5997 - accuracy: 0.6200 - val_loss: 0.5442 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5959 - accuracy: 0.63\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 86: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6007 - accuracy: 0.6167 - val_loss: 0.5435 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6020 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6031 - accuracy: 0.6142 - val_loss: 0.5436 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5969 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 88: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5969 - accuracy: 0.6242 - val_loss: 0.5427 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5951 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 89: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5957 - accuracy: 0.6242 - val_loss: 0.5413 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6004 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 90: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5986 - accuracy: 0.6200 - val_loss: 0.5401 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6014 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 91: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6040 - accuracy: 0.6125 - val_loss: 0.5393 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5992 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 92: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5991 - accuracy: 0.6183 - val_loss: 0.5388 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5933 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 93: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5935 - accuracy: 0.6258 - val_loss: 0.5372 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5984 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 94: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.5969 - accuracy: 0.6208 - val_loss: 0.5364 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5907 - accuracy: 0.63\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 95: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5890 - accuracy: 0.6308 - val_loss: 0.5353 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6015 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 96: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 0.6083 - val_loss: 0.5351 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5938 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 97: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5957 - accuracy: 0.6242 - val_loss: 0.5340 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5869 - accuracy: 0.63\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 98: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5946 - accuracy: 0.6242 - val_loss: 0.5330 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5986 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 99: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5986 - accuracy: 0.6200 - val_loss: 0.5323 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5948 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 100: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5928 - accuracy: 0.6258 - val_loss: 0.5315 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "\n",
      "Training time: 00:00:36 sec\n",
      "\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.8025\n"
     ]
    }
   ],
   "source": [
    "param_combinations = list(product(*parameter_grid.values()))            #all possible combinations\n",
    "results = []\n",
    "for params in tqdm(param_combinations):\n",
    "\n",
    "    input_size, activate_func, prob, hid_layers_size, optimizer_alg, bs_size, num_epochs = params          #unpack params\n",
    "    history, model = create_MLP(input_size, activate_func, prob, hid_layers_size, optimizer_alg, bs_size, num_epochs)\n",
    "    dev_loss, dev_accuracy = model.evaluate(X_dev_svd, y_dev_1_hot)\n",
    "\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'history': history,\n",
    "        'model': model,\n",
    "\n",
    "    })\n",
    "\n",
    "\n",
    "best_result = max(results, key=lambda x: max(x['history'].history['val_accuracy']))               #Find the set of parameters with the best validation accuracy\n",
    "\n",
    "input_size = best_result['params'][0]\n",
    "activate_func = best_result['params'][1]\n",
    "dropout_prob = best_result['params'][2]\n",
    "hid_layer_size = best_result['params'][3]\n",
    "optimizer_alg = best_result['params'][4]\n",
    "batch_size = best_result['params'][5]\n",
    "num_epochs = best_result['params'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0tlep8n7sl8t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tlep8n7sl8t",
    "outputId": "4a92b1e3-082d-45e2-b81f-ecb0ece338c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Best Hyperparameters---\n",
      "Input size: 1\n",
      "Activation Function: relu\n",
      "Dropout Probability: 0.5\n",
      "Hidden Layer Size: 2\n",
      "Optimizer Algorithm: adam\n",
      "Batch Size: 32\n",
      "Number of Epochs: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"---Best Hyperparameters---\")\n",
    "print(\"Input size:\", input_size)\n",
    "print(\"Activation Function:\", activate_func)\n",
    "print(\"Dropout Probability:\", dropout_prob)\n",
    "print(\"Hidden Layer Size:\", hid_layer_size)\n",
    "print(\"Optimizer Algorithm:\", optimizer_alg)\n",
    "print(\"Batch Size:\", batch_size)\n",
    "print(\"Number of Epochs:\", num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "PYjpmlPttlBn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYjpmlPttlBn",
    "outputId": "5fb5818a-b52e-4dc9-cce1-9ca2bd8e6af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 1)                 501       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 4         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508 (1.98 KB)\n",
      "Trainable params: 508 (1.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6931 - accuracy: 0.50\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49500, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 2s 14ms/step - loss: 0.6931 - accuracy: 0.5008 - val_loss: 0.6930 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6927 - accuracy: 0.49\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6926 - accuracy: 0.4975 - val_loss: 0.6928 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6924 - accuracy: 0.52\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6928 - accuracy: 0.5092 - val_loss: 0.6926 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6926 - accuracy: 0.50\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6921 - accuracy: 0.5092 - val_loss: 0.6924 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6911 - accuracy: 0.51\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.5092 - val_loss: 0.6918 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6909 - accuracy: 0.50\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.5092 - val_loss: 0.6911 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6903 - accuracy: 0.50\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6903 - accuracy: 0.5092 - val_loss: 0.6904 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6897 - accuracy: 0.50\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5092 - val_loss: 0.6892 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6877 - accuracy: 0.51\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6879 - accuracy: 0.5092 - val_loss: 0.6882 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6837 - accuracy: 0.51\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6844 - accuracy: 0.5092 - val_loss: 0.6866 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6852 - accuracy: 0.50\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6859 - accuracy: 0.5092 - val_loss: 0.6853 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6829 - accuracy: 0.51\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6823 - accuracy: 0.5092 - val_loss: 0.6834 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6794 - accuracy: 0.51\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6797 - accuracy: 0.5092 - val_loss: 0.6810 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6759 - accuracy: 0.52\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.49500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6774 - accuracy: 0.5092 - val_loss: 0.6787 - val_accuracy: 0.4950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6730 - accuracy: 0.51\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 15: val_accuracy improved from 0.49500 to 0.55500, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6710 - accuracy: 0.5233 - val_loss: 0.6762 - val_accuracy: 0.5550 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6719 - accuracy: 0.53\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 16: val_accuracy improved from 0.55500 to 0.58500, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6746 - accuracy: 0.5267 - val_loss: 0.6735 - val_accuracy: 0.5850 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6601 - accuracy: 0.55\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 17: val_accuracy improved from 0.58500 to 0.60000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6628 - accuracy: 0.5542 - val_loss: 0.6704 - val_accuracy: 0.6000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6601 - accuracy: 0.54\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 18: val_accuracy improved from 0.60000 to 0.63000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6627 - accuracy: 0.5483 - val_loss: 0.6671 - val_accuracy: 0.6300 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6614 - accuracy: 0.54\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 19: val_accuracy improved from 0.63000 to 0.64750, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6614 - accuracy: 0.5483 - val_loss: 0.6638 - val_accuracy: 0.6475 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6589 - accuracy: 0.55\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 20: val_accuracy improved from 0.64750 to 0.65750, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6563 - accuracy: 0.5600 - val_loss: 0.6605 - val_accuracy: 0.6575 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6611 - accuracy: 0.55\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 21: val_accuracy improved from 0.65750 to 0.67000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6588 - accuracy: 0.5575 - val_loss: 0.6573 - val_accuracy: 0.6700 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6573 - accuracy: 0.55\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 22: val_accuracy improved from 0.67000 to 0.72000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6580 - accuracy: 0.5467 - val_loss: 0.6548 - val_accuracy: 0.7200 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6539 - accuracy: 0.57\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.72000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6481 - accuracy: 0.5808 - val_loss: 0.6517 - val_accuracy: 0.7175 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6421 - accuracy: 0.57\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.72000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6419 - accuracy: 0.5758 - val_loss: 0.6474 - val_accuracy: 0.7075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6456 - accuracy: 0.57\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.72000\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.6459 - accuracy: 0.5692 - val_loss: 0.6438 - val_accuracy: 0.7025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6414 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 26: val_accuracy improved from 0.72000 to 0.73250, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6412 - accuracy: 0.5783 - val_loss: 0.6414 - val_accuracy: 0.7325 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6424 - accuracy: 0.57\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 27: val_accuracy improved from 0.73250 to 0.74750, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6424 - accuracy: 0.5725 - val_loss: 0.6383 - val_accuracy: 0.7475 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6380 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.74750\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.5950 - val_loss: 0.6351 - val_accuracy: 0.7425 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6469 - accuracy: 0.56\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 29: val_accuracy improved from 0.74750 to 0.78500, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6463 - accuracy: 0.5633 - val_loss: 0.6344 - val_accuracy: 0.7850 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6259 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.78500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6259 - accuracy: 0.6017 - val_loss: 0.6298 - val_accuracy: 0.7600 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6260 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.78500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6318 - accuracy: 0.5942 - val_loss: 0.6259 - val_accuracy: 0.7525 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 3ms/steposs: 0.6138 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.78500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6138 - accuracy: 0.6150 - val_loss: 0.6229 - val_accuracy: 0.7650 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6316 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.78500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6318 - accuracy: 0.5842 - val_loss: 0.6219 - val_accuracy: 0.7800 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 1ms/steposs: 0.6237 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.78500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6227 - accuracy: 0.5992 - val_loss: 0.6190 - val_accuracy: 0.7825 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6269 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.78500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6241 - accuracy: 0.5975 - val_loss: 0.6148 - val_accuracy: 0.7675 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6138 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 36: val_accuracy improved from 0.78500 to 0.79000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.6186 - accuracy: 0.6033 - val_loss: 0.6133 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6188 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.79000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6151 - accuracy: 0.6150 - val_loss: 0.6095 - val_accuracy: 0.7750 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6152 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 38: val_accuracy improved from 0.79000 to 0.79250, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6162 - accuracy: 0.6075 - val_loss: 0.6070 - val_accuracy: 0.7925 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6177 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.79250\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6175 - accuracy: 0.6067 - val_loss: 0.6052 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6139 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.79250\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6100 - accuracy: 0.6158 - val_loss: 0.6023 - val_accuracy: 0.7850 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6159 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 41: val_accuracy did not improve from 0.79250\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6174 - accuracy: 0.6058 - val_loss: 0.6004 - val_accuracy: 0.7900 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6117 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 42: val_accuracy improved from 0.79250 to 0.80000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6102 - accuracy: 0.6150 - val_loss: 0.5998 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6313 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 43: val_accuracy improved from 0.80000 to 0.80250, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6324 - accuracy: 0.5825 - val_loss: 0.6007 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6208 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.80250\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6208 - accuracy: 0.6017 - val_loss: 0.5967 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6238 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.80250\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6227 - accuracy: 0.6017 - val_loss: 0.5946 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6142 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.80250\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6160 - accuracy: 0.6017 - val_loss: 0.5925 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6141 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 47: val_accuracy improved from 0.80250 to 0.80750, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6151 - accuracy: 0.6008 - val_loss: 0.5937 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6161 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 48: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6159 - accuracy: 0.6083 - val_loss: 0.5901 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6257 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6213 - accuracy: 0.5958 - val_loss: 0.5894 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6109 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6109 - accuracy: 0.6125 - val_loss: 0.5863 - val_accuracy: 0.7925 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6235 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6191 - accuracy: 0.5950 - val_loss: 0.5882 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6156 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 52: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6156 - accuracy: 0.6042 - val_loss: 0.5842 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6086 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6107 - accuracy: 0.6100 - val_loss: 0.5822 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6241 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 54: val_accuracy did not improve from 0.80750\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6240 - accuracy: 0.5908 - val_loss: 0.5834 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6076 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 55: val_accuracy improved from 0.80750 to 0.81000, saving model to checkpoints/weights.hdf5\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6082 - accuracy: 0.6150 - val_loss: 0.5789 - val_accuracy: 0.8100 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6156 - accuracy: 0.59\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 56: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6184 - accuracy: 0.6000 - val_loss: 0.5798 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6154 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 57: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6154 - accuracy: 0.6025 - val_loss: 0.5776 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6013 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6032 - accuracy: 0.6183 - val_loss: 0.5758 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6133 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 59: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6167 - accuracy: 0.5992 - val_loss: 0.5743 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6039 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 60: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6039 - accuracy: 0.6167 - val_loss: 0.5720 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6038 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 61: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6046 - accuracy: 0.6158 - val_loss: 0.5715 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6141 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 62: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6143 - accuracy: 0.6025 - val_loss: 0.5715 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6028 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 63: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6043 - accuracy: 0.6192 - val_loss: 0.5678 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6075 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6127 - accuracy: 0.6075 - val_loss: 0.5665 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6001 - accuracy: 0.63\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6034 - accuracy: 0.6167 - val_loss: 0.5661 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5992 - accuracy: 0.63\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 66: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.6158 - val_loss: 0.5637 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6083 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 67: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6083 - accuracy: 0.6083 - val_loss: 0.5635 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6031 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 68: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6034 - accuracy: 0.6167 - val_loss: 0.5609 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6202 - accuracy: 0.58\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 69: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6160 - accuracy: 0.5992 - val_loss: 0.5606 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6036 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 70: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6024 - accuracy: 0.6175 - val_loss: 0.5581 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6087 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 71: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6086 - accuracy: 0.6075 - val_loss: 0.5591 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5997 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5970 - accuracy: 0.6225 - val_loss: 0.5568 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6032 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 73: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6010 - accuracy: 0.6200 - val_loss: 0.5561 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6124 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 74: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6054 - accuracy: 0.6125 - val_loss: 0.5537 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6044 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 75: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5959 - accuracy: 0.6242 - val_loss: 0.5532 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6092 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 76: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6105 - accuracy: 0.6042 - val_loss: 0.5520 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5888 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 77: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5972 - accuracy: 0.6242 - val_loss: 0.5511 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6116 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.6106 - accuracy: 0.6058 - val_loss: 0.5502 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5988 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 79: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6004 - accuracy: 0.6175 - val_loss: 0.5482 - val_accuracy: 0.7925 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6005 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 80: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5988 - accuracy: 0.6192 - val_loss: 0.5487 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5999 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 81: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6044 - accuracy: 0.6142 - val_loss: 0.5479 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5986 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 82: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5997 - accuracy: 0.6192 - val_loss: 0.5463 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6088 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 83: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6096 - accuracy: 0.6067 - val_loss: 0.5463 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6009 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 84: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6034 - accuracy: 0.6142 - val_loss: 0.5444 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6093 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 85: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6080 - accuracy: 0.6075 - val_loss: 0.5438 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5928 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 86: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5922 - accuracy: 0.6300 - val_loss: 0.5432 - val_accuracy: 0.8050 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5992 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6007 - accuracy: 0.6167 - val_loss: 0.5410 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5970 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 88: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5971 - accuracy: 0.6200 - val_loss: 0.5410 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5865 - accuracy: 0.63\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 89: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5917 - accuracy: 0.6267 - val_loss: 0.5395 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6043 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 90: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6048 - accuracy: 0.6108 - val_loss: 0.5402 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5897 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 91: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5899 - accuracy: 0.6300 - val_loss: 0.5369 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5868 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 92: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5912 - accuracy: 0.6283 - val_loss: 0.5362 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6031 - accuracy: 0.61\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 93: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6015 - accuracy: 0.6158 - val_loss: 0.5373 - val_accuracy: 0.8075 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5948 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 94: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5948 - accuracy: 0.6233 - val_loss: 0.5351 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6077 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 95: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6090 - accuracy: 0.6075 - val_loss: 0.5353 - val_accuracy: 0.8100 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5928 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 96: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5944 - accuracy: 0.6242 - val_loss: 0.5332 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5977 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 97: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5965 - accuracy: 0.6217 - val_loss: 0.5325 - val_accuracy: 0.8000 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5938 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 98: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5966 - accuracy: 0.6208 - val_loss: 0.5311 - val_accuracy: 0.7950 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.6129 - accuracy: 0.60\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 99: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.6129 - accuracy: 0.6017 - val_loss: 0.5312 - val_accuracy: 0.7975 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 2ms/steposs: 0.5989 - accuracy: 0.62\n",
      " — val_f1: 0.338904 — val_precision: 0.750025 — val_recall: 0.505000\n",
      "\n",
      "Epoch 100: val_accuracy did not improve from 0.81000\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.6043 - accuracy: 0.6125 - val_loss: 0.5305 - val_accuracy: 0.8025 - val_f1: 0.3389 - val_recall: 0.5050 - val_precision: 0.7500\n",
      "\n",
      "Training time: 00:00:33 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history, best_model = create_MLP(input_size, activate_func, dropout_prob, hid_layer_size, optimizer_alg, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "Sv-RqCNRuorF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sv-RqCNRuorF",
    "outputId": "3ecf6ce4-e62b-4f6b-be0f-255201e53980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report -- Training set\n",
      "38/38 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.49      1.00      0.66       589\n",
      "         pos       0.00      0.00      0.00       611\n",
      "\n",
      "    accuracy                           0.49      1200\n",
      "   macro avg       0.25      0.50      0.33      1200\n",
      "weighted avg       0.24      0.49      0.32      1200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification report -- Training set\n",
    "print(\"Classification report -- Training set\")\n",
    "pred = np.argmax(best_model.predict(X_train_svd), axis = -1)                  #use np.argmax() because we are handling binary data\n",
    "print(classification_report(y_train, pred, target_names = z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "g0ssgwZYy1lW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0ssgwZYy1lW",
    "outputId": "9e0eed59-31ee-4a32-a9b8-171209780547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report -- Development set\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.51      1.00      0.67       202\n",
      "         pos       0.00      0.00      0.00       198\n",
      "\n",
      "    accuracy                           0.51       400\n",
      "   macro avg       0.25      0.50      0.34       400\n",
      "weighted avg       0.26      0.51      0.34       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification report -- Development set\n",
    "print(\"Classification report -- Development set\")\n",
    "pred = np.argmax(best_model.predict(X_dev_svd), axis = -1)                  #use np.argmax() because we are handling binary data\n",
    "print(classification_report(y_dev, pred, target_names = z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "X6ZaEp2vzDbu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6ZaEp2vzDbu",
    "outputId": "78a08e0e-c388-48cb-ae82-414574a3394c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report -- Test set\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.52      1.00      0.69       209\n",
      "         pos       0.00      0.00      0.00       191\n",
      "\n",
      "    accuracy                           0.52       400\n",
      "   macro avg       0.26      0.50      0.34       400\n",
      "weighted avg       0.27      0.52      0.36       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification report -- Test set\n",
    "print(\"Classification report -- Test set\")\n",
    "pred = np.argmax(best_model.predict(X_test_svd), axis = -1)                  #use np.argmax() because we are handling binary data\n",
    "print(classification_report(y_test, pred, target_names = z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xHF01dC6Itrf",
   "metadata": {
    "id": "xHF01dC6Itrf"
   },
   "source": [
    "## Visualize Model's Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "TxNNgy4kQEjG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "TxNNgy4kQEjG",
    "outputId": "803dfbae-7c1d-4e40-dd27-052248fa694a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0893bb6fc1f44c75b116451c0db08d7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0c8fef8ac4b54e4d9aaaea5850ab9eff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f20b5bb7d4047d590feaca68dc42bd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c8fef8ac4b54e4d9aaaea5850ab9eff",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b336a10bef144a6844edd1da9a5c023",
      "value": 2000
     }
    },
    "369278ddbf8a4f8da77e7d8c5f2d164f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b336a10bef144a6844edd1da9a5c023": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "404eda6f19d8484bb0b03bb5ba1b1440": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82e6cd0156f849ecb6af877a20cdb95a",
      "placeholder": "​",
      "style": "IPY_MODEL_dca058a9f3694a1cab4ed29c413da0ec",
      "value": " 1/1 [00:04&lt;00:00,  4.83s/it]"
     }
    },
    "44548d7fb95e49bc8997f875d75f844e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fbb55f5a77e43b7a45469ffc0a3e7a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d176a22127244866a55996f7e20580f9",
      "placeholder": "​",
      "style": "IPY_MODEL_369278ddbf8a4f8da77e7d8c5f2d164f",
      "value": "100%"
     }
    },
    "60b3adea3ef44003855d0ff2b80615b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a743fc251bfe4047bec57294de574712",
      "placeholder": "​",
      "style": "IPY_MODEL_62ca82bacb48437c8f9aacb227dffd19",
      "value": "100%"
     }
    },
    "62ca82bacb48437c8f9aacb227dffd19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82e6cd0156f849ecb6af877a20cdb95a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8581bbea114e4654b1645c6ca33203f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bfc1dd7d99c4aec90323b6a7d88721c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4fbb55f5a77e43b7a45469ffc0a3e7a9",
       "IPY_MODEL_cac6c4b6e34043398e731ec55ff47b56",
       "IPY_MODEL_404eda6f19d8484bb0b03bb5ba1b1440"
      ],
      "layout": "IPY_MODEL_8581bbea114e4654b1645c6ca33203f6"
     }
    },
    "8f0f0e9457a54be4be063c36b4c488a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a743fc251bfe4047bec57294de574712": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b89cc201689a403fb5a29eb128e2580e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cac6c4b6e34043398e731ec55ff47b56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44548d7fb95e49bc8997f875d75f844e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0893bb6fc1f44c75b116451c0db08d7b",
      "value": 1
     }
    },
    "d176a22127244866a55996f7e20580f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dca058a9f3694a1cab4ed29c413da0ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3f31da4bba74c78a7391b09073db313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f0f0e9457a54be4be063c36b4c488a1",
      "placeholder": "​",
      "style": "IPY_MODEL_f7d05083994f473b990512ced48c27dc",
      "value": " 2000/2000 [00:24&lt;00:00, 93.31it/s]"
     }
    },
    "efd411dc932e4e22be0c8fac54980f2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_60b3adea3ef44003855d0ff2b80615b2",
       "IPY_MODEL_1f20b5bb7d4047d590feaca68dc42bd4",
       "IPY_MODEL_e3f31da4bba74c78a7391b09073db313"
      ],
      "layout": "IPY_MODEL_b89cc201689a403fb5a29eb128e2580e"
     }
    },
    "f7d05083994f473b990512ced48c27dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
