{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5bfb9c9-35fe-4522-af77-5c7f9502ae64"
      },
      "source": [
        "## Dataset : Cornell Movie Review Data"
      ],
      "id": "b5bfb9c9-35fe-4522-af77-5c7f9502ae64"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8acb39d-9baf-479f-99a7-feb46f97bbb4",
        "outputId": "9d5e79ff-d449-4ffb-c82f-812fef120848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import math\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "import time\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import accuracy_score\n",
        "from itertools import product\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from itertools import product\n"
      ],
      "id": "a8acb39d-9baf-479f-99a7-feb46f97bbb4"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cdf95519-3876-485d-b379-8297d977fa20"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade tensorflow"
      ],
      "id": "cdf95519-3876-485d-b379-8297d977fa20"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b124fd8c-1035-48e7-9dc2-2fc1b599d94d",
        "outputId": "bd8d4a6c-148d-4501-878a-05b86ff92c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-14 17:37:20--  https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3127238 (3.0M) [application/x-gzip]\n",
            "Saving to: ‘review_polarity.tar.gz.2’\n",
            "\n",
            "review_polarity.tar 100%[===================>]   2.98M  5.80MB/s    in 0.5s    \n",
            "\n",
            "2024-02-14 17:37:21 (5.80 MB/s) - ‘review_polarity.tar.gz.2’ saved [3127238/3127238]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n"
      ],
      "id": "b124fd8c-1035-48e7-9dc2-2fc1b599d94d"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "91a9d448-2512-4a32-bb8d-4ddafcdc3c55",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!tar xzf review_polarity.tar.gz\n",
        "\n",
        "#!tar xvzf review_polarity.tar.gz                     #This prints also the names of the files"
      ],
      "id": "91a9d448-2512-4a32-bb8d-4ddafcdc3c55"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d414c1e2-e967-4384-8d3e-3981c7815862"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "\n",
        "dataset_path = 'txt_sentoken'\n",
        "movie_reviews = load_files(container_path = dataset_path, encoding = 'utf-8')\n",
        "\n",
        "\n",
        "x = movie_reviews.data            #the data\n",
        "y = movie_reviews.target          #the labels\n",
        "z = movie_reviews.target_names    #the names of labels"
      ],
      "id": "d414c1e2-e967-4384-8d3e-3981c7815862"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a309b1c-5b50-4b6c-bb0b-27392f5949f8",
        "outputId": "b3dfea74-bfa4-47e2-aec0-7233bc7dda5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"arnold schwarzenegger has been an icon for action enthusiasts , since the late 80's , but lately his films have been very sloppy and the one-liners are getting worse . \\nit's hard seeing arnold as mr . freeze in batman and robin , especially when he says tons of ice jokes , but hey he got 15 million , what's it matter to him ? \\nonce again arnold has signed to do another expensive blockbuster , that can't compare with the likes of the terminator series , true lies and even eraser . \\nin this so called dark thriller , the devil ( gabriel byrne ) has come upon earth , to impregnate a woman ( robin tunney ) which happens every 1000 years , and basically destroy the world , but apparently god has chosen one man , and that one man is jericho cane ( arnold himself ) . \\nwith the help of a trusty sidekick ( kevin pollack ) , they will stop at nothing to let the devil take over the world ! \\nparts of this are actually so absurd , that they would fit right in with dogma . \\nyes , the film is that weak , but it's better than the other blockbuster right now ( sleepy hollow ) , but it makes the world is not enough look like a 4 star film . \\nanyway , this definitely doesn't seem like an arnold movie . \\nit just wasn't the type of film you can see him doing . \\nsure he gave us a few chuckles with his well known one-liners , but he seemed confused as to where his character and the film was going . \\nit's understandable , especially when the ending had to be changed according to some sources . \\naside form that , he still walked through it , much like he has in the past few films . \\ni'm sorry to say this arnold but maybe these are the end of your action days . \\nspeaking of action , where was it in this film ? \\nthere was hardly any explosions or fights . \\nthe devil made a few places explode , but arnold wasn't kicking some devil butt . \\nthe ending was changed to make it more spiritual , which undoubtedly ruined the film . \\ni was at least hoping for a cool ending if nothing else occurred , but once again i was let down . \\ni also don't know why the film took so long and cost so much . \\nthere was really no super affects at all , unless you consider an invisible devil , who was in it for 5 minutes tops , worth the overpriced budget . \\nthe budget should have gone into a better script , where at least audiences could be somewhat entertained instead of facing boredom . \\nit's pitiful to see how scripts like these get bought and made into a movie . \\ndo they even read these things anymore ? \\nit sure doesn't seem like it . \\nthankfully gabriel's performance gave some light to this poor film . \\nwhen he walks down the street searching for robin tunney , you can't help but feel that he looked like a devil . \\nthe guy is creepy looking anyway ! \\nwhen it's all over , you're just glad it's the end of the movie . \\ndon't bother to see this , if you're expecting a solid action flick , because it's neither solid nor does it have action . \\nit's just another movie that we are suckered in to seeing , due to a strategic marketing campaign . \\nsave your money and see the world is not enough for an entertaining experience . \\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x[:1]"
      ],
      "id": "7a309b1c-5b50-4b6c-bb0b-27392f5949f8"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "090e57a5-8c4d-4887-ace5-8dfc8e8ed3a6",
        "outputId": "bc0ca845-90c3-4690-c17a-ea6f7bdbde37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "y"
      ],
      "id": "090e57a5-8c4d-4887-ace5-8dfc8e8ed3a6"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf9c8b3c-195a-4956-b387-1f514bed48e0",
        "outputId": "ce4288af-4969-4b66-c327-9f9879bd53ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg', 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "z"
      ],
      "id": "cf9c8b3c-195a-4956-b387-1f514bed48e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84c3d968-7410-4763-b9df-afee4286e36d"
      },
      "source": [
        "## Average Document Length"
      ],
      "id": "84c3d968-7410-4763-b9df-afee4286e36d"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f4c8cdd-6239-4c5f-b430-acbc6b6bffae",
        "outputId": "5c34d38d-7dd6-458a-a06d-ae1244877884"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(x)"
      ],
      "id": "5f4c8cdd-6239-4c5f-b430-acbc6b6bffae"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c6f2807-7676-448e-b3aa-01ca9b61cda2",
        "outputId": "94157bf8-f3a7-47da-c51e-7b12da82b526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3126"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(x[0])"
      ],
      "id": "6c6f2807-7676-448e-b3aa-01ca9b61cda2"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wDNKEYR67iEF"
      },
      "outputs": [],
      "source": [
        "def average_doc_length(corpus):\n",
        "    ''' Takes as input a whole corpus\n",
        "      Returns the average number of words and chars per document '''\n",
        "\n",
        "    document_word_lengths = [len(doc.split()) for doc in corpus]                            #length of each doc (in words)\n",
        "    average_doc_length_words = sum(document_word_lengths) / len(document_word_lengths)      #average doc length (in words)\n",
        "\n",
        "    document_char_lengths = [len(doc) for doc in corpus]                                    #length of each doc (in characters)\n",
        "    average_doc_length_chars = sum(document_char_lengths) / len(document_char_lengths)      #average doc length (in characters)\n",
        "\n",
        "    return average_doc_length_words, average_doc_length_chars"
      ],
      "id": "wDNKEYR67iEF"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "639a1e2f-8f79-4d85-8289-1bf47238f10e",
        "outputId": "34e87d4e-82c7-459d-e8be-c2098793ca7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Before preprocessing---\n",
            "Average Document Length (in words): 746.3405\n",
            "Average Document Length (in characters): 3893.002\n"
          ]
        }
      ],
      "source": [
        "print(\"---Before preprocessing---\")\n",
        "avg_length_words, avg_length_chars = average_doc_length(x)\n",
        "print(\"Average Document Length (in words):\", avg_length_words)\n",
        "print(\"Average Document Length (in characters):\", avg_length_chars)"
      ],
      "id": "639a1e2f-8f79-4d85-8289-1bf47238f10e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb82d229-1baa-4e0a-a331-b3b093f6db93"
      },
      "source": [
        "## Pre processing"
      ],
      "id": "fb82d229-1baa-4e0a-a331-b3b093f6db93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByZOdhlYIrmH"
      },
      "source": [
        "Let's take a look at the 100 most frequent words:"
      ],
      "id": "ByZOdhlYIrmH"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HwWtwMf6hVH",
        "outputId": "2fb889ad-c354-4711-9b2f-12964d8a2f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",: 77717 occurrences\n",
            "the: 76276 occurrences\n",
            ".: 65876 occurrences\n",
            "a: 37995 occurrences\n",
            "and: 35404 occurrences\n",
            "of: 33972 occurrences\n",
            "to: 31772 occurrences\n",
            "is: 26054 occurrences\n",
            "in: 21611 occurrences\n",
            "'s: 18128 occurrences\n",
            "``: 17625 occurrences\n",
            "it: 16059 occurrences\n",
            "that: 15912 occurrences\n",
            "): 11781 occurrences\n",
            "(: 11664 occurrences\n",
            "as: 11349 occurrences\n",
            "with: 10782 occurrences\n",
            "for: 9918 occurrences\n",
            "this: 9573 occurrences\n",
            "his: 9569 occurrences\n",
            "film: 9443 occurrences\n",
            "i: 8850 occurrences\n",
            "he: 8840 occurrences\n",
            "but: 8604 occurrences\n",
            "on: 7249 occurrences\n",
            "are: 7204 occurrences\n",
            "by: 6218 occurrences\n",
            "n't: 6217 occurrences\n",
            "be: 6083 occurrences\n",
            "an: 5742 occurrences\n",
            "who: 5680 occurrences\n",
            "not: 5672 occurrences\n",
            "movie: 5671 occurrences\n",
            "one: 5582 occurrences\n",
            "you: 5286 occurrences\n",
            "was: 5225 occurrences\n",
            "have: 5046 occurrences\n",
            "from: 4987 occurrences\n",
            "at: 4972 occurrences\n",
            "they: 4815 occurrences\n",
            "has: 4811 occurrences\n",
            "her: 4508 occurrences\n",
            "all: 4259 occurrences\n",
            "?: 3771 occurrences\n",
            "there: 3758 occurrences\n",
            "so: 3585 occurrences\n",
            "like: 3547 occurrences\n",
            "about: 3518 occurrences\n",
            "out: 3442 occurrences\n",
            "more: 3342 occurrences\n",
            "what: 3310 occurrences\n",
            "when: 3255 occurrences\n",
            "which: 3160 occurrences\n",
            "she: 3129 occurrences\n",
            "their: 3117 occurrences\n",
            "up: 3108 occurrences\n",
            "or: 3106 occurrences\n",
            "do: 3090 occurrences\n",
            ":: 3042 occurrences\n",
            "some: 2981 occurrences\n",
            "just: 2901 occurrences\n",
            "does: 2834 occurrences\n",
            "if: 2792 occurrences\n",
            "we: 2761 occurrences\n",
            "him: 2631 occurrences\n",
            "into: 2618 occurrences\n",
            "even: 2556 occurrences\n",
            "only: 2485 occurrences\n",
            "than: 2438 occurrences\n",
            "no: 2408 occurrences\n",
            "can: 2379 occurrences\n",
            "good: 2316 occurrences\n",
            "most: 2302 occurrences\n",
            "time: 2282 occurrences\n",
            "its: 2268 occurrences\n",
            "would: 2264 occurrences\n",
            "will: 2213 occurrences\n",
            "story: 2146 occurrences\n",
            "--: 2055 occurrences\n",
            "been: 2045 occurrences\n",
            "much: 2024 occurrences\n",
            "character: 1996 occurrences\n",
            "also: 1965 occurrences\n",
            "other: 1944 occurrences\n",
            "get: 1925 occurrences\n",
            "': 1885 occurrences\n",
            "them: 1877 occurrences\n",
            "very: 1862 occurrences\n",
            "characters: 1858 occurrences\n",
            ";: 1850 occurrences\n",
            "two: 1827 occurrences\n",
            "first: 1769 occurrences\n",
            "after: 1755 occurrences\n",
            "see: 1731 occurrences\n",
            "!: 1713 occurrences\n",
            "because: 1682 occurrences\n",
            "way: 1669 occurrences\n",
            "well: 1656 occurrences\n",
            "could: 1609 occurrences\n",
            "make: 1593 occurrences\n"
          ]
        }
      ],
      "source": [
        "text = ' '.join(x)\n",
        "tokens = word_tokenize(text.lower())              #convert to lowercase to treat words case-insensitively\n",
        "#tokens = [token.lower() for token in x]\n",
        "word_counts = Counter(tokens)\n",
        "top_100_words = word_counts.most_common(100)\n",
        "\n",
        "for word, count in top_100_words:\n",
        "  print(f\"{word}: {count} occurrences\")"
      ],
      "id": "0HwWtwMf6hVH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN30flXUIy1J"
      },
      "source": [
        "The english stopwords is a package of 179 words that in general, would not help in a sentiment analysis problem. But, since they include terms that are negative, removing them could prove harmful for our case.\n",
        "\n",
        "e.g. imagine the phrase \"I didn't like the film\" to end up \"like film\".\n",
        "\n",
        "So, the plan is to remove all the stop words that include negative meaning before the preprocessing."
      ],
      "id": "kN30flXUIy1J"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW31ByWhG80h",
        "outputId": "926dfe30-8355-4dd4-ab0f-f8a215f4e6b7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "stopwords.words('english')"
      ],
      "id": "EW31ByWhG80h"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOXMvNL1_x94"
      },
      "source": [
        " From these words, we will decide which ones to keep because in fact they have a meaningful impact in our sentiment analysis problem, as we stated earlier."
      ],
      "id": "oOXMvNL1_x94"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4JeOUnaDu_J",
        "outputId": "f25afe68-98e3-4b8b-ca73-e85604ed22b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not',\n",
              " \"don't\",\n",
              " \"aren't\",\n",
              " \"couldn't\",\n",
              " \"didn't\",\n",
              " \"doesn't\",\n",
              " \"hadn't\",\n",
              " \"hasn't\",\n",
              " \"shouldn't\",\n",
              " \"haven't\",\n",
              " \"wasn't\",\n",
              " \"weren't\",\n",
              " \"isn't\",\n",
              " 'doesn']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "set_stop_words = set(stopwords.words('english'))\n",
        "set_x = set(tokens)\n",
        "to_keep_words = ['not', \"don't\", \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"hadn't\", \"hasn't\" , \"shouldn't\", \"haven't\", \"wasn't\", \"weren't\",  \"isn't\", \"doesn\"]\n",
        "to_keep_words"
      ],
      "id": "q4JeOUnaDu_J"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWeLNvZcHwvC",
        "outputId": "eff437a6-9e06-4a7c-a32f-d117cfe3949b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n",
            "14\n",
            "165\n"
          ]
        }
      ],
      "source": [
        "stopwords_updated = set(stopwords.words('english')) - set(to_keep_words)\n",
        "print(len(stopwords.words('english')))\n",
        "print(len(to_keep_words))\n",
        "print(len(stopwords_updated))"
      ],
      "id": "rWeLNvZcHwvC"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "03b5d72f-a3d8-4504-ae30-8a5216ff038d"
      },
      "outputs": [],
      "source": [
        "def pre_process_text(text):\n",
        "    ''' Function to preprocess text.\n",
        "     input: initial text\n",
        "     output: processed text\n",
        "     Performs pre-processing methods:\n",
        "        1. Combination to a single document.\n",
        "        2. Convertion to lowercase.\n",
        "        3. Lemmatization and stop words extraction\n",
        "        4. Punctuation removal\n",
        "        5. Number removal\n",
        "        6. Single characters removal\n",
        "        7. Converting multiple spaces to single ones\n",
        "        '''\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    all_docs = []\n",
        "\n",
        "    single_char = re.compile(r'\\s+[a-z]\\s+')                                          #6. Remove single characters\n",
        "    multiple_space= re.compile(r'\\s+')                                                 #7. Replace multiple space with a single one\n",
        "\n",
        "    stopwords_updated = set(stopwords.words('english')) - set(to_keep_words)\n",
        "    for document in tqdm(x):\n",
        "\n",
        "        combined_text = ' '.join(text)            #1.Combine in one single document\n",
        "\n",
        "        combined_text = combined_text.lower()    #2. Convert to lowercase\n",
        "        combined_text = [lemmatizer.lemmatize(word) for word in document.split() if word not in stopwords_updated]  # 3.Lemmatize and remove stop words\n",
        "\n",
        "\n",
        "        combined_text = ' '.join(combined_text)\n",
        "\n",
        "        combined_text = ''.join([char for char in combined_text if char not in string.punctuation])   #4.remove punctuation\n",
        "        combined_text = ''.join([char for char in combined_text if not char.isdigit()])     #5.remove numbers\n",
        "\n",
        "        res = single_char.sub(combined_text, '')\n",
        "        res2 = multiple_space.sub(combined_text, ' ')\n",
        "        all_docs.append(combined_text)\n",
        "\n",
        "    return all_docs"
      ],
      "id": "03b5d72f-a3d8-4504-ae30-8a5216ff038d"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "f1084e2520574ce79fc5fac2e99bb66f",
            "9839a11842ca4e3ca66267c2c2943ad9",
            "d010708bb303467a942533ecd28230b0",
            "66cb7f4d6cb844049949d1112e961508",
            "e7e0d9747a3b40ecbd6f8d17f8998c9d",
            "4ac942090b964422a78f1940957fce5c",
            "e1556c174cda4962a5649c711a8658ca",
            "6ef35c9a467e462da65f629c4acb13b0",
            "299a0ab4784a4eb1bada5241d23f8e19",
            "3f37227cee9e4d71a82034aaa0745753",
            "6421f7c778ca490f985d148838d6417e"
          ]
        },
        "id": "03cecf2b-efb5-487b-94d0-de2666c5b724",
        "outputId": "391dfa3d-b196-4c07-8b5a-17a0f151313d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1084e2520574ce79fc5fac2e99bb66f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arnold schwarzenegger icon action enthusiast  since late s  lately film sloppy oneliner getting worse  hard seeing arnold mr  freeze batman robin  especially say ton ice joke  hey got  million  whats matter  arnold signed another expensive blockbuster  cant compare like terminator series  true lie even eraser  called dark thriller  devil  gabriel byrne  come upon earth  impregnate woman  robin tunney  happens every  year  basically destroy world  apparently god chosen one man  one man jericho cane  arnold   help trusty sidekick  kevin pollack   stop nothing let devil take world  part actually absurd  would fit right dogma  yes  film weak  better blockbuster right  sleepy hollow   make world not enough look like  star film  anyway  definitely doesnt seem like arnold movie  wasnt type film see  sure gave u chuckle well known oneliner  seemed confused character film going  understandable  especially ending changed according source  aside form  still walked  much like past film  im sorry say arnold maybe end action day  speaking action  film  hardly explosion fight  devil made place explode  arnold wasnt kicking devil butt  ending changed make spiritual  undoubtedly ruined film  least hoping cool ending nothing else occurred  let  also dont know film took long cost much  really super affect  unless consider invisible devil   minute top  worth overpriced budget  budget gone better script  least audience could somewhat entertained instead facing boredom  pitiful see script like get bought made movie  even read thing anymore  sure doesnt seem like  thankfully gabriels performance gave light poor film  walk street searching robin tunney  cant help feel looked like devil  guy creepy looking anyway   glad end movie  dont bother see  expecting solid action flick  neither solid action  another movie suckered seeing  due strategic marketing campaign  save money see world not enough entertaining experience ']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "processed_text = pre_process_text(x)\n",
        "\n",
        "processed_text[:1]"
      ],
      "id": "03cecf2b-efb5-487b-94d0-de2666c5b724"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tXfE8DYjnbQF",
        "outputId": "2cd0c39f-80ed-44da-ddc9-3be76cbfe2fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "word_counts = [len(doc.split()) for doc in x]\n",
        "\n",
        "# Plotting\n",
        "plt.bar(range(len(word_counts)), word_counts, color='blue')\n",
        "plt.xlabel('Document Index')\n",
        "plt.ylabel('Number of Words')\n",
        "plt.title('Number of Words in Each Document')\n",
        "plt.xticks(range(len(word_counts)), range(1, len(word_counts)+1))\n",
        "plt.show()"
      ],
      "id": "tXfE8DYjnbQF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c02f5f7f-c35e-4598-a662-0201cad098bf"
      },
      "source": [
        "## Splitting into training set (70%), development set (15%) and test set (15%)"
      ],
      "id": "c02f5f7f-c35e-4598-a662-0201cad098bf"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "b4c7b5bf-67cd-4b64-9aa6-397553e4e2dc"
      },
      "outputs": [],
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(processed_text, y, test_size=0.3, random_state=17)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=25)\n",
        "\n",
        "training_text = ' '.join(X_train)                    #Flatten into a single string\n",
        "development_text = ' '.join(X_dev)\n",
        "test_text = ' '.join(X_test)\n",
        "\n",
        "training_words = training_text.split()\n",
        "development_words = development_text.split()\n",
        "test_words = test_text.split()\n",
        "\n",
        "training_vocab = set(training_words)\n",
        "development_vocab = set(development_words)\n",
        "test_vocab = set(test_words)"
      ],
      "id": "b4c7b5bf-67cd-4b64-9aa6-397553e4e2dc"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ddd1654-381d-465d-a938-25a278114bcd",
        "outputId": "c8c91dd4-1d8e-400b-d5bb-dcd0bac603e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size (in documents):  1400\n",
            "Development set size (in documents):  300\n",
            "Test set size (in documents):  300\n",
            "Full size (sanity check):  2000\n",
            "---------------------------------\n",
            "Training vocabulary size (in words):  36624\n",
            "Development vocabulary size (in words):  16948\n",
            "Test vocabulary size (in words):  16780\n",
            "Full vocabulary size (in words):  70352\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set size (in documents): \", len(y_train))\n",
        "print(\"Development set size (in documents): \", len(y_dev))\n",
        "print(\"Test set size (in documents): \", len(y_test))\n",
        "print(\"Full size (sanity check): \", len(y_train) + len(y_dev) + len(y_test))\n",
        "print(\"---------------------------------\")\n",
        "print(\"Training vocabulary size (in words): \" , len(training_vocab))\n",
        "print(\"Development vocabulary size (in words): \", len(development_vocab))\n",
        "print(\"Test vocabulary size (in words): \", len(test_vocab))\n",
        "print(\"Full vocabulary size (in words): \", len(training_vocab) + len(development_vocab) + len(test_vocab))"
      ],
      "id": "6ddd1654-381d-465d-a938-25a278114bcd"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7506630-3bcd-484b-a332-9b24e40952a8",
        "outputId": "fc654864-ef29-45c3-e467-609557d1d5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape (training data):  (1400, 5000)\n",
            "Shape (development data):  (300, 5000)\n",
            "Shape (test data):  (300, 5000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2),                                        #Using unigram and bigram tf-idf features\n",
        "                             max_features = 5000, sublinear_tf=True)\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_dev_tfidf = vectorizer.transform(X_dev)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"Shape (training data): \", X_train_tfidf.shape)\n",
        "print(\"Shape (development data): \", X_dev_tfidf.shape)\n",
        "print(\"Shape (test data): \", X_test_tfidf.shape)"
      ],
      "id": "e7506630-3bcd-484b-a332-9b24e40952a8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cee1bea4-7deb-4317-b2e4-73bab9cf2d89"
      },
      "source": [
        "Below we can see that X_test_tfidf is a sparse array, keeping only the non-zero elements. We demonstrate all the elements in the first document with their corresponding TFIDF weights."
      ],
      "id": "cee1bea4-7deb-4317-b2e4-73bab9cf2d89"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06cbf1eb-2aa8-4f98-af50-1c5fbd030a67",
        "outputId": "ff38b531-2d6b-46e4-d228-7d12594e6ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#Doc,col index)     weight\n",
            "--------------------------------------------\n",
            "  (0, 4988)\t0.04369979111445381\n",
            "  (0, 4984)\t0.04509572589709288\n",
            "  (0, 4949)\t0.029438259695493924\n",
            "  (0, 4944)\t0.056137163964358784\n",
            "  (0, 4824)\t0.05057974628634809\n",
            "  (0, 4818)\t0.04691105533946471\n",
            "  (0, 4813)\t0.044492208704761484\n",
            "  (0, 4809)\t0.05686119775889408\n",
            "  (0, 4752)\t0.05958423412364823\n",
            "  (0, 4745)\t0.0545816762790642\n",
            "  (0, 4738)\t0.055935407908133075\n",
            "  (0, 4602)\t0.04369979111445381\n",
            "  (0, 4547)\t0.059221065124916185\n",
            "  (0, 4503)\t0.08881260047092368\n",
            "  (0, 4501)\t0.06533835593131196\n",
            "  (0, 4494)\t0.08320647266960984\n",
            "  (0, 4483)\t0.05583535077757744\n",
            "  (0, 4468)\t0.03918145513118411\n",
            "  (0, 4397)\t0.11107231660960269\n",
            "  (0, 4360)\t0.03126951709001394\n",
            "  (0, 4306)\t0.10415507060882424\n",
            "  (0, 4231)\t0.09278366310364763\n",
            "  (0, 4229)\t0.049964847720078163\n",
            "  (0, 4217)\t0.0896171685791907\n",
            "  (0, 4202)\t0.09205962930911232\n",
            "  :\t:\n",
            "  (0, 513)\t0.060849146279275595\n",
            "  (0, 489)\t0.08036077475459913\n",
            "  (0, 488)\t0.053672108305792124\n",
            "  (0, 442)\t0.08410716327055671\n",
            "  (0, 380)\t0.0960023130040499\n",
            "  (0, 377)\t0.05467514734151401\n",
            "  (0, 376)\t0.0699762476960985\n",
            "  (0, 332)\t0.06413650390552839\n",
            "  (0, 331)\t0.07225822256092695\n",
            "  (0, 302)\t0.09884801091906062\n",
            "  (0, 301)\t0.03675692747000289\n",
            "  (0, 274)\t0.03811953647139697\n",
            "  (0, 272)\t0.08710734322007006\n",
            "  (0, 224)\t0.03838903754087644\n",
            "  (0, 188)\t0.043855576810225616\n",
            "  (0, 187)\t0.09784990322980708\n",
            "  (0, 186)\t0.04983898276858567\n",
            "  (0, 172)\t0.06461190774122398\n",
            "  (0, 143)\t0.06234860813888304\n",
            "  (0, 127)\t0.0426935204821557\n",
            "  (0, 124)\t0.06289809001901348\n",
            "  (0, 67)\t0.06367303616411338\n",
            "  (0, 53)\t0.07789571909603248\n",
            "  (0, 41)\t0.09690300360499679\n",
            "  (0, 38)\t0.04056821918397283\n"
          ]
        }
      ],
      "source": [
        "print(\"(#Doc,col index)     weight\")\n",
        "print(\"--------------------------------------------\")\n",
        "print(X_test_tfidf[0, :])"
      ],
      "id": "06cbf1eb-2aa8-4f98-af50-1c5fbd030a67"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "70bdae24-6855-4d76-9e12-e9b21644b7d9"
      },
      "outputs": [],
      "source": [
        "x_train_tfidf_array = X_train_tfidf.toarray()                   #from sparse to dense\n",
        "x_dev_tfidf_array = X_dev_tfidf.toarray()\n",
        "x_test_tfidf_array = X_test_tfidf.toarray()\n"
      ],
      "id": "70bdae24-6855-4d76-9e12-e9b21644b7d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1db2561-957a-4242-872a-8869b1ba9b21"
      },
      "source": [
        "## Reducing dimensionality using SVD (from 5000 ---> 500 features)"
      ],
      "id": "d1db2561-957a-4242-872a-8869b1ba9b21"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d70f7f63-650d-4267-b54a-6a21551e9255",
        "outputId": "2067b1a4-59f5-4f3e-aace-c84ce9336e39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape (training data) after SVD:  (1400, 500)\n",
            "Shape (development data) after SVD:  (300, 500)\n",
            "Shape (test data) after SVD:  (300, 500)\n"
          ]
        }
      ],
      "source": [
        "svd = TruncatedSVD(n_components=500, random_state=4321)\n",
        "X_train_svd = svd.fit_transform(x_train_tfidf_array)\n",
        "X_dev_svd = svd.transform(x_dev_tfidf_array)\n",
        "X_test_svd = svd.transform(x_test_tfidf_array)\n",
        "\n",
        "print(\"Shape (training data) after SVD: \", X_train_svd.shape)\n",
        "print(\"Shape (development data) after SVD: \", X_dev_svd.shape)\n",
        "print(\"Shape (test data) after SVD: \", X_test_svd.shape)"
      ],
      "id": "d70f7f63-650d-4267-b54a-6a21551e9255"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca401852-4cc8-423f-ba64-83be90733a6c",
        "outputId": "b96ce9b6-1b53-40a3-ae15-2e3b2488c3b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(X_test_svd[0,:]) == 500     #Sanity check if the dimension is 500"
      ],
      "id": "ca401852-4cc8-423f-ba64-83be90733a6c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "669ffd59-8a38-4897-b273-04fee1b71f09"
      },
      "source": [
        "## Dummy Classifier"
      ],
      "id": "669ffd59-8a38-4897-b273-04fee1b71f09"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6eba716-a996-4b15-8704-aa6963a1ed69",
        "outputId": "f732b14f-7a55-49c7-e2f2-03366d28ac15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report on Development Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.00      0.00      0.00       157\n",
            "         pos       0.48      1.00      0.65       143\n",
            "\n",
            "    accuracy                           0.48       300\n",
            "   macro avg       0.24      0.50      0.32       300\n",
            "weighted avg       0.23      0.48      0.31       300\n",
            "\n",
            "-----------------------------------------------------\n",
            "Classification Report on Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.00      0.00      0.00       690\n",
            "         pos       0.51      1.00      0.67       710\n",
            "\n",
            "    accuracy                           0.51      1400\n",
            "   macro avg       0.25      0.50      0.34      1400\n",
            "weighted avg       0.26      0.51      0.34      1400\n",
            "\n",
            "-----------------------------------------------------\n",
            "Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.00      0.00      0.00       153\n",
            "         pos       0.49      1.00      0.66       147\n",
            "\n",
            "    accuracy                           0.49       300\n",
            "   macro avg       0.24      0.50      0.33       300\n",
            "weighted avg       0.24      0.49      0.32       300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\") #assigns the most frequent class\n",
        "dummy_clf.fit(X_train_svd, y_train)\n",
        "\n",
        "\n",
        "y_dev_pred = dummy_clf.predict(X_dev_svd)\n",
        "\n",
        "#classification report -- Development set\n",
        "print(\"Classification Report on Development Set:\")\n",
        "print(classification_report(y_dev, y_dev_pred, target_names=z, zero_division = 0))\n",
        "\n",
        "print(\"-----------------------------------------------------\")\n",
        "\n",
        "#classification report -- Training set\n",
        "y_train_pred = dummy_clf.predict(X_train_svd)\n",
        "print(\"Classification Report on Training Set:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=z, zero_division = 0))\n",
        "\n",
        "print(\"-----------------------------------------------------\")\n",
        "\n",
        "#classification report -- Test set\n",
        "y_test_pred = dummy_clf.predict(X_test_svd)\n",
        "print(\"Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=z, zero_division = 0))"
      ],
      "id": "d6eba716-a996-4b15-8704-aa6963a1ed69"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7502b238-433a-47e7-9b6a-cab5c0dba2b7"
      },
      "source": [
        "## Logistic Regression"
      ],
      "id": "7502b238-433a-47e7-9b6a-cab5c0dba2b7"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d4185b7-57fc-47bc-b27d-3a4bc2e6f8d1",
        "outputId": "91c2889a-f861-4df6-81c3-82a5161f8fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "parameters = {\n",
        "    'solver': ['liblinear', 'saga'],  #solvers to try\n",
        "    'penalty': ['l1', 'l2'],  #reguralization penalties\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10],  #inverse of regularization strength\n",
        "}\n",
        "\n",
        "log_clf = LogisticRegression(max_iter = 1000)\n",
        "log_grid_clf = GridSearchCV(log_clf, parameters, cv=5, scoring='accuracy', verbose=1)\n",
        "\n",
        "\n",
        "log_grid_clf.fit(X_train_svd, y_train)\n",
        "print(\"Best hyperparameters:\", log_grid_clf.best_params_)"
      ],
      "id": "8d4185b7-57fc-47bc-b27d-3a4bc2e6f8d1"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "6831ebc0-25a7-40da-a5d4-7aecc5db151d",
        "outputId": "80f68899-fcfe-4789-a669-094b59a5acc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1, max_iter=1000, solver='liblinear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "best_clf = log_grid_clf.best_estimator_\n",
        "best_clf"
      ],
      "id": "6831ebc0-25a7-40da-a5d4-7aecc5db151d"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "045cc7ce-8889-4f41-9776-b35454ba7453",
        "outputId": "7c029700-bb9d-4fcb-f436-0b42e8ae550e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report on Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.94      0.92      0.93       690\n",
            "         pos       0.92      0.94      0.93       710\n",
            "\n",
            "    accuracy                           0.93      1400\n",
            "   macro avg       0.93      0.93      0.93      1400\n",
            "weighted avg       0.93      0.93      0.93      1400\n",
            "\n",
            "-----------------------------------------------------\n",
            "\n",
            "Classification Report on Development Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.90      0.82      0.85       157\n",
            "         pos       0.82      0.90      0.85       143\n",
            "\n",
            "    accuracy                           0.85       300\n",
            "   macro avg       0.86      0.86      0.85       300\n",
            "weighted avg       0.86      0.85      0.85       300\n",
            "\n",
            "-----------------------------------------------------\n",
            "Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.88      0.81      0.84       153\n",
            "         pos       0.82      0.88      0.85       147\n",
            "\n",
            "    accuracy                           0.85       300\n",
            "   macro avg       0.85      0.85      0.85       300\n",
            "weighted avg       0.85      0.85      0.85       300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_clf.fit(X_train_svd, y_train)\n",
        "\n",
        "#classification report -- Training set\n",
        "y_train_pred = best_clf.predict(X_train_svd)\n",
        "print(\"Classification Report on Training Set:\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=z))\n",
        "\n",
        "print(\"-----------------------------------------------------\")\n",
        "\n",
        "#classification report -- Development set\n",
        "y_dev_pred = best_clf.predict(X_dev_svd)\n",
        "print(\"\\nClassification Report on Development Set:\")\n",
        "print(classification_report(y_dev, y_dev_pred, target_names=z))\n",
        "\n",
        "print(\"-----------------------------------------------------\")\n",
        "\n",
        "#classification report -- Test set\n",
        "y_test_pred = best_clf.predict(X_test_svd)\n",
        "print(\"Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=z))"
      ],
      "id": "045cc7ce-8889-4f41-9776-b35454ba7453"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85fcff45-3931-45c3-b2c8-4e5d0faa5447"
      },
      "source": [
        "## Creating one-hot vectors"
      ],
      "id": "85fcff45-3931-45c3-b2c8-4e5d0faa5447"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7853e3b0-502d-490f-abf3-c3903a5a7339",
        "outputId": "b30a29c5-0496-48a3-fe15-43a27d144eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_dev_1_hot: [0] [1] [1] [0] [0] [1] [0] [1] [1] [1] [0] [1] [0] [1] [0] [1] [0] [1] [0] [0] [0] [1] [0] [1] [1] [1] [0] [0] [0] [0] [0] [1] [0] [0] [1] [1] [1] [0] [1] [1] [1] [0] [1] [1] [1] [1] [0] [0] [1] [0] [0] [0] [0] [1] [1] [1] [0] [0] [0] [0] [1] [1] [1] [1] [0] [0] [0] [0] [0] [0] [1] [0] [1] [1] [0] [1] [1] [0] [1] [0] [0] [0] [1] [0] [1] [1] [1] [0] [1] [1] [0] [0] [0] [0] [0] [1] [0] [1] [1] [0] [1] [0] [0] [1] [1] [1] [0] [0] [0] [0] [1] [0] [1] [0] [1] [0] [0] [1] [0] [1] [0] [0] [0] [0] [0] [1] [0] [0] [0] [0] [0] [0] [1] [0] [1] [0] [0] [0] [0] [0] [0] [0] [0] [1] [1] [0] [1] [0] [1] [1] [1] [1] [1] [0] [0] [0] [0] [1] [0] [1] [0] [1] [0] [1] [0] [1] [0] [1] [1] [1] [0] [0] [0] [1] [0] [0] [1] [1] [1] [1] [1] [1] [1] [0] [0] [1] [0] [0] [0] [1] [1] [1] [1] [1] [1] [1] [1] [1] [0] [1] [1] [0] [0] [0] [0] [1] [0] [1] [0] [1] [0] [1] [0] [0] [1] [1] [1] [1] [0] [0] [0] [0] [0] [1] [1] [1] [0] [1] [1] [1] [0] [0] [0] [0] [1] [0] [1] [0] [1] [1] [0] [0] [1] [0] [0] [0] [0] [0] [1] [1] [0] [1] [1] [1] [1] [0] [0] [0] [1] [0] [1] [0] [0] [1] [0] [1] [0] [0] [0] [0] [0] [0] [0] [0] [1] [1] [1] [1] [1] [1] [1] [0] [0] [1] [1] [1] [1] [1] [0] [0] [1] [1] [0] [0] [0] [1] [1] [1] [0] [1]\n"
          ]
        }
      ],
      "source": [
        "lb = LabelBinarizer()\n",
        "target_list = z\n",
        "\n",
        "y_train_1_hot = lb.fit_transform([target_list[x] for x in y_train])\n",
        "y_dev_1_hot = lb.transform([target_list[x] for x in y_dev])\n",
        "\n",
        "#y_train_1_hot = np.argmax(y_train_1_hot, axis=1)\n",
        "#y_dev_1_hot = np.argmax(y_dev_1_hot, axis=1)\n",
        "\n",
        "#print('y_dev_1_hot:', y_dev_1_hot)                             #prints vertically\n",
        "print('y_dev_1_hot:', ' '.join(map(str, y_dev_1_hot)))          #prints horizontally\n",
        "\n",
        "\n"
      ],
      "id": "7853e3b0-502d-490f-abf3-c3903a5a7339"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "L7-NHGvBM_hq"
      },
      "outputs": [],
      "source": [
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, valid_data):\n",
        "        super(Metrics, self).__init__()\n",
        "        self.validation_data = valid_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
        "        val_targ = self.validation_data[1]\n",
        "\n",
        "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
        "            val_targ = np.argmax(val_targ, -1)\n",
        "        val_targ = tf.cast(val_targ,dtype=tf.float32)\n",
        "\n",
        "        _val_f1 = f1_score(val_targ, val_predict,average=\"weighted\", zero_division = 0)\n",
        "        _val_recall = recall_score(val_targ, val_predict,average=\"weighted\", zero_division = 0)\n",
        "        _val_precision = precision_score(val_targ, val_predict,average=\"weighted\", zero_division = 0)\n",
        "\n",
        "        logs['val_f1'] = _val_f1\n",
        "        logs['val_recall'] = _val_recall\n",
        "        logs['val_precision'] = _val_precision\n",
        "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
        "        return"
      ],
      "id": "L7-NHGvBM_hq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz0V9CnkJlay"
      },
      "source": [
        "## Setting our MLP model"
      ],
      "id": "lz0V9CnkJlay"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "aF05twPzUTtY"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'hidden_layers': [1, 2],\n",
        "    'hidden_layers_size': [64, 128],\n",
        "    'dropout_prob': [0.4, 0.5],\n",
        "    'batch_size': [1,64, 128]\n",
        "\n",
        "}"
      ],
      "id": "aF05twPzUTtY"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lhVGZg40UQCR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n"
      ],
      "id": "lhVGZg40UQCR"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8TlC0crDwzp6"
      },
      "outputs": [],
      "source": [
        "def MLP(input_size, num_hid_layers, hid_layers_size, drop_prob, batch_size, learn_rate):\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(input_size, input_dim=X_train_svd.shape[1] , activation='relu'))\n",
        "  model.add(Dropout(drop_prob))\n",
        "\n",
        "  for i in range(num_hid_layers):\n",
        "    model.add(Dense(hid_layers_size, activation = 'relu'))\n",
        "    model.add(Dropout(drop_prob))\n",
        "\n",
        "  model.add(Dense(1,  activation='sigmoid'))\n",
        "\n",
        "  # print(model.summary())\n",
        "\n",
        "  model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=SGD(learning_rate=learn_rate),\n",
        "    metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "  if not os.path.exists('./checkpoints'):\n",
        "    os.makedirs('./checkpoints')\n",
        "\n",
        "  checkpoint = ModelCheckpoint(\n",
        "    'checkpoints/weights.hdf5',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    verbose=2,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True\n",
        "    )\n",
        "\n",
        "  start_training_time = time.time()\n",
        "  history = model.fit(\n",
        "      X_train_svd,\n",
        "      y_train_1_hot,\n",
        "      validation_data=(X_dev_svd, y_dev_1_hot),\n",
        "      batch_size=batch_size,\n",
        "      epochs=50,\n",
        "      shuffle=True,\n",
        "      callbacks=[Metrics(valid_data=(X_dev_svd, y_dev_1_hot)), checkpoint, early_stopping]\n",
        "      )\n",
        "  end_training_time = time.time()\n",
        "\n",
        "  print(f'\\nTraining time: {time.strftime(\"%H:%M:%S\", time.gmtime(end_training_time - start_training_time))} sec\\n')\n",
        "\n",
        "  return history, model\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "8TlC0crDwzp6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov15A_oRf5w8"
      },
      "source": [
        "## Hyperparameter Tuning"
      ],
      "id": "ov15A_oRf5w8"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3gKFovMycy8",
        "outputId": "99a8ed44-b9ee-42ba-c2fa-c10a609c77e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with hyperparameters: (0.1, 2, 64, 0.5, 1)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.7046 - accuracy: 0.5014 - val_loss: 0.6927 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.52333\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.7001 - accuracy: 0.5021 - val_loss: 0.6954 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.52333\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.7021 - accuracy: 0.4857 - val_loss: 0.6925 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.52333\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6989 - accuracy: 0.5093 - val_loss: 0.6922 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.52333\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.7001 - accuracy: 0.5136 - val_loss: 0.6920 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.52333\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6992 - accuracy: 0.5086 - val_loss: 0.7029 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.52333 to 0.80667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6954 - accuracy: 0.5286 - val_loss: 0.6558 - val_accuracy: 0.8067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.80667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6858 - accuracy: 0.5779 - val_loss: 0.7226 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.80667 to 0.82000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6886 - accuracy: 0.5636 - val_loss: 0.6483 - val_accuracy: 0.8200 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.82000\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6711 - accuracy: 0.5893 - val_loss: 0.6832 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.82000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6575 - accuracy: 0.6150 - val_loss: 0.6924 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.82000 to 0.83000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6695 - accuracy: 0.6000 - val_loss: 0.5546 - val_accuracy: 0.8300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.83000\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6818 - accuracy: 0.5779 - val_loss: 0.6245 - val_accuracy: 0.8000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.83000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6720 - accuracy: 0.5814 - val_loss: 0.6833 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.83000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6376 - accuracy: 0.6086 - val_loss: 0.6433 - val_accuracy: 0.5767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.83000\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6712 - accuracy: 0.6207 - val_loss: 0.5827 - val_accuracy: 0.8067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.83000\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6404 - accuracy: 0.6221 - val_loss: 0.5401 - val_accuracy: 0.8200 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.83000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6827 - accuracy: 0.5979 - val_loss: 0.6784 - val_accuracy: 0.5900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.83000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6660 - accuracy: 0.6264 - val_loss: 0.7169 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.83000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6911 - accuracy: 0.5457 - val_loss: 0.6341 - val_accuracy: 0.7800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.83000\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6543 - accuracy: 0.6429 - val_loss: 0.6120 - val_accuracy: 0.6667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.83000 to 0.84000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6484 - accuracy: 0.6650 - val_loss: 0.4957 - val_accuracy: 0.8400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6358 - accuracy: 0.6571 - val_loss: 0.6462 - val_accuracy: 0.6633 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6508 - accuracy: 0.6271 - val_loss: 0.6375 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6563 - accuracy: 0.5821 - val_loss: 0.6934 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6869 - accuracy: 0.5421 - val_loss: 0.7074 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6962 - accuracy: 0.5079 - val_loss: 0.6949 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6869 - accuracy: 0.5350 - val_loss: 0.6992 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.7014 - accuracy: 0.4871 - val_loss: 0.6921 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.6998 - accuracy: 0.5000 - val_loss: 0.6964 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.7012 - accuracy: 0.4957 - val_loss: 0.6954 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.84000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6984 - accuracy: 0.5021 - val_loss: 0.7179 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:02:01 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.4767\n",
            "Development Accuracy: 0.476666659116745\n",
            "\n",
            "Training with hyperparameters: (0.001, 1, 128, 0.5, 64)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 2s 36ms/step - loss: 0.6936 - accuracy: 0.4971 - val_loss: 0.6936 - val_accuracy: 0.4633 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.46333\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6946 - accuracy: 0.4886 - val_loss: 0.6936 - val_accuracy: 0.4567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.46333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.4950 - val_loss: 0.6936 - val_accuracy: 0.4567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.46333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6942 - accuracy: 0.4871 - val_loss: 0.6936 - val_accuracy: 0.4567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.46333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6939 - accuracy: 0.4893 - val_loss: 0.6936 - val_accuracy: 0.4600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.46333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6938 - accuracy: 0.4936 - val_loss: 0.6936 - val_accuracy: 0.4600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.46333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6947 - accuracy: 0.4786 - val_loss: 0.6936 - val_accuracy: 0.4633 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.46333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.4986 - val_loss: 0.6936 - val_accuracy: 0.4633 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.46333 to 0.46667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5164 - val_loss: 0.6936 - val_accuracy: 0.4667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.46667 to 0.47333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6937 - accuracy: 0.4843 - val_loss: 0.6936 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.47333 to 0.48000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6942 - accuracy: 0.4821 - val_loss: 0.6936 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.48000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6940 - accuracy: 0.4779 - val_loss: 0.6936 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.48000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6929 - accuracy: 0.4993 - val_loss: 0.6936 - val_accuracy: 0.4667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.48000\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6943 - accuracy: 0.4864 - val_loss: 0.6936 - val_accuracy: 0.4667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.48000\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6940 - accuracy: 0.4964 - val_loss: 0.6936 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.48000\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6947 - accuracy: 0.4750 - val_loss: 0.6936 - val_accuracy: 0.4700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.48000\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6942 - accuracy: 0.4993 - val_loss: 0.6936 - val_accuracy: 0.4700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.48000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6943 - accuracy: 0.4786 - val_loss: 0.6936 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.48000 to 0.48333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6942 - accuracy: 0.4864 - val_loss: 0.6936 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6942 - accuracy: 0.4857 - val_loss: 0.6936 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6944 - accuracy: 0.4814 - val_loss: 0.6936 - val_accuracy: 0.4567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5093 - val_loss: 0.6936 - val_accuracy: 0.4567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6941 - accuracy: 0.5007 - val_loss: 0.6936 - val_accuracy: 0.4533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6945 - accuracy: 0.4943 - val_loss: 0.6936 - val_accuracy: 0.4533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6942 - accuracy: 0.4800 - val_loss: 0.6936 - val_accuracy: 0.4567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6946 - accuracy: 0.4836 - val_loss: 0.6936 - val_accuracy: 0.4633 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5064 - val_loss: 0.6935 - val_accuracy: 0.4600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6952 - accuracy: 0.4793 - val_loss: 0.6935 - val_accuracy: 0.4567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6940 - accuracy: 0.5014 - val_loss: 0.6935 - val_accuracy: 0.4500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6922 - accuracy: 0.5129 - val_loss: 0.6935 - val_accuracy: 0.4500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5007 - val_loss: 0.6935 - val_accuracy: 0.4567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6935 - accuracy: 0.4936 - val_loss: 0.6935 - val_accuracy: 0.4567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6938 - accuracy: 0.4786 - val_loss: 0.6935 - val_accuracy: 0.4500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6945 - accuracy: 0.4871 - val_loss: 0.6935 - val_accuracy: 0.4433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6936 - accuracy: 0.4943 - val_loss: 0.6935 - val_accuracy: 0.4400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6943 - accuracy: 0.4800 - val_loss: 0.6935 - val_accuracy: 0.4500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6935 - accuracy: 0.5014 - val_loss: 0.6935 - val_accuracy: 0.4600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6937 - accuracy: 0.4893 - val_loss: 0.6935 - val_accuracy: 0.4600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6934 - accuracy: 0.5164 - val_loss: 0.6935 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6939 - accuracy: 0.4979 - val_loss: 0.6935 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.48333 to 0.49000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6935 - val_accuracy: 0.4900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.4900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 43: val_accuracy improved from 0.49000 to 0.49333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.4893 - val_loss: 0.6935 - val_accuracy: 0.4933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 44: val_accuracy improved from 0.49333 to 0.49667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6924 - accuracy: 0.5029 - val_loss: 0.6935 - val_accuracy: 0.4967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 45: val_accuracy improved from 0.49667 to 0.50000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6944 - accuracy: 0.4907 - val_loss: 0.6935 - val_accuracy: 0.5000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.50000\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.4871 - val_loss: 0.6935 - val_accuracy: 0.5000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.50000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5014 - val_loss: 0.6935 - val_accuracy: 0.4967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.50000\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5007 - val_loss: 0.6934 - val_accuracy: 0.4967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.50000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5029 - val_loss: 0.6934 - val_accuracy: 0.5000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 50: val_accuracy improved from 0.50000 to 0.51333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6961 - accuracy: 0.4600 - val_loss: 0.6934 - val_accuracy: 0.5133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:00:16 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5133\n",
            "Development Accuracy: 0.5133333206176758\n",
            "\n",
            "Training with hyperparameters: (0.01, 2, 64, 0.5, 64)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.47333 to 0.47667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5186 - val_loss: 0.6937 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6943 - accuracy: 0.4886 - val_loss: 0.6937 - val_accuracy: 0.4667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6922 - accuracy: 0.5300 - val_loss: 0.6937 - val_accuracy: 0.4667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6938 - accuracy: 0.4950 - val_loss: 0.6937 - val_accuracy: 0.4667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5107 - val_loss: 0.6936 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.4993 - val_loss: 0.6936 - val_accuracy: 0.4600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.5214 - val_loss: 0.6936 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5171 - val_loss: 0.6936 - val_accuracy: 0.4667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6943 - accuracy: 0.4893 - val_loss: 0.6936 - val_accuracy: 0.4700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5093 - val_loss: 0.6936 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.4829 - val_loss: 0.6935 - val_accuracy: 0.4700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5029 - val_loss: 0.6935 - val_accuracy: 0.4700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6916 - accuracy: 0.5307 - val_loss: 0.6934 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6939 - accuracy: 0.4857 - val_loss: 0.6934 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.4993 - val_loss: 0.6933 - val_accuracy: 0.4700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5029 - val_loss: 0.6933 - val_accuracy: 0.4700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5236 - val_loss: 0.6933 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.47667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5086 - val_loss: 0.6932 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.47667 to 0.48333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5050 - val_loss: 0.6932 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6916 - accuracy: 0.5279 - val_loss: 0.6932 - val_accuracy: 0.4700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6923 - accuracy: 0.5129 - val_loss: 0.6932 - val_accuracy: 0.4733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5221 - val_loss: 0.6932 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6929 - accuracy: 0.5164 - val_loss: 0.6932 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6934 - accuracy: 0.5186 - val_loss: 0.6931 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6926 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6923 - accuracy: 0.5264 - val_loss: 0.6931 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6926 - accuracy: 0.5086 - val_loss: 0.6931 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.48333\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6927 - accuracy: 0.5114 - val_loss: 0.6931 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 31: val_accuracy improved from 0.48333 to 0.49000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.4900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6941 - accuracy: 0.4893 - val_loss: 0.6930 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6922 - accuracy: 0.5293 - val_loss: 0.6930 - val_accuracy: 0.4867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5129 - val_loss: 0.6931 - val_accuracy: 0.4867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6927 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.4900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6918 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.4900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5079 - val_loss: 0.6931 - val_accuracy: 0.4900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6941 - accuracy: 0.5007 - val_loss: 0.6930 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6917 - accuracy: 0.5286 - val_loss: 0.6931 - val_accuracy: 0.4900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.4936 - val_loss: 0.6930 - val_accuracy: 0.4900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6929 - accuracy: 0.5150 - val_loss: 0.6930 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6925 - accuracy: 0.5050 - val_loss: 0.6930 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5171 - val_loss: 0.6931 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5029 - val_loss: 0.6930 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.5350 - val_loss: 0.6930 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6918 - accuracy: 0.5143 - val_loss: 0.6930 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.5207 - val_loss: 0.6930 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.4964 - val_loss: 0.6930 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6929 - accuracy: 0.5100 - val_loss: 0.6930 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.49000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6904 - accuracy: 0.5443 - val_loss: 0.6929 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:00:15 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4833\n",
            "Development Accuracy: 0.4833333194255829\n",
            "\n",
            "Training with hyperparameters: (0.01, 1, 128, 0.5, 1)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6923 - accuracy: 0.5236 - val_loss: 0.6986 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.47667\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.6907 - accuracy: 0.5436 - val_loss: 0.6866 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.47667 to 0.69667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6819 - accuracy: 0.5764 - val_loss: 0.6691 - val_accuracy: 0.6967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.69667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6666 - accuracy: 0.6014 - val_loss: 0.6600 - val_accuracy: 0.5067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.69667\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.6166 - accuracy: 0.6786 - val_loss: 0.6425 - val_accuracy: 0.5333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.69667 to 0.82667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.5600 - accuracy: 0.7371 - val_loss: 0.4947 - val_accuracy: 0.8267 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.82667 to 0.86000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.4673 - accuracy: 0.7879 - val_loss: 0.4090 - val_accuracy: 0.8600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.86000\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.4001 - accuracy: 0.8250 - val_loss: 0.3816 - val_accuracy: 0.8400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.86000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.3645 - accuracy: 0.8364 - val_loss: 0.3448 - val_accuracy: 0.8600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.86000 to 0.88000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.3155 - accuracy: 0.8729 - val_loss: 0.3204 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.88000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.2768 - accuracy: 0.8836 - val_loss: 0.3509 - val_accuracy: 0.8300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.88000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.2487 - accuracy: 0.9029 - val_loss: 0.3197 - val_accuracy: 0.8733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.88000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.2382 - accuracy: 0.9050 - val_loss: 0.2935 - val_accuracy: 0.8767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.88000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.2190 - accuracy: 0.9121 - val_loss: 0.3479 - val_accuracy: 0.8400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.88000 to 0.89000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.2187 - accuracy: 0.9157 - val_loss: 0.3104 - val_accuracy: 0.8900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.1906 - accuracy: 0.9243 - val_loss: 0.3756 - val_accuracy: 0.8367 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.1796 - accuracy: 0.9271 - val_loss: 0.2917 - val_accuracy: 0.8667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.1633 - accuracy: 0.9379 - val_loss: 0.2932 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.1436 - accuracy: 0.9464 - val_loss: 0.2968 - val_accuracy: 0.8833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.1613 - accuracy: 0.9350 - val_loss: 0.3013 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.1315 - accuracy: 0.9514 - val_loss: 0.4862 - val_accuracy: 0.8300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.1301 - accuracy: 0.9486 - val_loss: 0.3239 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.1099 - accuracy: 0.9579 - val_loss: 0.3953 - val_accuracy: 0.8567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.1265 - accuracy: 0.9579 - val_loss: 0.3464 - val_accuracy: 0.8667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.1124 - accuracy: 0.9571 - val_loss: 0.4075 - val_accuracy: 0.8500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.0748 - accuracy: 0.9714 - val_loss: 0.3254 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.0930 - accuracy: 0.9650 - val_loss: 0.3947 - val_accuracy: 0.8700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:01:54 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8700\n",
            "Development Accuracy: 0.8700000047683716\n",
            "\n",
            "Training with hyperparameters: (0.001, 1, 128, 0.4, 64)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 0.6928 - accuracy: 0.5114 - val_loss: 0.6915 - val_accuracy: 0.5300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.53000 to 0.53333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6933 - accuracy: 0.5014 - val_loss: 0.6915 - val_accuracy: 0.5333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.53333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6927 - accuracy: 0.5100 - val_loss: 0.6915 - val_accuracy: 0.5333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.53333 to 0.53667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6920 - accuracy: 0.5107 - val_loss: 0.6915 - val_accuracy: 0.5367 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.53667 to 0.54667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6929 - accuracy: 0.5050 - val_loss: 0.6915 - val_accuracy: 0.5467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.54667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5050 - val_loss: 0.6915 - val_accuracy: 0.5467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.54667 to 0.55667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5107 - val_loss: 0.6915 - val_accuracy: 0.5567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.55667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6940 - accuracy: 0.4986 - val_loss: 0.6915 - val_accuracy: 0.5500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.55667 to 0.56000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6935 - accuracy: 0.4986 - val_loss: 0.6916 - val_accuracy: 0.5600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.56000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.5100 - val_loss: 0.6916 - val_accuracy: 0.5600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.56000 to 0.57000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6926 - accuracy: 0.5064 - val_loss: 0.6916 - val_accuracy: 0.5700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:00:04 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5700\n",
            "Development Accuracy: 0.5699999928474426\n",
            "\n",
            "Training with hyperparameters: (0.1, 1, 64, 0.5, 128)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53000, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 1s 40ms/step - loss: 0.6930 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.53000 to 0.53667, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.6928 - accuracy: 0.4950 - val_loss: 0.6920 - val_accuracy: 0.5367 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.53667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6927 - accuracy: 0.5271 - val_loss: 0.6916 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.53667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6910 - accuracy: 0.5214 - val_loss: 0.6911 - val_accuracy: 0.5000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.53667\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.6903 - accuracy: 0.5436 - val_loss: 0.6906 - val_accuracy: 0.5033 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.53667\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6893 - accuracy: 0.5307 - val_loss: 0.6903 - val_accuracy: 0.5000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.53667\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.6887 - accuracy: 0.5321 - val_loss: 0.6894 - val_accuracy: 0.5133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.53667 to 0.55000, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6872 - accuracy: 0.5714 - val_loss: 0.6887 - val_accuracy: 0.5500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.55000 to 0.58000, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6885 - accuracy: 0.5321 - val_loss: 0.6881 - val_accuracy: 0.5800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.58000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.6877 - accuracy: 0.5664 - val_loss: 0.6878 - val_accuracy: 0.5300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.58000 to 0.64000, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.6866 - accuracy: 0.5514 - val_loss: 0.6864 - val_accuracy: 0.6400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.64000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.6865 - accuracy: 0.5679 - val_loss: 0.6859 - val_accuracy: 0.6400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.64000\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.6851 - accuracy: 0.5764 - val_loss: 0.6858 - val_accuracy: 0.5367 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.64000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.6841 - accuracy: 0.5793 - val_loss: 0.6850 - val_accuracy: 0.5433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.64000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.6822 - accuracy: 0.5936 - val_loss: 0.6841 - val_accuracy: 0.5700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.64000\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.6828 - accuracy: 0.5793 - val_loss: 0.6830 - val_accuracy: 0.6133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.64000 to 0.64667, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6798 - accuracy: 0.6143 - val_loss: 0.6818 - val_accuracy: 0.6467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.64667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6816 - accuracy: 0.5936 - val_loss: 0.6812 - val_accuracy: 0.6400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.64667\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.6796 - accuracy: 0.6007 - val_loss: 0.6803 - val_accuracy: 0.6300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.64667\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.6787 - accuracy: 0.6036 - val_loss: 0.6799 - val_accuracy: 0.5767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.64667\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6770 - accuracy: 0.6007 - val_loss: 0.6784 - val_accuracy: 0.5933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.64667 to 0.68333, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.6753 - accuracy: 0.6071 - val_loss: 0.6759 - val_accuracy: 0.6833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.68333 to 0.69000, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.6740 - accuracy: 0.6193 - val_loss: 0.6745 - val_accuracy: 0.6900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.69000 to 0.70000, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.6721 - accuracy: 0.6207 - val_loss: 0.6730 - val_accuracy: 0.7000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.70000\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.6674 - accuracy: 0.6264 - val_loss: 0.6713 - val_accuracy: 0.7000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.70000 to 0.72667, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6673 - accuracy: 0.6343 - val_loss: 0.6689 - val_accuracy: 0.7267 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy improved from 0.72667 to 0.75667, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6685 - accuracy: 0.6200 - val_loss: 0.6668 - val_accuracy: 0.7567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.75667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6629 - accuracy: 0.6464 - val_loss: 0.6655 - val_accuracy: 0.7100 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 29: val_accuracy improved from 0.75667 to 0.77667, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6588 - accuracy: 0.6421 - val_loss: 0.6620 - val_accuracy: 0.7767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.77667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6615 - accuracy: 0.6500 - val_loss: 0.6601 - val_accuracy: 0.7400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.77667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6600 - accuracy: 0.6479 - val_loss: 0.6576 - val_accuracy: 0.7567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.77667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6577 - accuracy: 0.6464 - val_loss: 0.6549 - val_accuracy: 0.7533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.77667\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6527 - accuracy: 0.6700 - val_loss: 0.6526 - val_accuracy: 0.7467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 34: val_accuracy improved from 0.77667 to 0.83000, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.6489 - accuracy: 0.6757 - val_loss: 0.6473 - val_accuracy: 0.8300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.83000\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.6425 - accuracy: 0.6750 - val_loss: 0.6466 - val_accuracy: 0.7267 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.83000\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6433 - accuracy: 0.6686 - val_loss: 0.6406 - val_accuracy: 0.8233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.83000\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6364 - accuracy: 0.6921 - val_loss: 0.6374 - val_accuracy: 0.8033 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.83000\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6309 - accuracy: 0.6971 - val_loss: 0.6357 - val_accuracy: 0.7267 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.83000\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.6220 - accuracy: 0.7064 - val_loss: 0.6328 - val_accuracy: 0.6867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 40: val_accuracy improved from 0.83000 to 0.83667, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.6158 - accuracy: 0.7029 - val_loss: 0.6211 - val_accuracy: 0.8367 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.83667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6159 - accuracy: 0.6986 - val_loss: 0.6211 - val_accuracy: 0.7300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.83667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6079 - accuracy: 0.7279 - val_loss: 0.6135 - val_accuracy: 0.7667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.83667\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.5931 - accuracy: 0.7571 - val_loss: 0.6048 - val_accuracy: 0.7933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.83667\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.5944 - accuracy: 0.7286 - val_loss: 0.6004 - val_accuracy: 0.7933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.83667\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.5837 - accuracy: 0.7379 - val_loss: 0.5953 - val_accuracy: 0.7700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.83667\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.5765 - accuracy: 0.7379 - val_loss: 0.5868 - val_accuracy: 0.7967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.83667\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.5670 - accuracy: 0.7586 - val_loss: 0.5721 - val_accuracy: 0.8333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.83667\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.5633 - accuracy: 0.7507 - val_loss: 0.5641 - val_accuracy: 0.8333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 49: val_accuracy improved from 0.83667 to 0.84667, saving model to checkpoints/weights.hdf5\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.5555 - accuracy: 0.7664 - val_loss: 0.5556 - val_accuracy: 0.8467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.84667\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.5462 - accuracy: 0.7571 - val_loss: 0.5562 - val_accuracy: 0.7967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:00:14 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7967\n",
            "Development Accuracy: 0.79666668176651\n",
            "\n",
            "Training with hyperparameters: (0.001, 1, 64, 0.4, 1)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6951 - accuracy: 0.4779 - val_loss: 0.6939 - val_accuracy: 0.4933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.49333\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6928 - accuracy: 0.5057 - val_loss: 0.6936 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.49333\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6931 - accuracy: 0.5136 - val_loss: 0.6931 - val_accuracy: 0.4933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.49333\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6908 - accuracy: 0.5379 - val_loss: 0.6929 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.49333\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.6904 - accuracy: 0.5371 - val_loss: 0.6924 - val_accuracy: 0.4833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.49333\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6914 - accuracy: 0.5379 - val_loss: 0.6918 - val_accuracy: 0.4933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.49333 to 0.56333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6922 - accuracy: 0.5064 - val_loss: 0.6908 - val_accuracy: 0.5633 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.56333 to 0.60000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6890 - accuracy: 0.5521 - val_loss: 0.6899 - val_accuracy: 0.6000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.60000 to 0.68000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6883 - accuracy: 0.5621 - val_loss: 0.6888 - val_accuracy: 0.6800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.68000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6862 - accuracy: 0.5757 - val_loss: 0.6881 - val_accuracy: 0.6567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.68000 to 0.68667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6867 - accuracy: 0.5750 - val_loss: 0.6871 - val_accuracy: 0.6867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.68667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6849 - accuracy: 0.6029 - val_loss: 0.6867 - val_accuracy: 0.5733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.68667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6833 - accuracy: 0.5936 - val_loss: 0.6856 - val_accuracy: 0.6033 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.68667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6816 - accuracy: 0.6000 - val_loss: 0.6849 - val_accuracy: 0.5733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.68667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6817 - accuracy: 0.5993 - val_loss: 0.6832 - val_accuracy: 0.6400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.68667 to 0.75667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6801 - accuracy: 0.5971 - val_loss: 0.6813 - val_accuracy: 0.7567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.75667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6785 - accuracy: 0.6150 - val_loss: 0.6799 - val_accuracy: 0.7433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.75667\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.6784 - accuracy: 0.6021 - val_loss: 0.6801 - val_accuracy: 0.5833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.75667\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6760 - accuracy: 0.6150 - val_loss: 0.6779 - val_accuracy: 0.6700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.75667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6724 - accuracy: 0.6457 - val_loss: 0.6761 - val_accuracy: 0.7100 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.75667\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.6738 - accuracy: 0.6164 - val_loss: 0.6740 - val_accuracy: 0.7567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.75667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6715 - accuracy: 0.6300 - val_loss: 0.6728 - val_accuracy: 0.7033 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.75667 to 0.77333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6656 - accuracy: 0.6379 - val_loss: 0.6694 - val_accuracy: 0.7733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.77333 to 0.78333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6643 - accuracy: 0.6550 - val_loss: 0.6670 - val_accuracy: 0.7833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.78333 to 0.78667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6623 - accuracy: 0.6721 - val_loss: 0.6643 - val_accuracy: 0.7867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.78667 to 0.81000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6594 - accuracy: 0.6679 - val_loss: 0.6606 - val_accuracy: 0.8100 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.81000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6545 - accuracy: 0.6850 - val_loss: 0.6569 - val_accuracy: 0.8033 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.81000\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6505 - accuracy: 0.6807 - val_loss: 0.6537 - val_accuracy: 0.8067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.81000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6462 - accuracy: 0.6936 - val_loss: 0.6511 - val_accuracy: 0.7733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.81000\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6392 - accuracy: 0.6950 - val_loss: 0.6466 - val_accuracy: 0.7667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.81000\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6315 - accuracy: 0.7029 - val_loss: 0.6425 - val_accuracy: 0.7467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 32: val_accuracy improved from 0.81000 to 0.81667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6263 - accuracy: 0.7129 - val_loss: 0.6325 - val_accuracy: 0.8167 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.81667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6235 - accuracy: 0.7164 - val_loss: 0.6288 - val_accuracy: 0.8033 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 34: val_accuracy improved from 0.81667 to 0.82667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6074 - accuracy: 0.7464 - val_loss: 0.6204 - val_accuracy: 0.8267 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.82667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.5999 - accuracy: 0.7457 - val_loss: 0.6138 - val_accuracy: 0.8067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.82667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.5943 - accuracy: 0.7329 - val_loss: 0.6065 - val_accuracy: 0.8000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.82667\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.5814 - accuracy: 0.7514 - val_loss: 0.5917 - val_accuracy: 0.8200 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 38: val_accuracy improved from 0.82667 to 0.83333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.5778 - accuracy: 0.7571 - val_loss: 0.5810 - val_accuracy: 0.8333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.83333\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.5625 - accuracy: 0.7714 - val_loss: 0.5792 - val_accuracy: 0.7767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.83333\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.5477 - accuracy: 0.7743 - val_loss: 0.5588 - val_accuracy: 0.8300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.83333 to 0.84333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.5307 - accuracy: 0.7986 - val_loss: 0.5467 - val_accuracy: 0.8433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.84333 to 0.84667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.5191 - accuracy: 0.7943 - val_loss: 0.5345 - val_accuracy: 0.8467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.84667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.5063 - accuracy: 0.8029 - val_loss: 0.5208 - val_accuracy: 0.8433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.84667\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.4845 - accuracy: 0.8264 - val_loss: 0.5149 - val_accuracy: 0.8233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 45: val_accuracy improved from 0.84667 to 0.85333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.4778 - accuracy: 0.8150 - val_loss: 0.4936 - val_accuracy: 0.8533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.85333\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.4560 - accuracy: 0.8214 - val_loss: 0.4954 - val_accuracy: 0.8233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.85333\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.4484 - accuracy: 0.8200 - val_loss: 0.4691 - val_accuracy: 0.8533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.85333\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.4385 - accuracy: 0.8300 - val_loss: 0.4556 - val_accuracy: 0.8467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.85333\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.4179 - accuracy: 0.8471 - val_loss: 0.4700 - val_accuracy: 0.8067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.85333\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.3994 - accuracy: 0.8536 - val_loss: 0.4333 - val_accuracy: 0.8433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:04:22 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8433\n",
            "Development Accuracy: 0.8433333039283752\n",
            "\n",
            "Training with hyperparameters: (0.1, 1, 64, 0.4, 64)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 0.6927 - accuracy: 0.5036 - val_loss: 0.6929 - val_accuracy: 0.4900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.49000 to 0.51333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6924 - accuracy: 0.5021 - val_loss: 0.6916 - val_accuracy: 0.5133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.51333 to 0.53667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6904 - accuracy: 0.5407 - val_loss: 0.6904 - val_accuracy: 0.5367 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.53667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6904 - accuracy: 0.5193 - val_loss: 0.6899 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.53667 to 0.62000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.5629 - val_loss: 0.6886 - val_accuracy: 0.6200 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.62000 to 0.64333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6881 - accuracy: 0.5543 - val_loss: 0.6874 - val_accuracy: 0.6433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.64333\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6875 - accuracy: 0.5721 - val_loss: 0.6865 - val_accuracy: 0.6200 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.64333\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6856 - accuracy: 0.5814 - val_loss: 0.6857 - val_accuracy: 0.5500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.64333\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.6849 - accuracy: 0.5814 - val_loss: 0.6843 - val_accuracy: 0.5533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.64333 to 0.75333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6812 - accuracy: 0.5914 - val_loss: 0.6802 - val_accuracy: 0.7533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.75333 to 0.77000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6782 - accuracy: 0.6071 - val_loss: 0.6788 - val_accuracy: 0.7700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.77000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6753 - accuracy: 0.6343 - val_loss: 0.6775 - val_accuracy: 0.5967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.77000 to 0.79000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.6771 - accuracy: 0.5993 - val_loss: 0.6732 - val_accuracy: 0.7900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.79000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6718 - accuracy: 0.6264 - val_loss: 0.6702 - val_accuracy: 0.7767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.79000 to 0.81000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6637 - accuracy: 0.6621 - val_loss: 0.6658 - val_accuracy: 0.8100 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.81000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6598 - accuracy: 0.6593 - val_loss: 0.6641 - val_accuracy: 0.6533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.81000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6554 - accuracy: 0.6729 - val_loss: 0.6546 - val_accuracy: 0.7833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.81000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6486 - accuracy: 0.6721 - val_loss: 0.6481 - val_accuracy: 0.7967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.81000 to 0.82333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6461 - accuracy: 0.6614 - val_loss: 0.6410 - val_accuracy: 0.8233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.82333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6343 - accuracy: 0.7121 - val_loss: 0.6428 - val_accuracy: 0.6133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.82333 to 0.84667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6169 - accuracy: 0.7193 - val_loss: 0.6219 - val_accuracy: 0.8467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.84667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6102 - accuracy: 0.7193 - val_loss: 0.6186 - val_accuracy: 0.6933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.84667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.5920 - accuracy: 0.7357 - val_loss: 0.6022 - val_accuracy: 0.7700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.84667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.5872 - accuracy: 0.7350 - val_loss: 0.5822 - val_accuracy: 0.8400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.84667 to 0.85667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.5664 - accuracy: 0.7593 - val_loss: 0.5643 - val_accuracy: 0.8567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.85667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.5477 - accuracy: 0.7700 - val_loss: 0.5453 - val_accuracy: 0.8467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.85667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.5283 - accuracy: 0.7779 - val_loss: 0.5284 - val_accuracy: 0.8400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.85667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.5127 - accuracy: 0.7943 - val_loss: 0.5247 - val_accuracy: 0.7833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.85667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.4834 - accuracy: 0.8279 - val_loss: 0.5043 - val_accuracy: 0.7900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.85667\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.4602 - accuracy: 0.8221 - val_loss: 0.4924 - val_accuracy: 0.7933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.85667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.4446 - accuracy: 0.8129 - val_loss: 0.4756 - val_accuracy: 0.7900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.85667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.4163 - accuracy: 0.8486 - val_loss: 0.4725 - val_accuracy: 0.7700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.85667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.4091 - accuracy: 0.8393 - val_loss: 0.4254 - val_accuracy: 0.8333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 34: val_accuracy improved from 0.85667 to 0.87000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.3651 - accuracy: 0.8650 - val_loss: 0.3950 - val_accuracy: 0.8700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.87000 to 0.88667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3725 - accuracy: 0.8529 - val_loss: 0.3820 - val_accuracy: 0.8867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.88667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3601 - accuracy: 0.8614 - val_loss: 0.3794 - val_accuracy: 0.8533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.88667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3387 - accuracy: 0.8736 - val_loss: 0.4273 - val_accuracy: 0.7933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.88667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3340 - accuracy: 0.8686 - val_loss: 0.3471 - val_accuracy: 0.8733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.88667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.3182 - accuracy: 0.8843 - val_loss: 0.3395 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.88667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3029 - accuracy: 0.8871 - val_loss: 0.3310 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.88667\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.3217 - accuracy: 0.8643 - val_loss: 0.3640 - val_accuracy: 0.8367 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.88667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3133 - accuracy: 0.8700 - val_loss: 0.3638 - val_accuracy: 0.8400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 43: val_accuracy improved from 0.88667 to 0.89000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.2664 - accuracy: 0.9021 - val_loss: 0.3206 - val_accuracy: 0.8900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.89000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.2604 - accuracy: 0.8964 - val_loss: 0.3065 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.89000\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.2434 - accuracy: 0.9064 - val_loss: 0.3050 - val_accuracy: 0.8833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.89000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.2780 - accuracy: 0.8871 - val_loss: 0.5710 - val_accuracy: 0.7167 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.89000\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.2545 - accuracy: 0.9071 - val_loss: 0.3048 - val_accuracy: 0.8733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.89000\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.2215 - accuracy: 0.9150 - val_loss: 0.4168 - val_accuracy: 0.8000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.89000\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.2347 - accuracy: 0.9071 - val_loss: 0.3214 - val_accuracy: 0.8767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.89000\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.2410 - accuracy: 0.9029 - val_loss: 0.2978 - val_accuracy: 0.8900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:00:21 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8900\n",
            "Development Accuracy: 0.8899999856948853\n",
            "\n",
            "Training with hyperparameters: (0.1, 1, 64, 0.5, 64)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 1s 21ms/step - loss: 0.6952 - accuracy: 0.4850 - val_loss: 0.6951 - val_accuracy: 0.4800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.48000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6934 - accuracy: 0.5143 - val_loss: 0.6945 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.48000 to 0.48667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6930 - accuracy: 0.5150 - val_loss: 0.6922 - val_accuracy: 0.4867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.48667 to 0.54000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5164 - val_loss: 0.6911 - val_accuracy: 0.5400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.54000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6905 - accuracy: 0.5386 - val_loss: 0.6909 - val_accuracy: 0.5067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.54000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6889 - accuracy: 0.5557 - val_loss: 0.6904 - val_accuracy: 0.5033 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.54000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6886 - accuracy: 0.5521 - val_loss: 0.6912 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.54000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6887 - accuracy: 0.5421 - val_loss: 0.6895 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.54000 to 0.57667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6865 - accuracy: 0.5500 - val_loss: 0.6873 - val_accuracy: 0.5767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.57667 to 0.58667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6853 - accuracy: 0.5657 - val_loss: 0.6857 - val_accuracy: 0.5867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.58667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6843 - accuracy: 0.5736 - val_loss: 0.6848 - val_accuracy: 0.5767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.58667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.5914 - val_loss: 0.6844 - val_accuracy: 0.5133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.58667 to 0.72000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6804 - accuracy: 0.5900 - val_loss: 0.6801 - val_accuracy: 0.7200 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.72000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6783 - accuracy: 0.5964 - val_loss: 0.6787 - val_accuracy: 0.7067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.72000 to 0.72333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6782 - accuracy: 0.5736 - val_loss: 0.6755 - val_accuracy: 0.7233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.72333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6751 - accuracy: 0.6100 - val_loss: 0.6749 - val_accuracy: 0.6400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.72333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6667 - accuracy: 0.6279 - val_loss: 0.6719 - val_accuracy: 0.6467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.72333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6688 - accuracy: 0.6200 - val_loss: 0.6683 - val_accuracy: 0.6667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.72333 to 0.77667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6624 - accuracy: 0.6336 - val_loss: 0.6621 - val_accuracy: 0.7767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.77667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6566 - accuracy: 0.6514 - val_loss: 0.6580 - val_accuracy: 0.7600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.77667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.6573 - accuracy: 0.6336 - val_loss: 0.6500 - val_accuracy: 0.7667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.77667\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6498 - accuracy: 0.6579 - val_loss: 0.6542 - val_accuracy: 0.5933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.77667\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6406 - accuracy: 0.6750 - val_loss: 0.6411 - val_accuracy: 0.7200 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.77667\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6320 - accuracy: 0.6779 - val_loss: 0.6325 - val_accuracy: 0.7400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.77667 to 0.80667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6093 - accuracy: 0.7336 - val_loss: 0.6166 - val_accuracy: 0.8067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.80667\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6153 - accuracy: 0.6964 - val_loss: 0.6182 - val_accuracy: 0.6800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.80667\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.6047 - accuracy: 0.7029 - val_loss: 0.5975 - val_accuracy: 0.7933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 28: val_accuracy improved from 0.80667 to 0.82667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.5843 - accuracy: 0.7379 - val_loss: 0.5780 - val_accuracy: 0.8267 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.82667\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.5681 - accuracy: 0.7464 - val_loss: 0.5634 - val_accuracy: 0.8067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.82667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.5570 - accuracy: 0.7564 - val_loss: 0.5467 - val_accuracy: 0.8233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.82667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.5364 - accuracy: 0.7621 - val_loss: 0.5306 - val_accuracy: 0.8167 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 32: val_accuracy improved from 0.82667 to 0.83333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.5228 - accuracy: 0.7907 - val_loss: 0.5105 - val_accuracy: 0.8333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.4955 - accuracy: 0.7929 - val_loss: 0.5300 - val_accuracy: 0.7400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.4785 - accuracy: 0.7979 - val_loss: 0.5061 - val_accuracy: 0.7700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.83333 to 0.84333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.4602 - accuracy: 0.8136 - val_loss: 0.4609 - val_accuracy: 0.8433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 36: val_accuracy improved from 0.84333 to 0.85333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.4543 - accuracy: 0.8150 - val_loss: 0.4399 - val_accuracy: 0.8533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.85333\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.4412 - accuracy: 0.8150 - val_loss: 0.4999 - val_accuracy: 0.7467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.85333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.4073 - accuracy: 0.8486 - val_loss: 0.4341 - val_accuracy: 0.8067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.85333\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.3925 - accuracy: 0.8507 - val_loss: 0.4046 - val_accuracy: 0.8500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.85333\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3775 - accuracy: 0.8593 - val_loss: 0.4741 - val_accuracy: 0.7667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.85333 to 0.86000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3618 - accuracy: 0.8643 - val_loss: 0.3746 - val_accuracy: 0.8600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 42: val_accuracy improved from 0.86000 to 0.87000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.3603 - accuracy: 0.8493 - val_loss: 0.3808 - val_accuracy: 0.8700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.87000\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.3604 - accuracy: 0.8571 - val_loss: 0.3559 - val_accuracy: 0.8700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.87000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3304 - accuracy: 0.8750 - val_loss: 0.3474 - val_accuracy: 0.8700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.87000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3318 - accuracy: 0.8614 - val_loss: 0.3437 - val_accuracy: 0.8667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.87000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.3020 - accuracy: 0.8864 - val_loss: 0.4603 - val_accuracy: 0.7767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.87000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3232 - accuracy: 0.8757 - val_loss: 0.3672 - val_accuracy: 0.8267 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 48: val_accuracy improved from 0.87000 to 0.87667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.2832 - accuracy: 0.8986 - val_loss: 0.3180 - val_accuracy: 0.8767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.87667\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.2835 - accuracy: 0.8921 - val_loss: 0.3502 - val_accuracy: 0.8467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.87667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.2596 - accuracy: 0.9079 - val_loss: 0.4434 - val_accuracy: 0.7767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:00:21 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7767\n",
            "Development Accuracy: 0.7766666412353516\n",
            "\n",
            "Training with hyperparameters: (0.01, 2, 128, 0.5, 1)\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6943 - accuracy: 0.5021 - val_loss: 0.6912 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.52333 to 0.74667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6931 - accuracy: 0.5086 - val_loss: 0.6890 - val_accuracy: 0.7467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.74667\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.6897 - accuracy: 0.5307 - val_loss: 0.7005 - val_accuracy: 0.4767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.74667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.6839 - accuracy: 0.5557 - val_loss: 0.6753 - val_accuracy: 0.5233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.74667 to 0.79333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.6751 - accuracy: 0.5829 - val_loss: 0.6560 - val_accuracy: 0.7933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.79333\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.6461 - accuracy: 0.6493 - val_loss: 0.5910 - val_accuracy: 0.7833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.79333\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.5893 - accuracy: 0.6936 - val_loss: 0.5317 - val_accuracy: 0.7933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.79333\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.5255 - accuracy: 0.7357 - val_loss: 0.5476 - val_accuracy: 0.6767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.79333 to 0.82333, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.4576 - accuracy: 0.8021 - val_loss: 0.3930 - val_accuracy: 0.8233 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.82333 to 0.88667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.3896 - accuracy: 0.8307 - val_loss: 0.3157 - val_accuracy: 0.8867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.88667\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.3613 - accuracy: 0.8407 - val_loss: 0.3675 - val_accuracy: 0.8567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.88667\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.3281 - accuracy: 0.8629 - val_loss: 0.3410 - val_accuracy: 0.8600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.88667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.2830 - accuracy: 0.8879 - val_loss: 0.3652 - val_accuracy: 0.8333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.88667\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.2754 - accuracy: 0.8879 - val_loss: 0.3012 - val_accuracy: 0.8767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.88667\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.2594 - accuracy: 0.9000 - val_loss: 0.3249 - val_accuracy: 0.8600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.88667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.2507 - accuracy: 0.8993 - val_loss: 0.2952 - val_accuracy: 0.8733 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.88667\n",
            "1400/1400 [==============================] - 5s 4ms/step - loss: 0.2494 - accuracy: 0.9043 - val_loss: 0.3082 - val_accuracy: 0.8633 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.88667 to 0.89000, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.2163 - accuracy: 0.9114 - val_loss: 0.2916 - val_accuracy: 0.8900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.2103 - accuracy: 0.9064 - val_loss: 0.3146 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.89000\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.1916 - accuracy: 0.9271 - val_loss: 0.4167 - val_accuracy: 0.8400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.89000 to 0.89667, saving model to checkpoints/weights.hdf5\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.1785 - accuracy: 0.9350 - val_loss: 0.2998 - val_accuracy: 0.8967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.89667\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.1503 - accuracy: 0.9414 - val_loss: 0.2978 - val_accuracy: 0.8967 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.89667\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.1640 - accuracy: 0.9386 - val_loss: 0.4286 - val_accuracy: 0.8200 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.89667\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.1597 - accuracy: 0.9421 - val_loss: 0.3141 - val_accuracy: 0.8700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.89667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.1365 - accuracy: 0.9464 - val_loss: 0.4370 - val_accuracy: 0.8333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.89667\n",
            "1400/1400 [==============================] - 6s 4ms/step - loss: 0.1376 - accuracy: 0.9507 - val_loss: 0.2993 - val_accuracy: 0.8800 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.89667\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.1212 - accuracy: 0.9550 - val_loss: 0.4074 - val_accuracy: 0.8567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.89667\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 0.1401 - accuracy: 0.9507 - val_loss: 0.2962 - val_accuracy: 0.8767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:02:18 sec\n",
            "\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8767\n",
            "Development Accuracy: 0.8766666650772095\n"
          ]
        }
      ],
      "source": [
        "best_dev_accuracy = -1\n",
        "best_hyperparameters = None\n",
        "\n",
        "hyperparameter_combinations = random.sample(list(product(*hyperparameters.values())), 10)\n",
        "for params in hyperparameter_combinations:\n",
        "    learning_rate, hidden_layers, hidden_layers_size, dropout_prob, batch_size = params\n",
        "\n",
        "    print(f\"\\nTraining with hyperparameters: {params}\")\n",
        "\n",
        "    history, model = MLP(256, hidden_layers, hidden_layers_size, dropout_prob, batch_size, learning_rate)\n",
        "\n",
        "\n",
        "    dev_loss, dev_accuracy = model.evaluate(X_dev_svd, y_dev_1_hot)             #evaluate model on the development set\n",
        "\n",
        "    if dev_accuracy > best_dev_accuracy:\n",
        "        best_dev_accuracy = dev_accuracy\n",
        "        best_hyperparameters = params\n",
        "    print(f\"Development Accuracy: {dev_accuracy}\")\n"
      ],
      "id": "L3gKFovMycy8"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ByJH7J51ZP-",
        "outputId": "44ac65d4-2cb2-43a4-a851-0d8c80c355f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperpameters: (0.1, 1, 64, 0.4, 64)\n",
            "Best development accuracy: 0.8899999856948853\n"
          ]
        }
      ],
      "source": [
        "print(\"Best hyperpameters:\" , best_hyperparameters)\n",
        "print(\"Best development accuracy:\", best_dev_accuracy)\n",
        "\n",
        "\n",
        "learning_rate = best_hyperparameters[0]\n",
        "num_hid_layers = best_hyperparameters[1]\n",
        "hid_layers_size = best_hyperparameters[2]\n",
        "dropout_prob = best_hyperparameters[3]\n",
        "bs = best_hyperparameters[4]\n",
        "\n"
      ],
      "id": "1ByJH7J51ZP-"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HTu_rkOPdpq",
        "outputId": "1ab2c1a0-ad4b-4b20-c1f7-4964ed14e9d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 1s 20ms/step - loss: 0.6943 - accuracy: 0.4836 - val_loss: 0.6925 - val_accuracy: 0.5067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.50667 to 0.55000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6919 - accuracy: 0.5143 - val_loss: 0.6914 - val_accuracy: 0.5500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.55000 to 0.64000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5121 - val_loss: 0.6904 - val_accuracy: 0.6400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.64000 to 0.66000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6906 - accuracy: 0.5371 - val_loss: 0.6892 - val_accuracy: 0.6600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.66000\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6890 - accuracy: 0.5421 - val_loss: 0.6893 - val_accuracy: 0.5167 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.66000 to 0.67000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.5507 - val_loss: 0.6869 - val_accuracy: 0.6700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.67000 to 0.69333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5643 - val_loss: 0.6855 - val_accuracy: 0.6933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.69333\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6864 - accuracy: 0.5643 - val_loss: 0.6844 - val_accuracy: 0.6933 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.69333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5907 - val_loss: 0.6829 - val_accuracy: 0.6767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.69333 to 0.73000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.6129 - val_loss: 0.6802 - val_accuracy: 0.7300 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.73000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6754 - accuracy: 0.6350 - val_loss: 0.6780 - val_accuracy: 0.7133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.73000 to 0.75667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6716 - accuracy: 0.6643 - val_loss: 0.6745 - val_accuracy: 0.7567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.75667\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6701 - accuracy: 0.6300 - val_loss: 0.6724 - val_accuracy: 0.7133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.75667\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6667 - accuracy: 0.6436 - val_loss: 0.6693 - val_accuracy: 0.6833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.75667\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6618 - accuracy: 0.6486 - val_loss: 0.6633 - val_accuracy: 0.7567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.75667 to 0.78667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.6555 - accuracy: 0.6536 - val_loss: 0.6565 - val_accuracy: 0.7867 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.78667 to 0.80000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6473 - accuracy: 0.7071 - val_loss: 0.6500 - val_accuracy: 0.8000 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 18: val_accuracy improved from 0.80000 to 0.80333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6396 - accuracy: 0.6829 - val_loss: 0.6420 - val_accuracy: 0.8033 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.80333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.6324 - accuracy: 0.7021 - val_loss: 0.6335 - val_accuracy: 0.8033 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.80333 to 0.80667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.6242 - accuracy: 0.7107 - val_loss: 0.6236 - val_accuracy: 0.8067 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.80667\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.6095 - accuracy: 0.7229 - val_loss: 0.6147 - val_accuracy: 0.6700 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.80667\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.5977 - accuracy: 0.7350 - val_loss: 0.5992 - val_accuracy: 0.7433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.80667 to 0.81333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.5776 - accuracy: 0.7621 - val_loss: 0.5858 - val_accuracy: 0.8133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.81333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.5637 - accuracy: 0.7564 - val_loss: 0.5758 - val_accuracy: 0.7600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.81333 to 0.81667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.5442 - accuracy: 0.7771 - val_loss: 0.5489 - val_accuracy: 0.8167 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.81667 to 0.84667, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.5307 - accuracy: 0.7750 - val_loss: 0.5274 - val_accuracy: 0.8467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.84667\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.4992 - accuracy: 0.7993 - val_loss: 0.5075 - val_accuracy: 0.8333 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.84667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.4852 - accuracy: 0.7957 - val_loss: 0.5080 - val_accuracy: 0.7833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.84667\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.4540 - accuracy: 0.8136 - val_loss: 0.5066 - val_accuracy: 0.7533 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 30: val_accuracy improved from 0.84667 to 0.85000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.4468 - accuracy: 0.8100 - val_loss: 0.4549 - val_accuracy: 0.8500 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.85000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.4342 - accuracy: 0.8186 - val_loss: 0.4448 - val_accuracy: 0.8367 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.85000\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.3998 - accuracy: 0.8536 - val_loss: 0.4235 - val_accuracy: 0.8367 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 33: val_accuracy improved from 0.85000 to 0.86000, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3743 - accuracy: 0.8600 - val_loss: 0.4032 - val_accuracy: 0.8600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.86000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3702 - accuracy: 0.8443 - val_loss: 0.3985 - val_accuracy: 0.8467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.86000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3512 - accuracy: 0.8621 - val_loss: 0.3792 - val_accuracy: 0.8600 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.86000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3510 - accuracy: 0.8586 - val_loss: 0.4073 - val_accuracy: 0.8100 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.86000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3403 - accuracy: 0.8679 - val_loss: 0.3728 - val_accuracy: 0.8467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.86000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2931 - accuracy: 0.8900 - val_loss: 0.5286 - val_accuracy: 0.7167 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.86000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3003 - accuracy: 0.8886 - val_loss: 0.3808 - val_accuracy: 0.8167 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.86000\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2750 - accuracy: 0.9043 - val_loss: 0.3627 - val_accuracy: 0.8400 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.86000 to 0.88333, saving model to checkpoints/weights.hdf5\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3346 - accuracy: 0.8614 - val_loss: 0.3324 - val_accuracy: 0.8833 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.88333\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2736 - accuracy: 0.8921 - val_loss: 0.3194 - val_accuracy: 0.8767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.88333\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2614 - accuracy: 0.9007 - val_loss: 0.3780 - val_accuracy: 0.8200 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.88333\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.2551 - accuracy: 0.9043 - val_loss: 0.4346 - val_accuracy: 0.7900 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.88333\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2624 - accuracy: 0.9021 - val_loss: 0.5034 - val_accuracy: 0.7467 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.88333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2393 - accuracy: 0.9086 - val_loss: 0.4022 - val_accuracy: 0.8133 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.88333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2486 - accuracy: 0.8929 - val_loss: 0.3363 - val_accuracy: 0.8433 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.88333\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.2213 - accuracy: 0.9157 - val_loss: 0.5156 - val_accuracy: 0.7667 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.88333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2224 - accuracy: 0.9093 - val_loss: 0.3187 - val_accuracy: 0.8567 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " — val_f1: 0.359577 — val_precision: 0.273878 — val_recall: 0.523333\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.88333\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1865 - accuracy: 0.9321 - val_loss: 0.2933 - val_accuracy: 0.8767 - val_f1: 0.3596 - val_recall: 0.5233 - val_precision: 0.2739\n",
            "\n",
            "Training time: 00:00:21 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        " history, best_model = MLP(256, num_hid_layers, hid_layers_size, dropout_prob, bs, learning_rate )\n",
        "\n"
      ],
      "id": "0HTu_rkOPdpq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHF01dC6Itrf"
      },
      "source": [
        "## Visualize Model's Training History"
      ],
      "id": "xHF01dC6Itrf"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "KB2azVTtoHr4",
        "outputId": "93b6c452-149a-436c-e965-1d91796183af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper right')\n",
        "plt.show()"
      ],
      "id": "KB2azVTtoHr4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FHH33IQgGY3"
      },
      "source": [
        "##Metrics (Precision, Recall, F1, AUC)"
      ],
      "id": "1FHH33IQgGY3"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnWrA6W-X7SP",
        "outputId": "333a8519-bb82-418a-d932-d948f1f5de0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "train_probs = best_model.predict(X_train_svd)                       #Predict probs for training,dev and test\n",
        "dev_probs = best_model.predict(X_dev_svd)\n",
        "test_probs = best_model.predict(X_test_svd)\n",
        "\n",
        "\n",
        "train_preds = (train_probs > 0.5).astype(int)                                 #To get binary predictions\n",
        "dev_preds = (dev_probs > 0.5).astype(int)\n",
        "test_preds = (test_probs > 0.5).astype(int)\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average=None)\n",
        "    recall = recall_score(y_true, y_pred, average=None)\n",
        "    f1 = f1_score(y_true, y_pred, average=None)\n",
        "    return precision, recall, f1\n",
        "\n",
        "train_precision, train_recall, train_f1 = calculate_metrics(y_train, train_preds)\n",
        "dev_precision, dev_recall, dev_f1 = calculate_metrics(y_dev, dev_preds)\n",
        "test_precision, test_recall, test_f1 = calculate_metrics(y_test, test_preds)\n",
        "\n",
        "\n",
        "def calculate_pr_auc(y_true, y_probs):\n",
        "    pr_auc_scores = []\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
        "    pr_auc_scores.append(auc(recall, precision))\n",
        "    return pr_auc_scores\n",
        "\n",
        "train_pr_auc = calculate_pr_auc(y_train, train_probs)\n",
        "dev_pr_auc = calculate_pr_auc(y_dev, dev_probs)\n",
        "test_pr_auc = calculate_pr_auc(y_test, test_probs)\n"
      ],
      "id": "ZnWrA6W-X7SP"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOnt3pXgdPe3",
        "outputId": "36d16fa6-28a4-4fb6-ebcd-a57720969451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class  neg :   (Training)     (Development)      (Test)\n",
            "Precision    |  0.973837   |    0.900000    |   0.852349\n",
            "Recall       |  0.971014   |    0.859873    |   0.830065\n",
            "F1-score     |  0.972424   |    0.879479    |   0.841060\n",
            "PR AUC       |  0.996832   |    0.945601    |   0.921112\n",
            "-------------------------------------------------------------\n",
            "Class  pos :   (Training)     (Development)      (Test)\n",
            "Precision    |  0.971910   |    0.853333    |   0.827815\n",
            "Recall       |  0.974648   |    0.895105    |   0.850340\n",
            "F1-score     |  0.973277   |    0.873720    |   0.838926\n",
            "PR AUC       |  0.996832   |    0.945601    |   0.921112\n",
            "-------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(2):\n",
        "    print(\"Class \", z[i], \":   (Training)     (Development)      (Test)\")\n",
        "    print(f\"Precision    |  {train_precision[i]:.6f}   |    {dev_precision[i]:.6f}    |   {test_precision[i]:.6f}\")\n",
        "    print(f\"Recall       |  {train_recall[i]:.6f}   |    {dev_recall[i]:.6f}    |   {test_recall[i]:.6f}\")\n",
        "    print(f\"F1-score     |  {train_f1[i]:.6f}   |    {dev_f1[i]:.6f}    |   {test_f1[i]:.6f}\")\n",
        "    print(f\"PR AUC       |  {train_pr_auc[i-1]:.6f}   |    {dev_pr_auc[i-1]:.6f}    |   {test_pr_auc[i-1]:.6f}\")\n",
        "    print(\"-------------------------------------------------------------\")"
      ],
      "id": "EOnt3pXgdPe3"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhu7XewQh-2Q",
        "outputId": "1dd42b61-8b28-4bcd-f700-c733fcd53d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-averaged Scores for Training Subset:\n",
            "===========================================\n",
            "Macro-averaged Precision: 0.972874\n",
            "Macro-averaged Recall: 0.972831\n",
            "Macro-averaged F1-score: 0.972850\n",
            "Macro-averaged PR AUC: 0.996832\n",
            "\n",
            "Macro-averaged Scores for Development Subset:\n",
            "===============================================\n",
            "Macro-averaged Precision: 0.876667\n",
            "Macro-averaged Recall: 0.877489\n",
            "Macro-averaged F1-score: 0.876599\n",
            "Macro-averaged PR AUC: 0.945601\n",
            "\n",
            "Macro-averaged Scores for Test Subset:\n",
            "========================================\n",
            "Macro-averaged Precision: 0.840082\n",
            "Macro-averaged Recall: 0.840203\n",
            "Macro-averaged F1-score: 0.839993\n",
            "Macro-averaged PR AUC: 0.921112\n"
          ]
        }
      ],
      "source": [
        "def calculate_macro_averaged_scores(y_true, y_pred, y_probs):\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, average=None)\n",
        "    recall = recall_score(y_true, y_pred, average=None)\n",
        "    f1 = f1_score(y_true, y_pred, average=None)\n",
        "\n",
        "    def calculate_pr_auc(y_true, y_probs):\n",
        "        precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
        "        pr_auc = auc(recall, precision)\n",
        "        return pr_auc\n",
        "\n",
        "    pr_auc = calculate_pr_auc(y_true, y_probs)\n",
        "\n",
        "\n",
        "    macro_avg_precision = np.mean(precision)\n",
        "    macro_avg_recall = np.mean(recall)\n",
        "    macro_avg_f1 = np.mean(f1)\n",
        "    macro_avg_pr_auc = np.mean(pr_auc)\n",
        "\n",
        "    return macro_avg_precision, macro_avg_recall, macro_avg_f1, macro_avg_pr_auc\n",
        "\n",
        "train_macro_avg_precision, train_macro_avg_recall, train_macro_avg_f1, train_macro_avg_pr_auc = calculate_macro_averaged_scores(y_train, train_preds, train_probs)\n",
        "dev_macro_avg_precision, dev_macro_avg_recall, dev_macro_avg_f1, dev_macro_avg_pr_auc = calculate_macro_averaged_scores(y_dev, dev_preds, dev_probs)\n",
        "test_macro_avg_precision, test_macro_avg_recall, test_macro_avg_f1, test_macro_avg_pr_auc = calculate_macro_averaged_scores(y_test, test_preds, test_probs)\n",
        "\n",
        "\n",
        "print(\"Macro-averaged Scores for Training Subset:\")\n",
        "print(\"===========================================\")\n",
        "print(f\"Macro-averaged Precision: {train_macro_avg_precision:.6f}\")\n",
        "print(f\"Macro-averaged Recall: {train_macro_avg_recall:.6f}\")\n",
        "print(f\"Macro-averaged F1-score: {train_macro_avg_f1:.6f}\")\n",
        "print(f\"Macro-averaged PR AUC: {train_macro_avg_pr_auc:.6f}\")\n",
        "print()\n",
        "\n",
        "print(\"Macro-averaged Scores for Development Subset:\")\n",
        "print(\"===============================================\")\n",
        "print(f\"Macro-averaged Precision: {dev_macro_avg_precision:.6f}\")\n",
        "print(f\"Macro-averaged Recall: {dev_macro_avg_recall:.6f}\")\n",
        "print(f\"Macro-averaged F1-score: {dev_macro_avg_f1:.6f}\")\n",
        "print(f\"Macro-averaged PR AUC: {dev_macro_avg_pr_auc:.6f}\")\n",
        "print()\n",
        "\n",
        "print(\"Macro-averaged Scores for Test Subset:\")\n",
        "print(\"========================================\")\n",
        "print(f\"Macro-averaged Precision: {test_macro_avg_precision:.6f}\")\n",
        "print(f\"Macro-averaged Recall: {test_macro_avg_recall:.6f}\")\n",
        "print(f\"Macro-averaged F1-score: {test_macro_avg_f1:.6f}\")\n",
        "print(f\"Macro-averaged PR AUC: {test_macro_avg_pr_auc:.6f}\")\n"
      ],
      "id": "bhu7XewQh-2Q"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1084e2520574ce79fc5fac2e99bb66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9839a11842ca4e3ca66267c2c2943ad9",
              "IPY_MODEL_d010708bb303467a942533ecd28230b0",
              "IPY_MODEL_66cb7f4d6cb844049949d1112e961508"
            ],
            "layout": "IPY_MODEL_e7e0d9747a3b40ecbd6f8d17f8998c9d"
          }
        },
        "9839a11842ca4e3ca66267c2c2943ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ac942090b964422a78f1940957fce5c",
            "placeholder": "​",
            "style": "IPY_MODEL_e1556c174cda4962a5649c711a8658ca",
            "value": "100%"
          }
        },
        "d010708bb303467a942533ecd28230b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef35c9a467e462da65f629c4acb13b0",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_299a0ab4784a4eb1bada5241d23f8e19",
            "value": 2000
          }
        },
        "66cb7f4d6cb844049949d1112e961508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f37227cee9e4d71a82034aaa0745753",
            "placeholder": "​",
            "style": "IPY_MODEL_6421f7c778ca490f985d148838d6417e",
            "value": " 2000/2000 [00:23&lt;00:00, 108.61it/s]"
          }
        },
        "e7e0d9747a3b40ecbd6f8d17f8998c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac942090b964422a78f1940957fce5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1556c174cda4962a5649c711a8658ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef35c9a467e462da65f629c4acb13b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "299a0ab4784a4eb1bada5241d23f8e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f37227cee9e4d71a82034aaa0745753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6421f7c778ca490f985d148838d6417e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}